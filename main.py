# main.py
import mysql.connector
from mysql.connector import Error as MySQLError
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options
from selenium.common.exceptions import InvalidSessionIdException, WebDriverException
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import logging
from datetime import datetime
import sys
import os
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
import streamlit as st
import hashlib
import pymysql
from pymysql.cursors import DictCursor

# è®¾ç½®é¡µé¢é…ç½® - å¿…é¡»åœ¨æœ€å‰é¢ï¼
st.set_page_config(
    page_title="è€ƒç ”AIé—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'crawler_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

# è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
if sys.stdout.encoding != 'utf-8':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except AttributeError:
        import codecs

        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)

# å…¨å±€æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': 'your_password',
    'database': 'kaoyan_data'
}


class ThreadSafeSpider:
    """çº¿ç¨‹å®‰å…¨çš„çˆ¬è™«ç±»ï¼Œæ¯ä¸ªçº¿ç¨‹æœ‰è‡ªå·±çš„æµè§ˆå™¨å®ä¾‹"""

    def __init__(self, thread_id=0):
        self.thread_id = thread_id
        self.retry_count = 0
        self.max_retries = 3
        self.setup_driver()

    def setup_driver(self):
        """é…ç½®Edgeæµè§ˆå™¨é©±åŠ¨"""
        edge_options = Options()

        # åŸºæœ¬è®¾ç½®
        edge_options.add_argument('--no-sandbox')
        edge_options.add_argument('--disable-dev-shm-usage')
        edge_options.add_argument('--window-size=1920,1080')
        edge_options.add_argument('--disable-gpu')
        edge_options.add_argument('--disable-extensions')
        edge_options.add_argument('--disable-background-timer-throttling')
        edge_options.add_argument('--disable-backgrounding-occluded-windows')
        edge_options.add_argument('--disable-renderer-backgrounding')

        # æ€§èƒ½ä¼˜åŒ–è®¾ç½®
        edge_options.add_argument('--disable-blink-features=AutomationControlled')
        edge_options.add_argument('--disable-features=VizDisplayCompositor')
        edge_options.add_argument('--disable-software-rasterizer')
        edge_options.add_argument('--disable-web-security')

        # ç¦ç”¨å›¾ç‰‡å’ŒJavaScript
        prefs = {
            'profile.default_content_setting_values': {
                'images': 2,  # ç¦ç”¨å›¾ç‰‡
                'javascript': 1,  # å¯ç”¨JavaScriptï¼ˆç ”æ‹›ç½‘éœ€è¦ï¼‰
            }
        }
        edge_options.add_experimental_option('prefs', prefs)

        # åæ£€æµ‹è®¾ç½®
        edge_options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
        edge_options.add_experimental_option('useAutomationExtension', False)
        edge_options.add_argument(
            '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0')

        try:
            driver_path = 'msedgedriver.exe'
            service = Service(driver_path)  # æŒ‡å®šé©±åŠ¨è·¯å¾„
            self.driver = webdriver.Edge(service=service, options=edge_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

            # è¶…æ—¶æ—¶é—´
            self.driver.set_page_load_timeout(35)
            self.driver.set_script_timeout(35)

            # è®¾ç½®éšå¼ç­‰å¾…æ—¶é—´
            self.driver.implicitly_wait(7)

            self.wait = WebDriverWait(self.driver, 10)
            logging.info(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def restart_driver(self):
        """é‡å¯æµè§ˆå™¨é©±åŠ¨"""
        try:
            if hasattr(self, 'driver'):
                self.driver.quit()
        except:
            pass

        time.sleep(5)
        self.setup_driver()
        self.retry_count += 1
        logging.info(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨é©±åŠ¨å·²é‡å¯ï¼Œé‡è¯•æ¬¡æ•°: {self.retry_count}")

    def safe_execute(self, func, *args, **kwargs):
        """å®‰å…¨æ‰§è¡Œå‡½æ•°ï¼Œå¦‚æœä¼šè¯å¤±æ•ˆåˆ™é‡å¯æµè§ˆå™¨"""
        try:
            return func(*args, **kwargs)
        except (InvalidSessionIdException, WebDriverException, TimeoutException) as e:
            if self.retry_count < self.max_retries:
                logging.warning(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨ä¼šè¯å¤±æ•ˆæˆ–è¶…æ—¶ï¼Œå‡†å¤‡é‡å¯: {e}")
                self.restart_driver()
                time.sleep(3)
                return self.safe_execute(func, *args, **kwargs)
            else:
                logging.error(f"çº¿ç¨‹ {self.thread_id} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒæ“ä½œ")
                raise
        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æ‰§è¡Œå‡½æ•°æ—¶å‡ºé”™: {e}")
            raise

    def wait_for_element(self, by, value, timeout=10):
        """ç­‰å¾…å…ƒç´ å‡ºç°"""
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.presence_of_element_located((by, value))
            )
            return element
        except TimeoutException:
            return None

    def wait_for_element_clickable(self, by, value, timeout=10):
        """ç­‰å¾…å…ƒç´ å¯ç‚¹å‡»"""
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.element_to_be_clickable((by, value))
            )
            return element
        except TimeoutException:
            return None

    def crawl_school_majors(self, school_name, major_link=None, region=None, school_features=None,
                            search_type='region'):
        """çˆ¬å–å­¦æ ¡ä¸“ä¸šä¿¡æ¯"""
        return self.safe_execute(self._crawl_school_majors_impl, school_name, major_link, region, school_features,
                                 search_type)

    def _crawl_school_majors_impl(self, school_name, major_link=None, region=None, school_features=None,
                                  search_type='region'):
        """çˆ¬å–å­¦æ ¡ä¸“ä¸šä¿¡æ¯çš„å®ç°"""
        all_majors_data = []

        # é™åˆ¶å…³é”®è¯æ•°é‡ä»¥æé«˜ç¨³å®šæ€§
        search_keywords = [
            "è®¡ç®—æœº", "è½¯ä»¶å·¥ç¨‹", "äººå·¥æ™ºèƒ½", "ç½‘ç»œç©ºé—´å®‰å…¨", "æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯",
            "ä¿¡æ¯å®‰å…¨", "æ•°å­¦", "ç»Ÿè®¡å­¦", "åŒ»å­¦", "è¯å­¦", "æŠ¤ç†å­¦"
        ]

        try:
            logging.info(f"çº¿ç¨‹ {self.thread_id} å¼€å§‹çˆ¬å– {school_name} çš„ä¸“ä¸šä¿¡æ¯")

            if major_link:
                self.driver.get(major_link)
                time.sleep(3)
                current_url = self.driver.current_url
                if "/zsml/dwzy.do" not in current_url:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœªèƒ½è¿›å…¥ä¸“ä¸šé¡µé¢ï¼Œå½“å‰URL: {current_url}")
                    return []
            else:
                self.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
                time.sleep(3)

                school_search_input = self.wait_for_element(
                    By.CSS_SELECTOR, "input[placeholder='è¯·è¾“å…¥æ‹›ç”Ÿå•ä½åç§°']"
                )
                if not school_search_input:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°å­¦æ ¡æœç´¢æ¡†")
                    return []

                school_search_input.clear()
                school_search_input.send_keys(school_name)
                time.sleep(3)

                search_button = self.wait_for_element_clickable(
                    By.CSS_SELECTOR, "button.ivu-btn-primary"
                )
                if search_button:
                    search_button.click()
                    time.sleep(3)
                else:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®")
                    return []

                if self.check_no_results():
                    logging.warning(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°å­¦æ ¡: {school_name}")
                    return []

                # åœ¨å­¦æ ¡æœç´¢æ¨¡å¼ä¸‹ï¼Œæå–åœ°åŒºä¿¡æ¯å’Œé™¢æ ¡ç‰¹æ€§
                if search_type == 'school':
                    region = self.extract_region_from_school_page()
                    if not school_features:
                        school_features = self.extract_school_features_from_page()
                    logging.info(f"çº¿ç¨‹ {self.thread_id} å­¦æ ¡ {school_name} ä½äº {region}ï¼Œé™¢æ ¡ç‰¹æ€§: {school_features}")

                major_button = self.find_major_button()
                if major_button:
                    try:
                        button_href = major_button.get_attribute("href")
                        if button_href and "http" in button_href:
                            self.driver.get(button_href)
                            time.sleep(3)
                    except Exception as e:
                        logging.error(f"çº¿ç¨‹ {self.thread_id} è¿›å…¥ä¸“ä¸šé¡µé¢å¤±è´¥: {e}")
                        return []
                else:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°å¼€è®¾ä¸“ä¸šæŒ‰é’®")
                    return []

            current_url = self.driver.current_url
            if "/zsml/dwzy.do" not in current_url:
                logging.error(f"çº¿ç¨‹ {self.thread_id} ä¸åœ¨ä¸“ä¸šé¡µé¢ï¼Œæ— æ³•ç»§ç»­")
                return []

            original_url = self.driver.current_url

            for keyword in search_keywords:
                logging.info(f"çº¿ç¨‹ {self.thread_id} æœç´¢å…³é”®è¯: {keyword}")
                try:
                    keyword_data = self.search_and_parse_majors(keyword, school_name, original_url, region,
                                                                school_features, search_type)
                    if keyword_data:
                        all_majors_data.extend(keyword_data)
                    time.sleep(2)
                except Exception as e:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœç´¢å…³é”®è¯ {keyword} æ—¶å‡ºé”™: {e}")
                    continue

            # å»é‡å¤„ç†
            unique_majors = {}
            for data in all_majors_data:
                key = f"{data['school_name']}_{data['major_name']}_{data.get('major_code', '')}_{data.get('department', '')}_{data.get('research_direction', '')}"
                if key not in unique_majors:
                    unique_majors[key] = data

            all_majors_data = list(unique_majors.values())
            logging.info(f"çº¿ç¨‹ {self.thread_id} å»é‡åå…±è·å– {len(all_majors_data)} ä¸ªå”¯ä¸€ä¸“ä¸š")

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} çˆ¬å–å­¦æ ¡ {school_name} å¤±è´¥: {e}")

        return all_majors_data

    def search_and_parse_majors(self, keyword, school_name, original_url, region, school_features, search_type):
        """æœç´¢å¹¶è§£æä¸“ä¸šä¿¡æ¯"""
        return self.safe_execute(self._search_and_parse_majors_impl, keyword, school_name, original_url, region,
                                 school_features, search_type)

    def _search_and_parse_majors_impl(self, keyword, school_name, original_url, region, school_features, search_type):
        """æœç´¢å¹¶è§£æä¸“ä¸šä¿¡æ¯çš„å®ç°"""
        majors_data = []

        try:
            search_input = self.wait_for_element(
                By.CSS_SELECTOR, "input.ivu-input.ivu-input-default[placeholder='è¯·è¾“å…¥ä¸“ä¸šåç§°']"
            )
            if not search_input:
                return []

            search_input.clear()
            search_input.send_keys(keyword)
            time.sleep(3)

            try:
                dropdown = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".ivu-select-dropdown"))
                )

                options = dropdown.find_elements(By.CSS_SELECTOR, ".ivu-select-item")

                logging.info(f"çº¿ç¨‹ {self.thread_id} å…³é”®è¯ '{keyword}' æ‰¾åˆ° {len(options)} ä¸ªé€‰é¡¹ï¼Œå°†å¤„ç†æ‰€æœ‰é€‰é¡¹")

                for i in range(len(options)):
                    try:
                        search_input = self.wait_for_element(
                            By.CSS_SELECTOR, "input.ivu-input.ivu-input-default[placeholder='è¯·è¾“å…¥ä¸“ä¸šåç§°']"
                        )
                        if not search_input:
                            continue

                        search_input.clear()
                        search_input.send_keys(keyword)
                        time.sleep(3)

                        dropdown = WebDriverWait(self.driver, 10).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, ".ivu-select-dropdown"))
                        )

                        current_options = dropdown.find_elements(By.CSS_SELECTOR, ".ivu-select-item")
                        if i < len(current_options):
                            current_option = current_options[i]
                            option_text = current_option.text.strip()

                            logging.info(f"çº¿ç¨‹ {self.thread_id} å¤„ç†é€‰é¡¹ {i + 1}/{len(options)}: {option_text}")

                            self.driver.execute_script("arguments[0].click();", current_option)
                            time.sleep(3)

                            page_data = self.parse_current_page_majors(school_name, keyword, option_text, region,
                                                                       school_features, search_type)
                            if page_data:
                                majors_data.extend(page_data)
                                logging.info(
                                    f"çº¿ç¨‹ {self.thread_id} é€‰é¡¹ '{option_text}' è·å–åˆ° {len(page_data)} æ¡æ•°æ®")

                            self.driver.get(original_url)
                            time.sleep(3)

                    except StaleElementReferenceException:
                        logging.warning(f"çº¿ç¨‹ {self.thread_id} é€‰é¡¹ {i} å…ƒç´ å¤±æ•ˆï¼Œè·³è¿‡")
                        continue
                    except Exception as e:
                        logging.error(f"çº¿ç¨‹ {self.thread_id} å¤„ç†é€‰é¡¹ {i} æ—¶å‡ºé”™: {e}")
                        try:
                            self.driver.get(original_url)
                            time.sleep(3)
                        except:
                            pass
                        continue

            except TimeoutException:
                # å¦‚æœæ²¡æœ‰ä¸‹æ‹‰é€‰é¡¹ï¼Œç›´æ¥æœç´¢
                logging.info(f"çº¿ç¨‹ {self.thread_id} å…³é”®è¯ '{keyword}' æ²¡æœ‰ä¸‹æ‹‰é€‰é¡¹ï¼Œç›´æ¥æœç´¢")
                search_button = self.wait_for_element_clickable(
                    By.CSS_SELECTOR, "button.ivu-btn-primary"
                )
                if search_button:
                    search_button.click()
                    time.sleep(3)

                    page_data = self.parse_current_page_majors(school_name, keyword, keyword, region,
                                                               school_features, search_type)
                    if page_data:
                        majors_data.extend(page_data)
                        logging.info(f"çº¿ç¨‹ {self.thread_id} ç›´æ¥æœç´¢è·å–åˆ° {len(page_data)} æ¡æ•°æ®")

                    self.driver.get(original_url)
                    time.sleep(3)

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æœç´¢ä¸“ä¸š {keyword} å¤±è´¥: {e}")

        logging.info(f"çº¿ç¨‹ {self.thread_id} å…³é”®è¯ '{keyword}' å…±è·å– {len(majors_data)} æ¡æ•°æ®")
        return majors_data

    def parse_current_page_majors(self, school_name, keyword, option_text, region, school_features, search_type):
        """è§£æå½“å‰é¡µé¢çš„ä¸“ä¸šä¿¡æ¯"""
        return self.safe_execute(self._parse_current_page_majors_impl, school_name, keyword, option_text, region,
                                 school_features, search_type)

    def _parse_current_page_majors_impl(self, school_name, keyword, option_text, region, school_features, search_type):
        """è§£æå½“å‰é¡µé¢ä¸“ä¸šä¿¡æ¯çš„å®ç°"""
        majors_data = []

        try:
            self.expand_all_major_details()
            time.sleep(2)

            major_items = self.driver.find_elements(By.CSS_SELECTOR, ".zy-item")

            logging.info(f"çº¿ç¨‹ {self.thread_id} æ‰¾åˆ° {len(major_items)} ä¸ªä¸“ä¸šé¡¹ç›®ï¼Œå°†å¤„ç†æ‰€æœ‰é¡¹ç›®")

            for item in major_items:
                try:
                    major_data = self.extract_major_basic_info(item)
                    if major_data and self.is_target_major(major_data['major_name']):
                        detailed_data_list = self.get_all_research_directions(item, school_name)

                        if detailed_data_list:
                            for detailed_data in detailed_data_list:
                                combined_data = major_data.copy()
                                combined_data.update(detailed_data)
                                combined_data.update({
                                    'school_name': school_name,
                                    'search_keyword': keyword,
                                    'selected_option': option_text,
                                    'region': region,
                                    'school_features': ', '.join(school_features) if school_features else '',
                                    'search_type': search_type,
                                    'data_source': f"ç ”æ‹›ç½‘æœç´¢ - {school_name} - {keyword} - é€‰é¡¹: {option_text}"
                                })
                                majors_data.append(combined_data)
                        else:
                            detailed_data = self.get_major_details_from_detail_page(item, school_name)
                            major_data.update(detailed_data)
                            major_data.update({
                                'school_name': school_name,
                                'search_keyword': keyword,
                                'selected_option': option_text,
                                'region': region,
                                'school_features': ', '.join(school_features) if school_features else '',
                                'search_type': search_type,
                                'data_source': f"ç ”æ‹›ç½‘æœç´¢ - {school_name} - {keyword} - é€‰é¡¹: {option_text}"
                            })
                            majors_data.append(major_data)

                except Exception as e:
                    logging.debug(f"çº¿ç¨‹ {self.thread_id} å¤„ç†ä¸“ä¸šé¡¹ç›®æ—¶å‡ºé”™: {e}")
                    continue

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} è§£æé¡µé¢ä¸“ä¸šå¤±è´¥: {e}")

        logging.info(f"çº¿ç¨‹ {self.thread_id} å½“å‰é¡µé¢è§£æåˆ° {len(majors_data)} ä¸ªä¸“ä¸š")
        return majors_data

    def is_target_major(self, text):
        """æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡ä¸“ä¸š"""
        if not text:
            return False

        target_keywords = [
            "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯", "è½¯ä»¶å·¥ç¨‹", "äººå·¥æ™ºèƒ½", "ç½‘ç»œç©ºé—´å®‰å…¨", "æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯",
            "è®¡ç®—æœºåº”ç”¨æŠ€æœ¯", "ä¿¡æ¯å®‰å…¨", "ç‰©è”ç½‘å·¥ç¨‹", "æ•°å­—åª’ä½“æŠ€æœ¯", "äº‘è®¡ç®—æŠ€æœ¯ä¸åº”ç”¨",
            "åŒºå—é“¾å·¥ç¨‹", "è®¡ç®—æœºç³»ç»Ÿç»“æ„", "è®¡ç®—æœºè½¯ä»¶ä¸ç†è®º", "æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯", "ç½‘ç»œå·¥ç¨‹",
            "æ•°å­¦ä¸åº”ç”¨æ•°å­¦", "ä¿¡æ¯ä¸è®¡ç®—ç§‘å­¦", "æ•°ç†åŸºç¡€ç§‘å­¦", "åº”ç”¨æ•°å­¦", "è®¡ç®—æ•°å­¦",
            "æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡", "è¿ç­¹å­¦ä¸æ§åˆ¶è®º", "åŸºç¡€æ•°å­¦", "ç»Ÿè®¡å­¦", "æ•°æ®è®¡ç®—åŠåº”ç”¨",
            "æ•°å­¦æ•™è‚²", "é‡‘èæ•°å­¦", "åº”ç”¨ç»Ÿè®¡å­¦", "è®¡é‡ç»æµå­¦", "æ•°å­¦å»ºæ¨¡",
            "ä¸´åºŠåŒ»å­¦", "åŸºç¡€åŒ»å­¦", "è¯å­¦", "æŠ¤ç†å­¦", "ä¸­åŒ»å­¦", "ä¸­è¯å­¦", "å£è…”åŒ»å­¦",
            "é¢„é˜²åŒ»å­¦", "å…¬å…±å«ç”Ÿä¸é¢„é˜²åŒ»å­¦", "åŒ»å­¦å½±åƒå­¦", "åŒ»å­¦æ£€éªŒæŠ€æœ¯", "ç”Ÿç‰©åŒ»å­¦å·¥ç¨‹",
            "ä¸­è¥¿åŒ»ä¸´åºŠåŒ»å­¦", "è¯å­¦ï¼ˆä¸´åºŠè¯å­¦ï¼‰", "éº»é†‰å­¦", "å„¿ç§‘å­¦", "çœ¼è§†å…‰åŒ»å­¦",
            "ç²¾ç¥åŒ»å­¦", "åº·å¤æ²»ç–—å­¦", "é’ˆç¸æ¨æ‹¿å­¦", "åˆ¶è¯å·¥ç¨‹", "è¯äº‹ç®¡ç†"
        ]

        text_lower = text.lower()
        return any(keyword in text_lower for keyword in target_keywords)

    def get_all_research_directions(self, item, school_name):
        """è·å–ä¸“ä¸šçš„æ‰€æœ‰ç ”ç©¶æ–¹å‘"""
        detailed_data_list = []

        try:
            table_rows = item.find_elements(By.CSS_SELECTOR, ".ivu-table-row")
            logging.debug(f"çº¿ç¨‹ {self.thread_id} æ‰¾åˆ° {len(table_rows)} ä¸ªç ”ç©¶æ–¹å‘")

            for row in table_rows:
                try:
                    department = self.extract_text_from_row(row, [
                        "td:nth-child(1)",
                        ".ivu-table-column-kC7Bg7",
                        ".ivu-table-column-gqsUra"
                    ])

                    research_direction = self.extract_text_from_row(row, [
                        "td:nth-child(4)",
                        ".ivu-table-column-AEYuj3",
                        ".ivu-table-column-Mb3vDC"
                    ])

                    exam_data = self.extract_exam_subjects_from_row(row)
                    enrollment_plan = self.extract_enrollment_plan_from_row(row)

                    if not enrollment_plan or not any(exam_data.values()):
                        detail_data = self.get_research_direction_details(row, school_name)
                        if detail_data:
                            if not enrollment_plan and detail_data.get('enrollment_plan'):
                                enrollment_plan = detail_data['enrollment_plan']
                            if not any(exam_data.values()) and any(detail_data.get(key) for key in
                                                                   ['politics_subject', 'foreign_language_subject',
                                                                    'business_subject1', 'business_subject2']):
                                exam_data = {k: detail_data.get(k, v) for k, v in exam_data.items()}

                    detailed_data = {
                        'department': department,
                        'research_direction': research_direction,
                        'enrollment_plan': enrollment_plan,
                        **exam_data
                    }

                    detailed_data_list.append(detailed_data)

                except Exception as e:
                    logging.debug(f"çº¿ç¨‹ {self.thread_id} å¤„ç†ç ”ç©¶æ–¹å‘æ—¶å‡ºé”™: {e}")
                    continue

        except Exception as e:
            logging.debug(f"çº¿ç¨‹ {self.thread_id} è·å–ç ”ç©¶æ–¹å‘å¤±è´¥: {e}")

        return detailed_data_list

    def get_research_direction_details(self, row, school_name):
        """è·å–å•ä¸ªç ”ç©¶æ–¹å‘çš„è¯¦ç»†ä¿¡æ¯"""
        details = {
            'enrollment_plan': '',
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            detail_links = row.find_elements(By.CSS_SELECTOR, "a[href*='/zsml/yjfxdetail']")
            if not detail_links:
                return details

            for detail_link in detail_links:
                try:
                    detail_url = detail_link.get_attribute("href")
                    if detail_url:
                        if not detail_url.startswith('http'):
                            detail_url = 'https://yz.chsi.com.cn' + detail_url

                        original_window = self.driver.current_window_handle
                        self.driver.execute_script("window.open(arguments[0]);", detail_url)
                        time.sleep(4)

                        new_window = [w for w in self.driver.window_handles if w != original_window][0]
                        self.driver.switch_to.window(new_window)
                        time.sleep(4)

                        if "ç™»å½•" in self.driver.title or "é”™è¯¯" in self.driver.title:
                            pass
                        else:
                            page_details = self.parse_detail_page()
                            details.update(page_details)

                        self.driver.close()
                        self.driver.switch_to.window(original_window)
                        time.sleep(3)
                        break

                except Exception as e:
                    try:
                        self.driver.switch_to.window(original_window)
                    except:
                        pass
                    continue

        except Exception as e:
            pass

        return details

    def extract_text_from_row(self, row, selectors):
        """ä»è¡¨æ ¼è¡Œä¸­æå–æ–‡æœ¬"""
        for selector in selectors:
            try:
                element = row.find_element(By.CSS_SELECTOR, selector)
                text = element.text.strip()
                if text:
                    return text
            except:
                continue
        return ""

    def extract_exam_subjects_from_row(self, row):
        """ä»è¡¨æ ¼è¡Œä¸­æå–è€ƒè¯•ç§‘ç›®ä¿¡æ¯"""
        exam_data = {
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            exam_buttons = row.find_elements(By.CSS_SELECTOR,
                                             "a[href*='javascript:;'], .ivu-table-column-xA7jhY a, td:nth-child(9) a")

            for button in exam_buttons:
                if "æŸ¥çœ‹" in button.text:
                    try:
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(2)

                        popup = self.wait_for_element(By.CSS_SELECTOR,
                                                      ".ivu-poptip-popper, .ivu-tooltip-popper, .kskm-modal")

                        if popup:
                            self.parse_exam_popup_content(popup, exam_data)
                            self.close_popup()
                            break

                    except Exception as e:
                        continue

        except Exception as e:
            pass

        return exam_data

    def parse_exam_popup_content(self, popup, exam_data):
        """è§£æè€ƒè¯•ç§‘ç›®å¼¹å‡ºçª—å£å†…å®¹"""
        try:
            # æŸ¥æ‰¾kskm-itemç»“æ„
            kskm_items = popup.find_elements(By.CSS_SELECTOR, ".kskm-item")
            if kskm_items:
                # å–ç¬¬ä¸€ä¸ªè€ƒè¯•ç§‘ç›®ç»„åˆ
                first_kskm = kskm_items[0]

                # è·å–ç§‘ç›®ç±»å‹å’Œè¯¦æƒ…
                kskm_types = first_kskm.find_elements(By.CSS_SELECTOR, ".kskm-type .item")
                kskm_details = first_kskm.find_elements(By.CSS_SELECTOR, ".kskm-detail .item")

                # æŒ‰é¡ºåºåŒ¹é…ç§‘ç›®
                for i in range(min(len(kskm_types), len(kskm_details))):
                    subject_type = kskm_types[i].text.strip()
                    subject_detail = kskm_details[i].text.strip()

                    # æ¸…ç†è¯¦æƒ…æ–‡æœ¬
                    clean_detail = re.sub(r'è§æ‹›ç”Ÿç®€ç« |æŸ¥çœ‹è¯¦æƒ…', '', subject_detail).strip()

                    if subject_type == 'æ”¿æ²»':
                        exam_data['politics_subject'] = clean_detail
                    elif subject_type == 'å¤–è¯­':
                        exam_data['foreign_language_subject'] = clean_detail
                    elif subject_type == 'ä¸šåŠ¡è¯¾ä¸€':
                        exam_data['business_subject1'] = clean_detail
                    elif subject_type == 'ä¸šåŠ¡è¯¾äºŒ':
                        exam_data['business_subject2'] = clean_detail
                return

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°kskm-itemç»“æ„ï¼Œå°è¯•å…¶ä»–æ–¹å¼
            kskm_details = popup.find_elements(By.CSS_SELECTOR, ".kskm-detail .item")
            if kskm_details:
                # æŒ‰é¡ºåºæå–ç§‘ç›®
                for i, item in enumerate(kskm_details):
                    text = item.text.strip()
                    if not text:
                        continue

                    clean_text = re.sub(r'è§æ‹›ç”Ÿç®€ç« |æŸ¥çœ‹è¯¦æƒ…', '', text).strip()

                    if i == 0:  # ç¬¬ä¸€ä¸ªé€šå¸¸æ˜¯æ”¿æ²»
                        exam_data['politics_subject'] = clean_text
                    elif i == 1:  # ç¬¬äºŒä¸ªé€šå¸¸æ˜¯å¤–è¯­
                        exam_data['foreign_language_subject'] = clean_text
                    elif i == 2:  # ç¬¬ä¸‰ä¸ªé€šå¸¸æ˜¯ä¸šåŠ¡è¯¾ä¸€
                        exam_data['business_subject1'] = clean_text
                    elif i == 3:  # ç¬¬å››ä¸ªé€šå¸¸æ˜¯ä¸šåŠ¡è¯¾äºŒ
                        exam_data['business_subject2'] = clean_text
                return

            # æœ€åå°è¯•æŒ‰æ–‡æœ¬è§£æ
            popup_text = popup.text
            lines = [line.strip() for line in popup_text.split('\n') if line.strip()]

            for i, line in enumerate(lines):
                if i == 0 or 'æ€æƒ³æ”¿æ²»' in line or '(101)' in line:
                    exam_data['politics_subject'] = line
                elif i == 1 or any(keyword in line for keyword in
                                   ['è‹±è¯­', 'æ—¥è¯­', 'ä¿„è¯­', 'å¾·è¯­', 'æ³•è¯­', '(201)', '(202)', '(203)', '(204)']):
                    exam_data['foreign_language_subject'] = line
                elif i == 2 or 'ä¸šåŠ¡è¯¾ä¸€' in line or 'ä¸“ä¸šè¯¾ä¸€' in line:
                    exam_data['business_subject1'] = line
                elif i == 3 or 'ä¸šåŠ¡è¯¾äºŒ' in line or 'ä¸“ä¸šè¯¾äºŒ' in line:
                    exam_data['business_subject2'] = line

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} è§£æè€ƒè¯•ç§‘ç›®å¼¹å‡ºæ¡†å¤±è´¥: {e}")

    def extract_enrollment_plan_from_row(self, row):
        """ä»è¡¨æ ¼è¡Œä¸­æå–æ‹Ÿæ‹›ç”Ÿäººæ•°"""
        enrollment_plan = ""

        try:
            plan_buttons = row.find_elements(By.CSS_SELECTOR,
                                             ".ivu-table-column-Ln8auZ a, .ivu-table-column-4bER4t a, td:nth-child(8) a")

            for button in plan_buttons:
                if "æŸ¥çœ‹" in button.text:
                    try:
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(4)

                        popup = self.wait_for_element(By.CSS_SELECTOR,
                                                      ".ivu-tooltip-popper, .ivu-poptip-popper")

                        if popup:
                            plan_text = popup.text.strip()

                            match = re.search(r'ä¸“ä¸šï¼š\s*(\d+)', plan_text)
                            if match:
                                enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"
                            else:
                                match = re.search(r'(\d+)\s*\(ä¸å«æ¨å…\)', plan_text)
                                if match:
                                    enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"
                                else:
                                    match = re.search(r'(\d+)', plan_text)
                                    if match:
                                        enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"
                                    else:
                                        enrollment_plan = plan_text

                            self.close_popup()
                            break

                    except Exception as e:
                        continue

        except Exception as e:
            pass

        return enrollment_plan

    def close_popup(self):
        """å…³é—­å¼¹å‡ºçª—å£"""
        try:
            body = self.driver.find_element(By.TAG_NAME, "body")
            body.click()
            time.sleep(2)
        except:
            pass

    def extract_major_basic_info(self, item):
        """æå–ä¸“ä¸šåŸºæœ¬ä¿¡æ¯"""
        try:
            name_elem = item.find_element(By.CSS_SELECTOR, ".zy-name")
            name_text = name_elem.text.strip()

            if not name_text:
                return None

            code_match = re.search(r'\((\d+)\)', name_text)
            major_code = code_match.group(1) if code_match else ""
            major_name = re.sub(r'\(\d+\)', '', name_text).strip()

            if not major_name:
                return None

            degree_type = ""
            try:
                # æå–å­¦ä½ç±»å‹ - å­¦æœ¯å­¦ä½æˆ–ä¸“ä¸šå­¦ä½
                degree_elem = item.find_element(By.CSS_SELECTOR, ".zy-tag.xs, .zy-tag.zs")
                degree_type = degree_elem.text.strip()
            except:
                # å¦‚æœæ‰¾ä¸åˆ°æ˜ç¡®çš„å­¦ä½æ ‡ç­¾ï¼Œå°è¯•ä»ä¸“ä¸šåç§°åˆ¤æ–­
                if "ä¸“ä¸šå­¦ä½" in name_text:
                    degree_type = "ä¸“ä¸šå­¦ä½"
                elif "å­¦æœ¯å­¦ä½" in name_text:
                    degree_type = "å­¦æœ¯å­¦ä½"
                else:
                    # æ ¹æ®ä¸“ä¸šä»£ç åˆ¤æ–­ï¼ˆ085å¼€å¤´é€šå¸¸æ˜¯ä¸“ä¸šå­¦ä½ï¼‰
                    if major_code and major_code.startswith('085'):
                        degree_type = "ä¸“ä¸šå­¦ä½"
                    else:
                        degree_type = "å­¦æœ¯å­¦ä½"

            return {
                'major_name': major_name,
                'major_code': major_code,
                'degree_type': degree_type
            }

        except Exception as e:
            return None

    def get_major_details_from_detail_page(self, item, school_name):
        """ä»è¯¦æƒ…é¡µé¢è·å–ä¸“ä¸šè¯¦ç»†ä¿¡æ¯"""
        details = {
            'enrollment_plan': '',
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            detail_links = item.find_elements(By.CSS_SELECTOR,
                                              "a[href*='/zsml/queryYjfx'], a[href*='/zsml/yjfxdetail']")

            if detail_links:
                for detail_link in detail_links:
                    try:
                        detail_url = detail_link.get_attribute("href")
                        if detail_url:
                            if not detail_url.startswith('http'):
                                detail_url = 'https://yz.chsi.com.cn' + detail_url

                            original_window = self.driver.current_window_handle
                            self.driver.execute_script("window.open(arguments[0]);", detail_url)
                            time.sleep(4)

                            new_window = [w for w in self.driver.window_handles if w != original_window][0]
                            self.driver.switch_to.window(new_window)
                            time.sleep(4)

                            if "ç™»å½•" in self.driver.title or "é”™è¯¯" in self.driver.title:
                                pass
                            else:
                                page_details = self.parse_detail_page()
                                details.update(page_details)

                            self.driver.close()
                            self.driver.switch_to.window(original_window)
                            time.sleep(3)
                            break

                    except Exception as e:
                        try:
                            self.driver.switch_to.window(original_window)
                        except:
                            pass
                        continue

        except Exception as e:
            pass

        return details

    def parse_detail_page(self):
        """è§£æè¯¦æƒ…é¡µé¢"""
        details = {
            'enrollment_plan': '',
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            time.sleep(4)

            enrollment_plan = self.extract_enrollment_plan_from_detail_page()
            if enrollment_plan:
                details['enrollment_plan'] = enrollment_plan

            exam_data = self.extract_exam_subjects_from_detail_page()
            details.update(exam_data)

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} è§£æè¯¦æƒ…é¡µé¢å¤±è´¥: {e}")

        return details

    def extract_enrollment_plan_from_detail_page(self):
        """ä»è¯¦æƒ…é¡µé¢æå–æ‹Ÿæ‹›ç”Ÿäººæ•°"""
        enrollment_plan = ""

        try:
            selectors = [
                "//div[contains(@class, 'item') and contains(., 'æ‹Ÿæ‹›ç”Ÿäººæ•°')]//div[contains(@class, 'value')]",
                "//div[contains(text(), 'æ‹Ÿæ‹›ç”Ÿäººæ•°ï¼š')]/following-sibling::div",
                "//*[contains(text(), 'ä¸“ä¸šï¼š')]",
                ".enrollment-plan",
                ".value"
            ]

            for selector in selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        text = element.text.strip()
                        if "ä¸“ä¸šï¼š" in text:
                            match = re.search(r'ä¸“ä¸šï¼š\s*(\d+)', text)
                            if match:
                                enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"
                                break
                        elif text and re.search(r'\d+', text):
                            match = re.search(r'(\d+)', text)
                            if match:
                                enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"
                                break

                    if enrollment_plan:
                        break
                except:
                    continue

            if not enrollment_plan:
                page_text = self.driver.page_source
                match = re.search(r'ä¸“ä¸šï¼š\s*(\d+)', page_text)
                if match:
                    enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"

        except Exception as e:
            pass

        return enrollment_plan

    def extract_exam_subjects_from_detail_page(self):
        """ä»è¯¦æƒ…é¡µé¢æå–è€ƒè¯•ç§‘ç›®ä¿¡æ¯"""
        exam_data = {
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            # é¦–å…ˆæŸ¥æ‰¾kskm-detail-listç»“æ„
            kskm_lists = self.driver.find_elements(By.CSS_SELECTOR, ".kskm-detail-list")
            for kskm_list in kskm_lists:
                kskm_items = kskm_list.find_elements(By.CSS_SELECTOR, ".kskm-item")
                if kskm_items:
                    # å–ç¬¬ä¸€ä¸ªè€ƒè¯•ç§‘ç›®ç»„åˆ
                    first_kskm = kskm_items[0]

                    # è·å–ç§‘ç›®ç±»å‹å’Œè¯¦æƒ…
                    kskm_types = first_kskm.find_elements(By.CSS_SELECTOR, ".kskm-type .item")
                    kskm_details = first_kskm.find_elements(By.CSS_SELECTOR, ".kskm-detail .item")

                    # æŒ‰é¡ºåºåŒ¹é…ç§‘ç›®
                    for i in range(min(len(kskm_types), len(kskm_details))):
                        subject_type = kskm_types[i].text.strip()
                        subject_detail = kskm_details[i].text.strip()

                        # æ¸…ç†è¯¦æƒ…æ–‡æœ¬
                        clean_detail = re.sub(r'è§æ‹›ç”Ÿç®€ç« |æŸ¥çœ‹è¯¦æƒ…', '', subject_detail).strip()

                        if subject_type == 'æ”¿æ²»':
                            exam_data['politics_subject'] = clean_detail
                        elif subject_type == 'å¤–è¯­':
                            exam_data['foreign_language_subject'] = clean_detail
                        elif subject_type == 'ä¸šåŠ¡è¯¾ä¸€':
                            exam_data['business_subject1'] = clean_detail
                        elif subject_type == 'ä¸šåŠ¡è¯¾äºŒ':
                            exam_data['business_subject2'] = clean_detail
                    break

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°kskm-detail-listï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨
            if not any(exam_data.values()):
                kskm_selectors = [
                    ".kskm-item",
                    ".exam-subjects",
                    "[class*='kskm']"
                ]

                for selector in kskm_selectors:
                    try:
                        kskm_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if kskm_elements:
                            for element in kskm_elements:
                                text = element.text
                                lines = text.split('\n')

                                for i, line in enumerate(lines):
                                    line = line.strip()
                                    if not line:
                                        continue

                                    if i == 0 or 'æ€æƒ³æ”¿æ²»' in line or '(101)' in line:
                                        exam_data['politics_subject'] = line
                                    elif i == 1 or any(keyword in line for keyword in
                                                       ['è‹±è¯­', 'æ—¥è¯­', 'ä¿„è¯­', 'å¾·è¯­', 'æ³•è¯­', '(201)', '(202)',
                                                        '(203)',
                                                        '(204)']):
                                        exam_data['foreign_language_subject'] = line
                                    elif i == 2 or 'ä¸šåŠ¡è¯¾ä¸€' in line or 'ä¸“ä¸šè¯¾ä¸€' in line:
                                        exam_data['business_subject1'] = line
                                    elif i == 3 or 'ä¸šåŠ¡è¯¾äºŒ' in line or 'ä¸“ä¸šè¯¾äºŒ' in line:
                                        exam_data['business_subject2'] = line

                            if any(exam_data.values()):
                                break
                    except:
                        continue

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æå–è€ƒè¯•ç§‘ç›®å¤±è´¥: {e}")

        return exam_data

    def extract_region_from_school_page(self):
        """ä»å­¦æ ¡é¡µé¢æå–åœ°åŒºä¿¡æ¯"""
        try:
            region_selectors = [
                ".yx-area",
                ".yx-detail-info .yx-area",
                "//div[contains(@class, 'yx-area')]",
                "//div[contains(text(), 'æ¹–åŒ—') or contains(text(), 'åŒ—äº¬') or contains(text(), 'ä¸Šæµ·') or contains(text(), 'å¤©æ´¥') or contains(text(), 'é‡åº†') or contains(text(), 'æ²³åŒ—') or contains(text(), 'å±±è¥¿') or contains(text(), 'è¾½å®') or contains(text(), 'å‰æ—') or contains(text(), 'é»‘é¾™æ±Ÿ') or contains(text(), 'æ±Ÿè‹') or contains(text(), 'æµ™æ±Ÿ') or contains(text(), 'å®‰å¾½') or contains(text(), 'ç¦å»º') or contains(text(), 'æ±Ÿè¥¿') or contains(text(), 'å±±ä¸œ') or contains(text(), 'æ²³å—') or contains(text(), 'æ¹–åŒ—') or contains(text(), 'æ¹–å—') or contains(text(), 'å¹¿ä¸œ') or contains(text(), 'æµ·å—') or contains(text(), 'å››å·') or contains(text(), 'è´µå·') or contains(text(), 'äº‘å—') or contains(text(), 'é™•è¥¿') or contains(text(), 'ç”˜è‚ƒ') or contains(text(), 'é’æµ·') or contains(text(), 'å°æ¹¾') or contains(text(), 'å†…è’™å¤') or contains(text(), 'å¹¿è¥¿') or contains(text(), 'è¥¿è—') or contains(text(), 'å®å¤') or contains(text(), 'æ–°ç–†') or contains(text(), 'é¦™æ¸¯') or contains(text(), 'æ¾³é—¨')]"
            ]

            for selector in region_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        text = element.text.strip()
                        if text and len(text) <= 10:
                            clean_text = re.sub(r'[^\u4e00-\u9fa5]', '', text)
                            if clean_text and len(clean_text) >= 2:
                                logging.info(f"çº¿ç¨‹ {self.thread_id} æå–åˆ°åœ°åŒºä¿¡æ¯: {clean_text}")
                                return clean_text
                except:
                    continue

            page_text = self.driver.page_source
            region_patterns = [
                r'<div class="yx-area"[^>]*>.*?([\u4e00-\u9fa5]{2,10})</div>',
                r'æ‰€åœ¨åœ°.*?([\u4e00-\u9fa5]{2,10})',
                r'åœ°åŒº.*?([\u4e00-\u9fa5]{2,10})'
            ]

            for pattern in region_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    region = match.group(1)
                    logging.info(f"çº¿ç¨‹ {self.thread_id} ä»é¡µé¢æºç æå–åˆ°åœ°åŒºä¿¡æ¯: {region}")
                    return region

            return "æœªçŸ¥"
        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æå–åœ°åŒºä¿¡æ¯å¤±è´¥: {e}")
            return "æœªçŸ¥"

    def extract_school_features_from_page(self):
        """ä»å­¦æ ¡é¡µé¢æå–é™¢æ ¡ç‰¹æ€§"""
        try:
            features = []
            feature_selectors = [
                ".yx-tag",
                ".yx-tags .yx-tag",
                "//div[contains(@class, 'yx-tag')]"
            ]

            for selector in feature_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        text = element.text.strip()
                        if text and "åšå£«ç‚¹" in text:
                            features.append("åšå£«ç‚¹")
                        elif text and "åŒä¸€æµ" in text:
                            features.append("åŒä¸€æµå»ºè®¾é«˜æ ¡")
                        elif text and "è‡ªåˆ’çº¿" in text:
                            features.append("è‡ªåˆ’çº¿é™¢æ ¡")
                        elif text and text not in features:
                            features.append(text)
                except:
                    continue

            return list(set(features))
        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æå–é™¢æ ¡ç‰¹æ€§å¤±è´¥: {e}")
            return []

    def expand_all_major_details(self):
        """å±•å¼€æ‰€æœ‰ä¸“ä¸šè¯¦ç»†ä¿¡æ¯"""
        try:
            expand_buttons = self.driver.find_elements(By.CSS_SELECTOR,
                                                       ".show-more, [class*='expand'], [class*='more']")
            expanded_count = 0

            for button in expand_buttons:
                try:
                    if button.is_displayed() and ("å±•å¼€" in button.text or "è¯¦æƒ…" in button.text):
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(1)
                        expanded_count += 1
                except:
                    continue

            return expanded_count > 0

        except Exception as e:
            return False

    def find_major_button(self):
        """æŸ¥æ‰¾å¼€è®¾ä¸“ä¸šæŒ‰é’®"""
        button_selectors = [
            "a.zy-btn.ivu-btn.ivu-btn-primary",
            "a.zy-btn",
            "a[class*='zy-btn']",
            "//a[contains(@class, 'zy-btn')]",
            "//a[contains(@href, '/zsml/dwzy.do')]",
            "//span[contains(text(), 'å¼€è®¾ä¸“ä¸š')]/parent::a",
            "//a[.//span[contains(text(), 'å¼€è®¾ä¸“ä¸š')]]",
            "//a[contains(text(), 'å¼€è®¾ä¸“ä¸š')]"
        ]

        for selector in button_selectors:
            try:
                if selector.startswith("//"):
                    button = self.driver.find_element(By.XPATH, selector)
                else:
                    button = self.driver.find_element(By.CSS_SELECTOR, selector)

                if button.is_displayed():
                    return button
            except:
                continue

        return None

    def check_no_results(self):
        """æ£€æŸ¥æ˜¯å¦æ²¡æœ‰ç»“æœ"""
        try:
            no_data_indicators = [
                "//*[contains(text(), 'æš‚æ— æ•°æ®')]",
                "//*[contains(text(), 'æ²¡æœ‰æ‰¾åˆ°')]",
                "//*[contains(text(), 'æœªæŸ¥è¯¢åˆ°')]",
                "//*[contains(text(), 'æ— ç›¸å…³ç»“æœ')]"
            ]

            for indicator in no_data_indicators:
                try:
                    no_data = self.driver.find_element(By.XPATH, indicator)
                    if no_data and no_data.is_displayed():
                        return True
                except:
                    continue
            return False
        except:
            return False

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if hasattr(self, 'driver'):
            try:
                self.driver.quit()
                logging.info(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨å·²å…³é—­")
            except:
                pass


class CompleteInfoSpider:
    def __init__(self, username=None, password=None, max_workers=2):
        self.username = username
        self.password = password
        self.is_logged_in = False
        self.max_workers = max_workers
        self.lock = threading.Lock()
        self.excel_filename = f'å®Œæ•´ä¿¡æ¯_è€ƒç ”ä¸“ä¸šä¿¡æ¯-{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'

        self.check_and_create_tables()
        self.init_excel_file()

    def init_excel_file(self):
        """åˆå§‹åŒ–Excelæ–‡ä»¶"""
        try:
            df = pd.DataFrame(columns=[
                'å­¦æ ¡', 'ä¸“ä¸šåç§°', 'ä¸“ä¸šä»£ç ', 'é™¢ç³»', 'ç ”ç©¶æ–¹å‘',
                'æ”¿æ²»ç§‘ç›®', 'å¤–è¯­ç§‘ç›®', 'ä¸šåŠ¡è¯¾ä¸€', 'ä¸šåŠ¡è¯¾äºŒ',
                'æ‹Ÿæ‹›ç”Ÿäººæ•°', 'åœ°åŒº', 'é™¢æ ¡ç‰¹æ€§', 'å­¦ä½ç±»å‹',
                'æœç´¢å…³é”®è¯', 'é€‰æ‹©é€‰é¡¹', 'æ•°æ®æ¥æº'
            ])
            df.to_excel(self.excel_filename, index=False, engine='openpyxl')
            logging.info(f"Excelæ–‡ä»¶å·²åˆå§‹åŒ–: {self.excel_filename}")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–Excelæ–‡ä»¶å¤±è´¥: {e}")

    def append_to_excel(self, data_list):
        """è¿½åŠ æ•°æ®åˆ°Excelæ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        if not data_list:
            return

        with self.lock:
            try:
                # è¯»å–ç°æœ‰æ•°æ®
                try:
                    existing_df = pd.read_excel(self.excel_filename, engine='openpyxl')
                except:
                    existing_df = pd.DataFrame()

                # åˆ›å»ºæ–°æ•°æ®æ¡†
                new_data = []
                for data in data_list:
                    new_data.append({
                        'å­¦æ ¡': data['school_name'],
                        'ä¸“ä¸šåç§°': data['major_name'],
                        'ä¸“ä¸šä»£ç ': data.get('major_code', ''),
                        'é™¢ç³»': data.get('department', ''),
                        'ç ”ç©¶æ–¹å‘': data.get('research_direction', ''),
                        'æ”¿æ²»ç§‘ç›®': data.get('politics_subject', ''),
                        'å¤–è¯­ç§‘ç›®': data.get('foreign_language_subject', ''),
                        'ä¸šåŠ¡è¯¾ä¸€': data.get('business_subject1', ''),
                        'ä¸šåŠ¡è¯¾äºŒ': data.get('business_subject2', ''),
                        'æ‹Ÿæ‹›ç”Ÿäººæ•°': data.get('enrollment_plan', ''),
                        'åœ°åŒº': data.get('region', ''),
                        'é™¢æ ¡ç‰¹æ€§': data.get('school_features', ''),
                        'å­¦ä½ç±»å‹': data.get('degree_type', ''),
                        'æœç´¢å…³é”®è¯': data.get('search_keyword', ''),
                        'é€‰æ‹©é€‰é¡¹': data.get('selected_option', ''),
                        'æ•°æ®æ¥æº': data['data_source']
                    })

                new_df = pd.DataFrame(new_data)

                # åˆå¹¶æ•°æ®
                if not existing_df.empty:
                    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                else:
                    combined_df = new_df

                # ä¿å­˜åˆ°æ–‡ä»¶
                combined_df.to_excel(self.excel_filename, index=False, engine='openpyxl')
                logging.info(f"å·²è¿½åŠ  {len(data_list)} æ¡æ•°æ®åˆ°Excelæ–‡ä»¶")

            except Exception as e:
                logging.error(f"è¿½åŠ æ•°æ®åˆ°Excelå¤±è´¥: {e}")

    def check_and_create_tables(self):
        """æ£€æŸ¥å¹¶åˆ›å»ºè¡¨"""
        connection = self.get_db_connection()
        if not connection:
            return

        try:
            cursor = connection.cursor()

            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            cursor.execute("SHOW TABLES LIKE 'crawl_progress'")
            if not cursor.fetchone():
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS crawl_progress (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        region VARCHAR(100),
                        school_name VARCHAR(255) NOT NULL,
                        search_type ENUM('region', 'school') DEFAULT 'region',
                        status ENUM('pending', 'completed', 'failed') DEFAULT 'pending',
                        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                        UNIQUE KEY unique_search_school (region, school_name, search_type)
                    )
                """)
                logging.info("åˆ›å»ºè¡¨ crawl_progress")

            cursor.execute("SHOW TABLES LIKE 'exam_subjects'")
            if not cursor.fetchone():
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS exam_subjects (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        school_name VARCHAR(255) NOT NULL,
                        major_name VARCHAR(255) NOT NULL,
                        major_code VARCHAR(100),
                        department VARCHAR(255),
                        research_direction VARCHAR(255),
                        politics_subject VARCHAR(100),
                        foreign_language_subject VARCHAR(100),
                        business_subject1 VARCHAR(255),
                        business_subject2 VARCHAR(255),
                        enrollment_plan VARCHAR(100),
                        exam_scope TEXT,
                        reference_books TEXT,
                        region VARCHAR(100),
                        data_source VARCHAR(500) NOT NULL,
                        school_features TEXT,
                        degree_type VARCHAR(50),
                        search_type ENUM('region', 'school') DEFAULT 'region',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE KEY unique_school_major_direction (school_name(100), major_name(100), major_code(50), department(100), research_direction(100))
                    )
                """)
                logging.info("åˆ›å»ºè¡¨ exam_subjects")

            connection.commit()
            logging.info("æ•°æ®è¡¨æ£€æŸ¥å®Œæˆ")

        except MySQLError as e:
            logging.error(f"æ£€æŸ¥è¡¨å¤±è´¥: {e}")
            try:
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS exam_subjects (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        school_name VARCHAR(255) NOT NULL,
                        major_name VARCHAR(255) NOT NULL,
                        major_code VARCHAR(100),
                        department VARCHAR(255),
                        research_direction VARCHAR(255),
                        politics_subject VARCHAR(100),
                        foreign_language_subject VARCHAR(100),
                        business_subject1 VARCHAR(255),
                        business_subject2 VARCHAR(255),
                        enrollment_plan VARCHAR(100),
                        exam_scope TEXT,
                        reference_books TEXT,
                        region VARCHAR(100),
                        data_source VARCHAR(500) NOT NULL,
                        school_features TEXT,
                        degree_type VARCHAR(50),
                        search_type ENUM('region', 'school') DEFAULT 'region',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                connection.commit()
                logging.info("æ•°æ®è¡¨åˆ›å»ºæˆåŠŸï¼ˆæ— å”¯ä¸€ç´¢å¼•ï¼‰")
            except MySQLError as e2:
                logging.error(f"åˆ›å»ºæ— ç´¢å¼•è¡¨ä¹Ÿå¤±è´¥: {e2}")
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            connection = mysql.connector.connect(**DB_CONFIG)
            return connection
        except MySQLError as e:
            logging.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return None

    def check_school_exists_in_database(self, school_name, search_type='region'):
        """æ£€æŸ¥å­¦æ ¡æ˜¯å¦å·²åœ¨æ•°æ®åº“ä¸­å­˜åœ¨"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()

            query = "SELECT COUNT(*) FROM exam_subjects WHERE school_name = %s AND search_type = %s"
            cursor.execute(query, (school_name, search_type))
            count = cursor.fetchone()[0]

            return count > 0
        except MySQLError as e:
            logging.error(f"æ£€æŸ¥å­¦æ ¡æ˜¯å¦å­˜åœ¨å¤±è´¥: {e}")
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def delete_school_data(self, school_name, search_type='region'):
        """åˆ é™¤æŒ‡å®šå­¦æ ¡çš„æ•°æ®"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()

            query = "DELETE FROM exam_subjects WHERE school_name = %s AND search_type = %s"
            cursor.execute(query, (school_name, search_type))

            query = "DELETE FROM crawl_progress WHERE school_name = %s AND search_type = %s"
            cursor.execute(query, (school_name, search_type))

            connection.commit()
            logging.info(f"å·²åˆ é™¤å­¦æ ¡ {school_name} çš„ç°æœ‰æ•°æ®")
            return True
        except MySQLError as e:
            logging.error(f"åˆ é™¤å­¦æ ¡æ•°æ®å¤±è´¥: {e}")
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def ask_user_for_existing_schools(self, school_list, search_type='region'):
        """è¯¢é—®ç”¨æˆ·å¯¹å·²å­˜åœ¨å­¦æ ¡çš„å¤„ç†æ–¹å¼"""
        schools_to_crawl = []

        print(f"\n=== æ£€æŸ¥å·²å­˜åœ¨çš„å­¦æ ¡ ===")
        print(f"å…±æ‰¾åˆ° {len(school_list)} æ‰€å­¦æ ¡")

        for i, school_info in enumerate(school_list, 1):
            school_name = school_info['name']
            exists = self.check_school_exists_in_database(school_name, search_type)

            if exists:
                print(f"\n{i}. å­¦æ ¡ '{school_name}' å·²å­˜åœ¨äºæ•°æ®åº“ä¸­")
                while True:
                    choice = input(f"æ˜¯å¦é‡æ–°çˆ¬å–å­¦æ ¡ '{school_name}'ï¼Ÿ(y/n): ").strip().lower()
                    if choice in ['y', 'yes', 'æ˜¯']:
                        if self.delete_school_data(school_name, search_type):
                            schools_to_crawl.append(school_info)
                            print(f"å­¦æ ¡ '{school_name}' å°†é‡æ–°çˆ¬å–")
                        else:
                            print(f"åˆ é™¤å­¦æ ¡ '{school_name}' æ•°æ®å¤±è´¥ï¼Œå°†è·³è¿‡è¯¥å­¦æ ¡")
                        break
                    elif choice in ['n', 'no', 'å¦']:
                        print(f"å­¦æ ¡ '{school_name}' å°†è·³è¿‡")
                        break
                    else:
                        print("è¯·è¾“å…¥ y/yes/æ˜¯ æˆ– n/no/å¦")
            else:
                schools_to_crawl.append(school_info)
                print(f"{i}. å­¦æ ¡ '{school_name}' æœªåœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°ï¼Œå°†è¿›è¡Œçˆ¬å–")

        print(f"\næœ€ç»ˆå°†çˆ¬å– {len(schools_to_crawl)} æ‰€å­¦æ ¡")
        return schools_to_crawl

    def save_to_database(self, data):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        if not data:
            return False

        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            saved_count = 0

            cursor.execute("SHOW TABLES LIKE 'exam_subjects'")
            table_exists = cursor.fetchone()

            if not table_exists:
                logging.error("è¡¨ exam_subjects ä¸å­˜åœ¨ï¼Œæ— æ³•ä¿å­˜æ•°æ®")
                return False

            for item in data:
                try:
                    query = """
                    INSERT IGNORE INTO exam_subjects 
                    (school_name, major_name, major_code, department, research_direction,
                     politics_subject, foreign_language_subject, business_subject1, business_subject2,
                     enrollment_plan, exam_scope, region, data_source, school_features, degree_type, search_type)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """
                    cursor.execute(query, (
                        item.get('school_name', ''),
                        item.get('major_name', ''),
                        item.get('major_code', ''),
                        item.get('department', ''),
                        item.get('research_direction', ''),
                        item.get('politics_subject', ''),
                        item.get('foreign_language_subject', ''),
                        item.get('business_subject1', ''),
                        item.get('business_subject2', ''),
                        item.get('enrollment_plan', ''),
                        item.get('exam_scope', ''),
                        item.get('region', ''),
                        item.get('data_source', ''),
                        item.get('school_features', ''),
                        item.get('degree_type', ''),
                        item.get('search_type', 'region')
                    ))
                    saved_count += 1

                except MySQLError as e:
                    continue

            connection.commit()
            logging.info(f"æˆåŠŸä¿å­˜ {saved_count} æ¡æ•°æ®åˆ°æ•°æ®åº“")
            return True

        except MySQLError as e:
            logging.error(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def crawl_school_task(self, school_info, region=None, search_type='region', thread_id=0):
        """å•ä¸ªå­¦æ ¡çš„çˆ¬å–ä»»åŠ¡ï¼ˆç”¨äºå¤šçº¿ç¨‹ï¼‰"""
        thread_spider = ThreadSafeSpider(thread_id)
        try:
            school_name = school_info['name']
            logging.info(f"çº¿ç¨‹ {thread_id} å¼€å§‹å¤„ç†: {school_name}")

            school_data = thread_spider.crawl_school_majors(
                school_info['name'],
                school_info.get('major_link'),
                region,
                school_info.get('features', []),
                search_type
            )

            if school_data:
                self.save_to_database(school_data)
                self.append_to_excel(school_data)
                logging.info(f"çº¿ç¨‹ {thread_id} å®Œæˆå­¦æ ¡ {school_name}ï¼Œè·å– {len(school_data)} æ¡æ•°æ®")
                return school_data
            else:
                logging.info(f"çº¿ç¨‹ {thread_id} å­¦æ ¡ {school_name} æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡ä¸“ä¸š")
                return []

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {thread_id} å¤„ç†å­¦æ ¡ {school_info['name']} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []
        finally:
            thread_spider.close()

    def crawl_all_schools_multithread(self, school_list, region=None, search_type='region'):
        """å¤šçº¿ç¨‹æ‰¹é‡çˆ¬å–æ‰€æœ‰å­¦æ ¡"""
        all_data = []

        logging.info(f"å¼€å§‹å¤šçº¿ç¨‹çˆ¬å–ï¼Œå…± {len(school_list)} æ‰€å­¦æ ¡ï¼Œä½¿ç”¨ {self.max_workers} ä¸ªçº¿ç¨‹")

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_school = {
                executor.submit(self.crawl_school_task, school, region, search_type, i): (school, i)
                for i, school in enumerate(school_list)
            }

            for future in as_completed(future_to_school):
                school, thread_id = future_to_school[future]
                try:
                    school_data = future.result()
                    if school_data:
                        all_data.extend(school_data)
                        logging.info(f"çº¿ç¨‹ {thread_id} å®Œæˆå­¦æ ¡ {school['name']} çš„çˆ¬å–")
                except Exception as e:
                    logging.error(f"å­¦æ ¡ {school['name']} çˆ¬å–å¤±è´¥: {e}")

        logging.info(f"å¤šçº¿ç¨‹çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡ä¸“ä¸šä¿¡æ¯")
        return all_data

    def get_available_regions(self):
        """è·å–æ‰€æœ‰å¯ç”¨åœ°åŒº"""
        temp_spider = ThreadSafeSpider(0)
        try:
            temp_spider.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
            time.sleep(5)

            print("\n=== å¯ç”¨åœ°åŒº ===")
            area_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".area-item")
            all_regions = []

            for area_item in area_items:
                regions = area_item.find_elements(By.CSS_SELECTOR, ".option-item")
                for region in regions:
                    region_name = region.text.strip()
                    all_regions.append(region_name)

            print("\nä¸€åŒº:", end=" ")
            for i, region in enumerate(all_regions[:21]):
                print(f"{i + 1}.{region}", end=" ")

            print("\n\näºŒåŒº:", end=" ")
            for i, region in enumerate(all_regions[21:], 22):
                print(f"{i}.{region}", end=" ")
            print()

            return all_regions

        except Exception as e:
            logging.error(f"è·å–å¯ç”¨åœ°åŒºå¤±è´¥: {e}")
            return []
        finally:
            temp_spider.close()

    def select_search_mode(self):
        """é€‰æ‹©æœç´¢æ¨¡å¼"""
        print("\n=== æœç´¢æ¨¡å¼é€‰æ‹© ===")
        print("1. æŒ‰åœ°åŒºæœç´¢")
        print("2. æŒ‰å­¦æ ¡æœç´¢")

        while True:
            mode = input("è¯·é€‰æ‹©æœç´¢æ¨¡å¼ (1 æˆ– 2): ").strip()
            if mode == "1":
                return "region"
            elif mode == "2":
                return "school"
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

    def select_region_and_features(self):
        """äº¤äº’å¼é€‰æ‹©åœ°åŒºå’Œé™¢æ ¡ç‰¹æ€§"""
        try:
            all_regions = self.get_available_regions()
            if not all_regions:
                return [], []

            print("\n=== åœ°åŒºé€‰æ‹© ===")
            print("è¯·é€‰æ‹©è¦çˆ¬å–çš„åœ°åŒºï¼ˆè¾“å…¥ç¼–å·ï¼Œå¤šä¸ªç¼–å·ç”¨é€—å·åˆ†éš”ï¼Œè¾“å…¥0é€‰æ‹©æ‰€æœ‰åœ°åŒºï¼‰:")

            region_input = input("è¯·è¾“å…¥ç¼–å·: ").strip()

            selected_regions = []
            if region_input == "0":
                selected_regions = all_regions
            else:
                input_nums = [num.strip() for num in region_input.split(',') if num.strip()]
                for num in input_nums:
                    if num.isdigit() and 1 <= int(num) <= len(all_regions):
                        selected_regions.append(all_regions[int(num) - 1])
                    else:
                        print(f"è­¦å‘Š: æ— æ•ˆç¼–å· {num}ï¼Œå·²è·³è¿‡")

            if not selected_regions:
                print("æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆåœ°åŒº")
                return [], []

            print("\n=== é™¢æ ¡ç‰¹æ€§ ===")
            feature_options = [
                ("bs", "åšå£«ç‚¹"),
                ("syl", "åŒä¸€æµå»ºè®¾é«˜æ ¡"),
                ("zhx", "è‡ªåˆ’çº¿é™¢æ ¡")
            ]

            print("è¯·é€‰æ‹©é™¢æ ¡ç‰¹æ€§ï¼ˆè¾“å…¥ç¼–å·ï¼Œå¤šä¸ªç¼–å·ç”¨é€—å·åˆ†éš”ï¼Œè¾“å…¥0é€‰æ‹©æ‰€æœ‰ç‰¹æ€§ï¼Œç›´æ¥å›è½¦è·³è¿‡é€‰æ‹©ï¼‰:")
            for idx, (value, name) in enumerate(feature_options, 1):
                print(f"  {idx}. {name}")

            feature_input = input("è¯·è¾“å…¥ç¼–å·: ").strip()

            selected_features = []
            if feature_input == "":
                print("æœªé€‰æ‹©ä»»ä½•é™¢æ ¡ç‰¹æ€§ï¼Œå°†æœç´¢æ‰€æœ‰é™¢æ ¡")
            elif feature_input == "0":
                selected_features = [value for value, name in feature_options]
            else:
                input_nums = [num.strip() for num in feature_input.split(',') if num.strip()]
                for num in input_nums:
                    if num.isdigit() and 1 <= int(num) <= len(feature_options):
                        selected_features.append(feature_options[int(num) - 1][0])
                    else:
                        print(f"è­¦å‘Š: æ— æ•ˆç¼–å· {num}ï¼Œå·²è·³è¿‡")

            return selected_regions, selected_features

        except Exception as e:
            logging.error(f"é€‰æ‹©åœ°åŒºå’Œç‰¹æ€§å¤±è´¥: {e}")
            return [], []

    def select_schools_by_name(self):
        """æŒ‰å­¦æ ¡åç§°é€‰æ‹©å­¦æ ¡"""
        print("\n=== å­¦æ ¡æœç´¢ ===")
        print("è¯·è¾“å…¥è¦çˆ¬å–çš„å­¦æ ¡åç§°ï¼ˆå¤šä¸ªå­¦æ ¡ç”¨é€—å·åˆ†éš”ï¼‰:")

        school_input = input("è¯·è¾“å…¥å­¦æ ¡åç§°: ").strip()

        if not school_input:
            print("æœªè¾“å…¥ä»»ä½•å­¦æ ¡åç§°")
            return []

        school_names = [name.strip() for name in school_input.split(',') if name.strip()]
        return school_names

    def search_schools_by_region_and_features(self, region, features):
        """æ ¹æ®åœ°åŒºå’Œç‰¹æ€§æœç´¢å­¦æ ¡"""
        temp_spider = ThreadSafeSpider(0)
        try:
            temp_spider.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
            time.sleep(3)

            area_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".area-item")
            region_found = False
            for area_item in area_items:
                regions = area_item.find_elements(By.CSS_SELECTOR, ".option-item")
                for region_elem in regions:
                    if region_elem.text.strip() == region:
                        region_elem.click()
                        region_found = True
                        break
                if region_found:
                    break

            if not region_found:
                logging.error(f"æ— æ³•é€‰æ‹©åœ°åŒº: {region}")
                return []

            if features:
                for feature in features:
                    try:
                        checkbox = temp_spider.driver.find_element(By.CSS_SELECTOR,
                                                                   f"input[type='checkbox'][value='{feature}']")
                        if not checkbox.is_selected():
                            checkbox.click()
                    except:
                        pass

            search_button = temp_spider.wait_for_element_clickable(By.CSS_SELECTOR, "button.ivu-btn-primary")
            if search_button:
                search_button.click()
                time.sleep(3)

            schools = []
            school_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".zy-item")
            for item in school_items:
                try:
                    name_elem = item.find_element(By.CSS_SELECTOR, ".yx-name")
                    school_name = name_elem.text.strip()
                    clean_name = re.sub(r'\(\d+\)', '', school_name).strip()

                    school_features = []
                    try:
                        feature_tags = item.find_elements(By.CSS_SELECTOR, ".yx-tag")
                        for tag in feature_tags:
                            feature_text = tag.text.strip()
                            if feature_text:
                                school_features.append(feature_text)
                    except:
                        pass

                    major_link_elem = item.find_element(By.CSS_SELECTOR, ".zy-btn")
                    major_link = major_link_elem.get_attribute("href")

                    schools.append({
                        'name': clean_name,
                        'original_name': school_name,
                        'major_link': major_link,
                        'features': school_features
                    })
                except:
                    continue

            logging.info(f"åœ°åŒº {region} æ‰¾åˆ° {len(schools)} æ‰€å­¦æ ¡")
            return schools

        except Exception as e:
            logging.error(f"æœç´¢å­¦æ ¡å¤±è´¥ - åœ°åŒº: {region}, ç‰¹æ€§: {features}: {e}")
            return []
        finally:
            temp_spider.close()

    def search_school_by_name(self, school_name):
        """æ ¹æ®å­¦æ ¡åç§°æœç´¢å­¦æ ¡"""
        temp_spider = ThreadSafeSpider(0)
        try:
            temp_spider.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
            time.sleep(3)

            school_search_input = temp_spider.wait_for_element(
                By.CSS_SELECTOR, "input[placeholder='è¯·è¾“å…¥æ‹›ç”Ÿå•ä½åç§°']"
            )
            if not school_search_input:
                logging.error("æœªæ‰¾åˆ°å­¦æ ¡æœç´¢æ¡†")
                return None

            school_search_input.clear()
            school_search_input.send_keys(school_name)
            time.sleep(3)

            search_button = temp_spider.wait_for_element_clickable(
                By.CSS_SELECTOR, "button.ivu-btn-primary"
            )
            if search_button:
                search_button.click()
                time.sleep(3)
            else:
                logging.error("æœªæ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®")
                return None

            if temp_spider.check_no_results():
                logging.warning(f"æœªæ‰¾åˆ°å­¦æ ¡: {school_name}")
                return None

            school_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".zy-item")
            if school_items:
                item = school_items[0]
                name_elem = item.find_element(By.CSS_SELECTOR, ".yx-name")
                school_name = name_elem.text.strip()
                clean_name = re.sub(r'\(\d+\)', '', school_name).strip()

                school_features = []
                try:
                    feature_tags = item.find_elements(By.CSS_SELECTOR, ".yx-tag")
                    for tag in feature_tags:
                        feature_text = tag.text.strip()
                        if feature_text:
                            school_features.append(feature_text)
                except:
                    pass

                major_link_elem = item.find_element(By.CSS_SELECTOR, ".zy-btn")
                major_link = major_link_elem.get_attribute("href")

                return {
                    'name': clean_name,
                    'original_name': school_name,
                    'major_link': major_link,
                    'features': school_features
                }
            else:
                logging.warning(f"æœªæ‰¾åˆ°å­¦æ ¡: {school_name}")
                return None

        except Exception as e:
            logging.error(f"æœç´¢å­¦æ ¡ {school_name} å¤±è´¥: {e}")
            return None
        finally:
            temp_spider.close()

    def crawl_by_regions_and_features(self, regions, features):
        """æŒ‰åœ°åŒºå’Œç‰¹æ€§çˆ¬å–æ‰€æœ‰å­¦æ ¡ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰"""
        all_data = []
        total_schools = 0

        for region in regions:
            logging.info(f"=== å¼€å§‹å¤„ç†åœ°åŒº: {region} ===")

            schools = self.search_schools_by_region_and_features(region, features)

            if not schools:
                logging.info(f"åœ°åŒº {region} æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å­¦æ ¡")
                continue

            filtered_schools = self.ask_user_for_existing_schools(schools, 'region')

            if not filtered_schools:
                logging.info(f"åœ°åŒº {region} æ²¡æœ‰éœ€è¦çˆ¬å–çš„å­¦æ ¡")
                continue

            logging.info(f"åœ°åŒº {region} æ‰¾åˆ° {len(filtered_schools)} æ‰€å­¦æ ¡éœ€è¦çˆ¬å–ï¼Œå¼€å§‹å¤šçº¿ç¨‹çˆ¬å–ä¸“ä¸šä¿¡æ¯...")

            region_data = self.crawl_all_schools_multithread(filtered_schools, region, 'region')
            all_data.extend(region_data)
            total_schools += len(filtered_schools)

            logging.info(f"åœ°åŒº {region} çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(region_data)} æ¡ä¸“ä¸šä¿¡æ¯")

        logging.info(f"æ‰€æœ‰åœ°åŒºçˆ¬å–å®Œæˆï¼Œå…±å¤„ç† {total_schools} æ‰€å­¦æ ¡ï¼Œè·å– {len(all_data)} æ¡ä¸“ä¸šä¿¡æ¯")
        return all_data

    def crawl_by_school_names(self, school_names):
        """æŒ‰å­¦æ ¡åç§°çˆ¬å–å­¦æ ¡ä¸“ä¸šä¿¡æ¯ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰"""
        all_data = []

        schools_to_crawl = []
        for school_name in school_names:
            logging.info(f"æœç´¢å­¦æ ¡: {school_name}")
            school_info = self.search_school_by_name(school_name)
            if school_info:
                schools_to_crawl.append(school_info)
            else:
                logging.warning(f"æœªæ‰¾åˆ°å­¦æ ¡: {school_name}")

        if not schools_to_crawl:
            logging.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å­¦æ ¡")
            return all_data

        filtered_schools = self.ask_user_for_existing_schools(schools_to_crawl, 'school')

        if not filtered_schools:
            logging.info("æ²¡æœ‰éœ€è¦çˆ¬å–çš„å­¦æ ¡")
            return all_data

        logging.info(f"æ‰¾åˆ° {len(filtered_schools)} æ‰€æœ‰æ•ˆå­¦æ ¡éœ€è¦çˆ¬å–ï¼Œå¼€å§‹å¤šçº¿ç¨‹çˆ¬å–...")

        all_data = self.crawl_all_schools_multithread(filtered_schools, None, 'school')

        logging.info(f"æ‰€æœ‰å­¦æ ¡çˆ¬å–å®Œæˆï¼Œå…±å¤„ç† {len(filtered_schools)} æ‰€å­¦æ ¡ï¼Œè·å– {len(all_data)} æ¡ä¸“ä¸šä¿¡æ¯")
        return all_data

    def delete_region_data(self, region):
        """åˆ é™¤æŒ‡å®šåœ°åŒºçš„æ•°æ®"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()

            query = "DELETE FROM exam_subjects WHERE region = %s AND search_type = 'region'"
            cursor.execute(query, (region,))

            query = "DELETE FROM crawl_progress WHERE region = %s AND search_type = 'region'"
            cursor.execute(query, (region,))

            connection.commit()
            logging.info(f"å·²åˆ é™¤åœ°åŒº {region} çš„æ‰€æœ‰æ•°æ®")
            return True
        except MySQLError as e:
            logging.error(f"åˆ é™¤åœ°åŒºæ•°æ®å¤±è´¥: {e}")
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()


class ShanghaiRankingSpider:
    """è½¯ç§‘æ’åçˆ¬è™«ç±»"""

    def __init__(self, headless=False):
        self.headless = headless
        self.driver = None
        self.wait = None
        self.edge_driver_path = r"msedgedriver.exe"
        self.all_subjects = {}
        self.subjects_2025 = {}
        self.subject_mapping = {}

        self.setup_driver()
        self.create_tables()

    def setup_driver(self):
        """é…ç½®Edgeæµè§ˆå™¨é©±åŠ¨"""
        try:
            from selenium.webdriver.edge.options import Options as EdgeOptions
            from selenium.webdriver.edge.service import Service as EdgeService

            edge_options = EdgeOptions()

            if self.headless:
                edge_options.add_argument('--headless')
                edge_options.add_argument('--disable-gpu')

            edge_options.add_argument('--no-sandbox')
            edge_options.add_argument('--disable-dev-shm-usage')
            edge_options.add_argument('--window-size=1920,1080')
            edge_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            edge_options.add_experimental_option('useAutomationExtension', False)
            edge_options.add_argument('--disable-blink-features=AutomationControlled')

            edge_options.add_argument(
                'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
            )

            if not os.path.exists(self.edge_driver_path):
                logging.error(f"Edgeé©±åŠ¨æ–‡ä»¶ä¸å­˜åœ¨: {self.edge_driver_path}")
                print(f"\né”™è¯¯: Edgeé©±åŠ¨æ–‡ä»¶ä¸å­˜åœ¨: {self.edge_driver_path}")
                raise FileNotFoundError(f"Edgeé©±åŠ¨æ–‡ä»¶ä¸å­˜åœ¨: {self.edge_driver_path}")

            logging.info(f"ä½¿ç”¨Edgeé©±åŠ¨è·¯å¾„: {self.edge_driver_path}")

            service = EdgeService(executable_path=self.edge_driver_path)
            self.driver = webdriver.Edge(service=service, options=edge_options)

            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

            self.wait = WebDriverWait(self.driver, 10)
            self.driver.implicitly_wait(5)

            logging.info("æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logging.error(f"æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def wait_for_element(self, by, value, timeout=10):
        """ç­‰å¾…å…ƒç´ å‡ºç°"""
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.presence_of_element_located((by, value))
            )
            return element
        except TimeoutException:
            logging.warning(f"ç­‰å¾…å…ƒç´ è¶…æ—¶: {by}={value}")
            return None

    def wait_for_element_clickable(self, by, value, timeout=10):
        """ç­‰å¾…å…ƒç´ å¯ç‚¹å‡»"""
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.element_to_be_clickable((by, value))
            )
            return element
        except TimeoutException:
            logging.warning(f"ç­‰å¾…å…ƒç´ å¯ç‚¹å‡»è¶…æ—¶: {by}={value}")
            return None

    def wait_for_page_load(self, timeout=30):
        """ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ"""
        try:
            WebDriverWait(self.driver, timeout).until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
            return True
        except TimeoutException:
            logging.warning("é¡µé¢åŠ è½½è¶…æ—¶")
            return False

    def get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            connection = mysql.connector.connect(**DB_CONFIG)
            return connection
        except MySQLError as e:
            logging.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return None

    def create_tables(self):
        """åˆ›å»ºè½¯ç§‘æ’åæ•°æ®è¡¨"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()

            cursor.execute("SHOW TABLES LIKE 'shanghai_subject_rankings'")
            table_exists = cursor.fetchone()

            if table_exists:
                try:
                    cursor.execute("SELECT ranking_position_2025 FROM shanghai_subject_rankings LIMIT 1")
                    cursor.fetchall()
                    logging.info("è¡¨ç»“æ„æ­£ç¡®ï¼Œæ— éœ€é‡å»º")
                except MySQLError:
                    logging.info("è¡¨ç»“æ„ä¸æ­£ç¡®ï¼Œåˆ é™¤é‡å»º...")
                    cursor.execute("DROP TABLE IF EXISTS shanghai_subject_rankings")
                    connection.commit()
            else:
                cursor.fetchall()

            cursor.execute("""
                CREATE TABLE IF NOT EXISTS shanghai_subject_rankings (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    year INT NOT NULL,
                    subject_code VARCHAR(20) NOT NULL,
                    subject_name VARCHAR(100) NOT NULL,
                    ranking_position_2025 INT,
                    ranking_position_2024 INT,
                    school_name VARCHAR(255) NOT NULL,
                    score_2025 FLOAT,
                    score_2024 FLOAT,
                    indicator_scores_2025 JSON,
                    indicator_scores_2024 JSON,
                    subject_category VARCHAR(50),
                    page_number INT DEFAULT 1,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY unique_year_subject_school (year, subject_code, school_name),
                    INDEX idx_year_subject (year, subject_code),
                    INDEX idx_school_name (school_name),
                    INDEX idx_subject_category (subject_category),
                    INDEX idx_page_number (page_number)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """)

            connection.commit()
            logging.info("è½¯ç§‘æ’åæ•°æ®è¡¨åˆ›å»º/æ›´æ–°æˆåŠŸ")
            return True

        except MySQLError as e:
            logging.error(f"åˆ›å»º/æ›´æ–°è½¯ç§‘æ’åè¡¨å¤±è´¥: {e}")
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def fetch_all_subjects_from_web(self, url="https://www.shanghairanking.cn/rankings/bcsr/2025"):
        """ä»è½¯ç§‘æ’åé¡µé¢åŠ¨æ€çˆ¬å–æ‰€æœ‰å­¦ç§‘ä¿¡æ¯"""
        logging.info(f"å¼€å§‹ä»ç½‘é¡µçˆ¬å–æ‰€æœ‰å­¦ç§‘ä¿¡æ¯: {url}")

        try:
            self.driver.get(url)
            time.sleep(5)

            subject_container = self.wait_for_element(By.CSS_SELECTOR, ".subject-container", timeout=15)
            if not subject_container:
                logging.error("æœªæ‰¾åˆ°å­¦ç§‘å®¹å™¨")
                return {}

            subject_items = subject_container.find_elements(By.CSS_SELECTOR, ".subject-item")
            all_subjects = {}

            for item in subject_items:
                try:
                    category_code = item.get_attribute("id")

                    category_title_elem = item.find_element(By.CSS_SELECTOR, ".subject-title")
                    category_name = category_title_elem.text.strip() if category_title_elem else f"ç±»åˆ«{category_code}"

                    subject_list = item.find_element(By.CSS_SELECTOR, ".subject-list")
                    subject_links = subject_list.find_elements(By.CSS_SELECTOR, ".subj-link")

                    subjects_in_category = []
                    for link in subject_links:
                        try:
                            spans = link.find_elements(By.TAG_NAME, "span")
                            if len(spans) >= 2:
                                subject_code = spans[0].text.strip()
                                subject_name = spans[1].text.strip()

                                if subject_code and subject_name:
                                    subjects_in_category.append((subject_code, subject_name))
                        except Exception as e:
                            logging.debug(f"è§£æå­¦ç§‘é“¾æ¥å¤±è´¥: {e}")
                            continue

                    if subjects_in_category:
                        all_subjects[category_code] = {
                            'category_name': category_name,
                            'subjects': subjects_in_category
                        }
                        logging.info(f"ç±»åˆ« {category_code}-{category_name}: æ‰¾åˆ° {len(subjects_in_category)} ä¸ªå­¦ç§‘")

                except Exception as e:
                    logging.debug(f"è§£æå­¦ç§‘å¤§ç±»å¤±è´¥: {e}")
                    continue

            self.all_subjects = all_subjects
            self.subjects_2025 = {cat_code: cat_info['subjects'] for cat_code, cat_info in all_subjects.items()}

            self.generate_subject_mapping()

            total_subjects = sum(len(cat_info['subjects']) for cat_info in all_subjects.values())
            logging.info(f"æˆåŠŸçˆ¬å– {len(all_subjects)} ä¸ªå­¦ç§‘å¤§ç±»ï¼Œå…± {total_subjects} ä¸ªå…·ä½“å­¦ç§‘")

            return all_subjects

        except Exception as e:
            logging.error(f"çˆ¬å–å­¦ç§‘ä¿¡æ¯å¤±è´¥: {e}")
            return {}

    def generate_subject_mapping(self):
        """ç”Ÿæˆå­¦ç§‘ç¼–å·æ˜ å°„ï¼Œç”¨äºäº¤äº’å¼é€‰æ‹©"""
        if not self.all_subjects:
            return {}

        self.subject_mapping = {}
        subject_index = 1

        sorted_categories = sorted(self.all_subjects.items(), key=lambda x: x[0])

        for category_code, category_info in sorted_categories:
            category_name = category_info['category_name']
            subjects = category_info['subjects']

            for subject_code, subject_name in subjects:
                self.subject_mapping[subject_index] = (subject_code, subject_name, category_code, category_name)
                subject_index += 1

        return self.subject_mapping

    def display_all_subjects(self):
        """æ˜¾ç¤ºæ‰€æœ‰çˆ¬å–åˆ°çš„å­¦ç§‘ä¿¡æ¯ï¼Œä¾›ç”¨æˆ·é€‰æ‹©"""
        if not self.all_subjects:
            print("æ­£åœ¨ä»è½¯ç§‘å®˜ç½‘è·å–æœ€æ–°å­¦ç§‘åˆ—è¡¨...")
            self.fetch_all_subjects_from_web()

        if not self.all_subjects:
            print("æœªè·å–åˆ°å­¦ç§‘ä¿¡æ¯")
            return {}

        print("\n" + "=" * 60)
        print("è½¯ç§‘2025å­¦ç§‘æ’å - æ‰€æœ‰å¯ç”¨å­¦ç§‘")
        print("=" * 60)

        if not self.subject_mapping:
            self.generate_subject_mapping()

        sorted_categories = sorted(self.all_subjects.items(), key=lambda x: x[0])

        for category_code, category_info in sorted_categories:
            category_name = category_info['category_name']
            subjects = category_info['subjects']

            print(f"\nã€{category_code}ã€‘{category_name}")

            for subject_code, subject_name in subjects:
                for idx, mapping in self.subject_mapping.items():
                    if mapping[0] == subject_code and mapping[1] == subject_name:
                        print(f"  {idx:3d}. [{subject_code}] {subject_name}")
                        break

        total_subjects = len(self.subject_mapping)
        print(f"\nå…± {total_subjects} ä¸ªå­¦ç§‘")
        print("=" * 60)

        return self.subject_mapping

    def clean_school_name(self, school_name):
        """æ¸…ç†å­¦æ ¡åç§°"""
        if not school_name:
            return ""

        school_name = school_name.strip()
        school_name = re.sub(r'\([^)]*\)', '', school_name)
        school_name = re.sub(r'ï¼ˆ[^ï¼‰]*ï¼‰', '', school_name)
        school_name = re.sub(r'\s+', ' ', school_name).strip()

        replacements = {
            'åŒ—äº¬åå’ŒåŒ»å­¦é™¢(æ¸…åå¤§å­¦åŒ»å­¦éƒ¨)': 'åŒ—äº¬åå’ŒåŒ»å­¦é™¢',
            'å›½é˜²ç§‘æŠ€å¤§å­¦ï¼ˆåŸå›½é˜²ç§‘å­¦æŠ€æœ¯å¤§å­¦ï¼‰': 'å›½é˜²ç§‘æŠ€å¤§å­¦',
            'åŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦ï¼ˆåŸåŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦ï¼‰': 'åŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦',
            'åŒ—äº¬ç†å·¥å¤§å­¦ï¼ˆåŸåŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦ï¼‰': 'åŒ—äº¬ç†å·¥å¤§å­¦',
            'å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦ï¼ˆåŸå“ˆå°”æ»¨å·¥ä¸šå¤§å­¦ï¼‰': 'å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦',
            'è¥¿åŒ—å·¥ä¸šå¤§å­¦ï¼ˆåŸè¥¿åŒ—å·¥ä¸šå¤§å­¦ï¼‰': 'è¥¿åŒ—å·¥ä¸šå¤§å­¦',
            'åŒ—äº¬å¤§å­¦åŒ»å­¦éƒ¨': 'åŒ—äº¬å¤§å­¦',
            'å¤æ—¦å¤§å­¦ä¸Šæµ·åŒ»å­¦é™¢': 'å¤æ—¦å¤§å­¦',
            'ä¸Šæµ·äº¤é€šå¤§å­¦åŒ»å­¦é™¢': 'ä¸Šæµ·äº¤é€šå¤§å­¦',
        }

        for old, new in replacements.items():
            if old in school_name:
                school_name = school_name.replace(old, new)

        return school_name

    def extract_rank_number(self, rank_text):
        """ä»æ’åæ–‡æœ¬ä¸­æå–æ’åæ•°å­—"""
        if not rank_text:
            return 0

        rank_text = str(rank_text).strip()

        if rank_text.isdigit():
            return int(rank_text)
        elif '-' in rank_text:
            parts = rank_text.split('-')
            if parts[0].strip().isdigit():
                return int(parts[0].strip())
            else:
                match = re.search(r'(\d+)', parts[0].strip())
                if match:
                    return int(match.group(1))
        else:
            match = re.search(r'(\d+)', rank_text)
            if match:
                return int(match.group(1))

        return 0

    def extract_score(self, score_text):
        """ä»åˆ†æ•°æ–‡æœ¬ä¸­æå–åˆ†æ•°"""
        if not score_text:
            return 0.0

        try:
            cleaned_text = re.sub(r'[^\d.]', '', str(score_text))
            if cleaned_text:
                return float(cleaned_text)
            return 0.0
        except:
            return 0.0

    def navigate_to_subject_page(self, subject_code):
        """å¯¼èˆªåˆ°å­¦ç§‘é¡µé¢"""
        url = f"https://www.shanghairanking.cn/rankings/bcsr/2025/{subject_code}"
        logging.info(f"å¯¼èˆªåˆ°: {url}")

        try:
            self.driver.get(url)

            if not self.wait_for_page_load():
                logging.warning("é¡µé¢åŠ è½½å¯èƒ½æœªå®Œæˆï¼Œç»§ç»­å°è¯•...")

            table = self.wait_for_element(By.CLASS_NAME, "rk-table", timeout=20)
            if not table:
                logging.error("æœªæ‰¾åˆ°æ’åè¡¨æ ¼")
                return False

            time.sleep(3)
            logging.info("é¡µé¢åŠ è½½å®Œæˆ")
            return True

        except TimeoutException:
            logging.error("é¡µé¢åŠ è½½è¶…æ—¶")
            try:
                self.driver.save_screenshot(f"timeout_{subject_code}.png")
                logging.info(f"å·²ä¿å­˜æˆªå›¾: timeout_{subject_code}.png")
            except:
                pass
            return False
        except Exception as e:
            logging.error(f"å¯¼èˆªåˆ°é¡µé¢å¤±è´¥: {e}")
            return False

    def get_total_pages(self):
        """è·å–æ€»é¡µæ•°"""
        try:
            pagination = self.wait_for_element(By.CLASS_NAME, "ant-pagination", timeout=15)
            if not pagination:
                logging.warning("æœªæ‰¾åˆ°åˆ†é¡µå™¨")
                return 1

            time.sleep(2)

            try:
                total_text_element = pagination.find_element(By.CLASS_NAME, "ant-pagination-total-text")
                text = total_text_element.text
                match = re.search(r'å…±\s*(\d+)\s*æ¡', text)
                if match:
                    total_items = int(match.group(1))
                    total_pages = (total_items + 29) // 30
                    logging.info(f"æ€»æ¡ç›®: {total_items}, æ€»é¡µæ•°: {total_pages}")
                    return total_pages
            except NoSuchElementException:
                pass

            try:
                page_buttons = pagination.find_elements(By.CLASS_NAME, "ant-pagination-item")
                if page_buttons:
                    page_numbers = []
                    for button in page_buttons:
                        try:
                            button_text = button.text.strip()
                            if button_text and button_text.isdigit():
                                page_num = int(button_text)
                                page_numbers.append(page_num)
                        except:
                            continue

                    if page_numbers:
                        max_page = max(page_numbers)
                        logging.info(f"ä»é¡µç æŒ‰é’®è·å–æ€»é¡µæ•°: {max_page}")
                        return max_page
            except Exception as e:
                logging.debug(f"æ–¹æ³•2å¤±è´¥: {e}")

            logging.info("æ— æ³•è·å–æ€»é¡µæ•°ï¼Œé»˜è®¤è¿”å›1é¡µ")
            return 1

        except Exception as e:
            logging.warning(f"è·å–æ€»é¡µæ•°å¤±è´¥: {e}")
            return 1

    def go_to_page(self, page_num):
        """è·³è½¬åˆ°æŒ‡å®šé¡µç """
        try:
            logging.info(f"å°è¯•è·³è½¬åˆ°ç¬¬ {page_num} é¡µ")

            pagination = self.wait_for_element(By.CLASS_NAME, "ant-pagination", timeout=15)
            if not pagination:
                logging.error("æœªæ‰¾åˆ°åˆ†é¡µå™¨")
                return False

            try:
                page_buttons = pagination.find_elements(By.CLASS_NAME, "ant-pagination-item")
                logging.info(f"æ‰¾åˆ° {len(page_buttons)} ä¸ªé¡µç æŒ‰é’®")

                target_button = None
                for button in page_buttons:
                    try:
                        button_text = button.text.strip()
                        if button_text and button_text.isdigit() and int(button_text) == page_num:
                            target_button = button
                            break
                    except:
                        continue

                if target_button:
                    class_attr = target_button.get_attribute("class")
                    if "ant-pagination-item-active" in class_attr:
                        logging.info(f"å·²ç»æ˜¯ç¬¬ {page_num} é¡µ")
                        return True

                    self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});",
                                               target_button)
                    time.sleep(1)

                    self.driver.execute_script("arguments[0].click();", target_button)
                    logging.info(f"é€šè¿‡JavaScriptç‚¹å‡»è·³è½¬åˆ°ç¬¬ {page_num} é¡µ")

                    self.wait_for_page_load()
                    time.sleep(3)

                    active_page = self.wait_for_element(By.CSS_SELECTOR, ".ant-pagination-item-active", timeout=10)
                    if active_page:
                        active_page_num = active_page.text.strip()
                        if active_page_num.isdigit() and int(active_page_num) == page_num:
                            logging.info(f"æˆåŠŸè·³è½¬åˆ°ç¬¬ {page_num} é¡µ")
                            return True
            except Exception as e:
                logging.debug(f"æ–¹æ³•1å¤±è´¥: {e}")

            try:
                quick_jumper = pagination.find_element(By.CLASS_NAME, "ant-pagination-options-quick-jumper")
                page_input = quick_jumper.find_element(By.TAG_NAME, "input")

                self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});",
                                           page_input)
                time.sleep(1)

                page_input.clear()
                page_input.send_keys(str(page_num))
                page_input.send_keys(Keys.RETURN)

                logging.info(f"ä½¿ç”¨è¾“å…¥æ¡†è·³è½¬åˆ°ç¬¬ {page_num} é¡µ")

                self.wait_for_page_load()
                time.sleep(4)

                active_page = self.wait_for_element(By.CSS_SELECTOR, ".ant-pagination-item-active", timeout=10)
                if active_page:
                    active_page_num = active_page.text.strip()
                    if active_page_num.isdigit() and int(active_page_num) == page_num:
                        logging.info(f"è¾“å…¥æ¡†è·³è½¬æˆåŠŸåˆ°ç¬¬ {page_num} é¡µ")
                        return True
            except Exception as e:
                logging.debug(f"æ–¹æ³•2å¤±è´¥: {e}")

            try:
                current_page = 1

                try:
                    active_page = pagination.find_element(By.CLASS_NAME, "ant-pagination-item-active")
                    current_page_text = active_page.text.strip()
                    if current_page_text.isdigit():
                        current_page = int(current_page_text)
                except:
                    pass

                if page_num > current_page:
                    clicks_needed = page_num - current_page
                    for click_count in range(clicks_needed):
                        next_button = pagination.find_element(By.CLASS_NAME, "ant-pagination-next")

                        if "ant-pagination-disabled" in next_button.get_attribute("class"):
                            logging.warning(f"ä¸‹ä¸€é¡µæŒ‰é’®å·²ç¦ç”¨ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                            break

                        self.driver.execute_script(
                            "arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", next_button)
                        time.sleep(1)

                        self.driver.execute_script("arguments[0].click();", next_button)

                        logging.info(f"ç‚¹å‡»ä¸‹ä¸€é¡µ ({current_page + click_count} -> {current_page + click_count + 1})")

                        self.wait_for_page_load()
                        time.sleep(3)

                        pagination = self.wait_for_element(By.CLASS_NAME, "ant-pagination", timeout=10)
                        if not pagination:
                            logging.warning("åˆ†é¡µå™¨ä¸¢å¤±")
                            break

                    time.sleep(2)
                    final_active_page = self.wait_for_element(By.CSS_SELECTOR, ".ant-pagination-item-active",
                                                              timeout=10)
                    if final_active_page:
                        final_page_text = final_active_page.text.strip()
                        if final_page_text.isdigit() and int(final_page_text) == page_num:
                            logging.info(f"é€šè¿‡ä¸‹ä¸€é¡µæŒ‰é’®æˆåŠŸè·³è½¬åˆ°ç¬¬ {page_num} é¡µ")
                            return True
                else:
                    logging.warning(f"ç›®æ ‡é¡µ {page_num} ä¸å¤§äºå½“å‰é¡µ {current_page}")
            except Exception as e:
                logging.debug(f"æ–¹æ³•3å¤±è´¥: {e}")

            logging.warning(f"æ— æ³•è·³è½¬åˆ°ç¬¬ {page_num} é¡µ")
            return False

        except Exception as e:
            logging.error(f"è·³è½¬åˆ°ç¬¬ {page_num} é¡µå¤±è´¥: {e}")
            return False

    def parse_current_page(self, subject_code, subject_name, page_num=1):
        """è§£æå½“å‰é¡µé¢çš„æ•°æ®"""
        try:
            table = self.wait_for_element(By.CLASS_NAME, "rk-table", timeout=15)
            if not table:
                logging.warning("æœªæ‰¾åˆ°æ’åè¡¨æ ¼")
                return []

            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')

            table = soup.find('table', class_='rk-table')
            if not table:
                logging.warning("æœªæ‰¾åˆ°æ’åè¡¨æ ¼")
                return []

            tbody = table.find('tbody')
            if not tbody:
                return []

            rows = tbody.find_all('tr')
            data_rows = []

            for row in rows:
                cells = row.find_all('td')
                if len(cells) < 5:
                    continue

                try:
                    rank_2025 = 0
                    if len(cells) > 0:
                        rank_cell = cells[0]
                        rank_div = rank_cell.find('div', class_='ranking')
                        if rank_div:
                            rank_text = rank_div.get_text(strip=True)
                        else:
                            rank_text = rank_cell.get_text(strip=True)
                        rank_2025 = self.extract_rank_number(rank_text)

                    rank_2024 = 0
                    if len(cells) > 1:
                        rank_cell = cells[1]
                        rank_span = rank_cell.find('span')
                        if rank_span:
                            rank_text = rank_span.get_text(strip=True)
                        else:
                            rank_text = rank_cell.get_text(strip=True)
                        rank_2024 = self.extract_rank_number(rank_text)

                    school_name = ""
                    if len(cells) > 3:
                        school_cell = cells[3]
                        name_span = school_cell.find('span', class_='name-cn')
                        if name_span:
                            school_name = self.clean_school_name(name_span.get_text(strip=True))
                        else:
                            school_name = self.clean_school_name(school_cell.get_text(strip=True))

                    if not school_name or len(school_name) < 2:
                        continue

                    score_2025 = 0.0
                    if len(cells) > 4:
                        score_text = cells[4].get_text(strip=True)
                        score_2025 = self.extract_score(score_text)

                    score_2024 = 0.0

                    subject_category = ""
                    if subject_code.startswith('01'):
                        subject_category = "å“²å­¦"
                    elif subject_code.startswith('02'):
                        subject_category = "ç»æµå­¦"
                    elif subject_code.startswith('03'):
                        subject_category = "æ³•å­¦"
                    elif subject_code.startswith('04'):
                        subject_category = "æ•™è‚²å­¦"
                    elif subject_code.startswith('05'):
                        subject_category = "æ–‡å­¦"
                    elif subject_code.startswith('06'):
                        subject_category = "å†å²å­¦"
                    elif subject_code.startswith('07'):
                        subject_category = "ç†å­¦"
                    elif subject_code.startswith('08'):
                        subject_category = "å·¥å­¦"
                    elif subject_code.startswith('09'):
                        subject_category = "å†œå­¦"
                    elif subject_code.startswith('10'):
                        subject_category = "åŒ»å­¦"
                    elif subject_code.startswith('12'):
                        subject_category = "ç®¡ç†å­¦"
                    elif subject_code.startswith('13'):
                        subject_category = "è‰ºæœ¯å­¦"
                    elif subject_code.startswith('14'):
                        subject_category = "äº¤å‰å­¦ç§‘"
                    else:
                        subject_category = "å…¶ä»–"

                    data_rows.append({
                        'year': 2025,
                        'subject_code': subject_code,
                        'subject_name': subject_name,
                        'ranking_position_2025': rank_2025,
                        'ranking_position_2024': rank_2024,
                        'school_name': school_name,
                        'score_2025': score_2025,
                        'score_2024': score_2024,
                        'indicator_scores_2025': '{}',
                        'indicator_scores_2024': '{}',
                        'subject_category': subject_category,
                        'page_number': page_num
                    })

                except Exception as e:
                    logging.debug(f"è§£æè¡Œæ•°æ®å¤±è´¥: {e}")
                    continue

            logging.info(f"æˆåŠŸè§£æ {len(data_rows)} æ¡æ•°æ®")

            if data_rows and page_num <= 2:
                logging.info(f"ç¬¬{page_num}é¡µæ ·æœ¬æ•°æ®:")
                for i, data in enumerate(data_rows[:3]):
                    logging.info(f"  æ’å2025:{data['ranking_position_2025']}, "
                                 f"æ’å2024:{data['ranking_position_2024']}, "
                                 f"{data['school_name']} "
                                 f"åˆ†æ•°:{data['score_2025']:.1f}")

            return data_rows

        except Exception as e:
            logging.error(f"è§£æé¡µé¢æ•°æ®å¤±è´¥: {e}")
            return []

    def fetch_subject_data(self, subject_code, subject_name, max_pages=None):
        """è·å–å­¦ç§‘æ‰€æœ‰é¡µé¢æ•°æ®"""
        logging.info(f"å¼€å§‹çˆ¬å–å­¦ç§‘æ’å: {subject_name} ({subject_code})")

        all_data = []

        try:
            if not self.navigate_to_subject_page(subject_code):
                logging.error(f"æ— æ³•è®¿é—®å­¦ç§‘é¡µé¢: {subject_name}")
                return []

            total_pages = self.get_total_pages()
            logging.info(f"æ€»é¡µæ•°: {total_pages}")

            if max_pages and max_pages < total_pages:
                total_pages = max_pages

            for page_num in range(1, total_pages + 1):
                try:
                    logging.info(f"çˆ¬å–ç¬¬ {page_num}/{total_pages} é¡µ...")

                    if page_num > 1:
                        if not self.go_to_page(page_num):
                            logging.warning(f"æ— æ³•è·³è½¬åˆ°ç¬¬ {page_num} é¡µï¼Œè·³è¿‡")
                            continue

                    table = self.wait_for_element(By.CLASS_NAME, "rk-table", timeout=10)
                    if not table:
                        logging.warning(f"ç¬¬ {page_num} é¡µæœªæ‰¾åˆ°è¡¨æ ¼")
                        continue

                    time.sleep(2)

                    page_data = self.parse_current_page(subject_code, subject_name, page_num)

                    if page_data:
                        all_data.extend(page_data)
                        logging.info(f"ç¬¬ {page_num} é¡µè§£æåˆ° {len(page_data)} æ¡æ•°æ®")

                        if page_num <= 2:
                            logging.info(f"  æ ·æœ¬æ•°æ®:")
                            for i, data in enumerate(page_data[:2]):
                                logging.info(
                                    f"    æ’å2025:{data['ranking_position_2025']}, "
                                    f"æ’å2024:{data['ranking_position_2024']}, "
                                    f"{data['school_name']} - "
                                    f"åˆ†æ•°: {data['score_2025']:.1f}")
                    else:
                        logging.warning(f"ç¬¬ {page_num} é¡µæœªè·å–åˆ°æ•°æ®")
                        if page_num == 1:
                            self.driver.refresh()
                            time.sleep(3)

                    if page_num < total_pages:
                        delay = random.uniform(3, 6)
                        logging.info(f"  ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                        time.sleep(delay)

                except Exception as e:
                    logging.error(f"çˆ¬å–ç¬¬ {page_num} é¡µå¤±è´¥: {e}")
                    if not self.navigate_to_subject_page(subject_code):
                        break
                    continue

            if not all_data:
                logging.warning(f"å­¦ç§‘ {subject_name} æœªè·å–åˆ°ä»»ä½•æ•°æ®")
                return []

            unique_data = {}
            for data in all_data:
                key = f"{data['ranking_position_2025']}_{data['school_name']}"
                if key not in unique_data:
                    unique_data[key] = data

            all_data = list(unique_data.values())
            all_data.sort(key=lambda x: x['ranking_position_2025'])

            logging.info(f"å­¦ç§‘ {subject_name} çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡å”¯ä¸€æ•°æ®")

            if all_data:
                logging.info(f"å‰10æ¡æ•°æ®:")
                for i, data in enumerate(all_data[:10]):
                    logging.info(
                        f"  æ’å2025:{data['ranking_position_2025']:3d}, "
                        f"æ’å2024:{data['ranking_position_2024']:3d}, "
                        f"{data['school_name']:20s} - "
                        f"åˆ†æ•°: {data['score_2025']:.1f}")

            return all_data

        except Exception as e:
            logging.error(f"çˆ¬å–å­¦ç§‘æ’åå¤±è´¥ {subject_name}: {e}")
            return []

    def save_subject_rankings_to_db(self, rankings):
        """ä¿å­˜å­¦ç§‘æ’åæ•°æ®åˆ°æ•°æ®åº“"""
        if not rankings:
            logging.warning("æ²¡æœ‰å­¦ç§‘æ’åæ•°æ®å¯ä¿å­˜")
            return False

        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            saved_count = 0
            error_count = 0

            for ranking in rankings:
                try:
                    if not ranking.get('school_name') or len(ranking['school_name']) < 2:
                        continue

                    query = """
                    INSERT INTO shanghai_subject_rankings 
                    (year, subject_code, subject_name, ranking_position_2025, ranking_position_2024, 
                     school_name, score_2025, score_2024, indicator_scores_2025, indicator_scores_2024, 
                     subject_category, page_number)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                    ranking_position_2025 = VALUES(ranking_position_2025),
                    ranking_position_2024 = VALUES(ranking_position_2024),
                    score_2025 = VALUES(score_2025),
                    score_2024 = VALUES(score_2024),
                    indicator_scores_2025 = VALUES(indicator_scores_2025),
                    indicator_scores_2024 = VALUES(indicator_scores_2024),
                    subject_category = VALUES(subject_category),
                    page_number = VALUES(page_number)
                    """

                    cursor.execute(query, (
                        ranking['year'],
                        ranking['subject_code'],
                        ranking['subject_name'],
                        ranking['ranking_position_2025'],
                        ranking['ranking_position_2024'],
                        ranking['school_name'],
                        ranking['score_2025'],
                        ranking['score_2024'],
                        ranking['indicator_scores_2025'],
                        ranking['indicator_scores_2024'],
                        ranking['subject_category'],
                        ranking['page_number']
                    ))
                    saved_count += 1

                except MySQLError as e:
                    error_count += 1
                    logging.warning(
                        f"ä¿å­˜æ•°æ®å¤±è´¥ {ranking.get('subject_name', '')}-{ranking.get('school_name', '')}: {e}")
                    continue

            connection.commit()
            logging.info(f"æˆåŠŸä¿å­˜ {saved_count} æ¡æ•°æ®åˆ°æ•°æ®åº“ï¼Œå¤±è´¥ {error_count} æ¡")
            return True

        except MySQLError as e:
            logging.error(f"ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def test_single_subject(self, subject_code='0701', subject_name='æ•°å­¦', max_pages=3):
        """æµ‹è¯•å•ä¸ªå­¦ç§‘çš„çˆ¬å–"""
        print(f"\næµ‹è¯• {subject_name} å­¦ç§‘çˆ¬å– ({subject_code})")
        print(f"æœ€å¤§é¡µæ•°: {max_pages}")

        data = self.fetch_subject_data(subject_code, subject_name, max_pages)

        if data:
            print(f"\næµ‹è¯•å®Œæˆï¼Œå…±è·å– {len(data)} æ¡å”¯ä¸€æ•°æ®")
            print(f"\nå‰10æ¡æ•°æ®:")
            for i, data_item in enumerate(data[:10]):
                print(f"  æ’å2025: {data_item['ranking_position_2025']:3d}, "
                      f"æ’å2024: {data_item['ranking_position_2024']:3d}, "
                      f"{data_item['school_name']:20s} - "
                      f"åˆ†æ•°2025: {data_item['score_2025']:.1f} "
                      f"(ç¬¬{data_item['page_number']}é¡µ)")
        else:
            print("æœªè·å–åˆ°æ•°æ®")

        return data

    def export_to_excel(self):
        """å¯¼å‡ºæ•°æ®åˆ°Excel"""
        print("\nå¯¼å‡ºæ•°æ®åˆ°Excel...")

        connection = self.get_db_connection()
        if not connection:
            print("æ•°æ®åº“è¿æ¥å¤±è´¥")
            return False

        try:
            query = "SELECT * FROM shanghai_subject_rankings ORDER BY subject_code, ranking_position_2025"
            df = pd.read_sql(query, connection)

            if df.empty:
                print("æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
                return False

            export_dir = 'exports'
            if not os.path.exists(export_dir):
                os.makedirs(export_dir)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"shanghai_subject_rankings_{timestamp}.xlsx"
            filepath = os.path.join(export_dir, filename)

            df.to_excel(filepath, index=False, engine='openpyxl')
            print(f"æ•°æ®å·²å¯¼å‡ºåˆ°: {filepath}")
            print(f"å…±å¯¼å‡º {len(df)} æ¡è®°å½•")
            print(f"å­¦ç§‘æ•°é‡: {df['subject_code'].nunique()}")
            print(f"å­¦æ ¡æ•°é‡: {df['school_name'].nunique()}")

            print("\næ•°æ®ç»“æ„:")
            print(f"åˆ—å: {', '.join(df.columns.tolist())}")

            print("\nå‰5æ¡æ•°æ®æ ·æœ¬:")
            for i, row in df.head().iterrows():
                print(f"  {row['subject_name']} - {row['school_name']}: "
                      f"æ’å2025:{row['ranking_position_2025']}, "
                      f"æ’å2024:{row['ranking_position_2024']}, "
                      f"åˆ†æ•°2025:{row['score_2025']:.1f}")

            return True

        except Exception as e:
            print(f"å¯¼å‡ºæ•°æ®å¤±è´¥: {e}")
            return False
        finally:
            if connection.is_connected():
                connection.close()

    def clear_database(self):
        """æ¸…é™¤æ•°æ®åº“ä¸­çš„æ‰€æœ‰è½¯ç§‘æ’åæ•°æ®"""
        print("\næ¸…é™¤æ•°æ®åº“ä¸­çš„æ•°æ®...")

        confirm = input("ç¡®è®¤æ¸…é™¤æ‰€æœ‰è½¯ç§‘æ’åæ•°æ®ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ï¼(è¾“å…¥ 'yes' ç¡®è®¤): ").strip()
        if confirm.lower() != 'yes':
            print("å·²å–æ¶ˆæ¸…é™¤æ“ä½œ")
            return False

        connection = self.get_db_connection()
        if not connection:
            print("æ•°æ®åº“è¿æ¥å¤±è´¥")
            return False

        try:
            cursor = connection.cursor()

            cursor.execute("SELECT COUNT(*) as count FROM shanghai_subject_rankings")
            subject_count = cursor.fetchone()[0]

            print(f"å½“å‰å­¦ç§‘æ’åè¡¨æœ‰ {subject_count} æ¡è®°å½•")

            cursor.execute("DELETE FROM shanghai_subject_rankings")
            connection.commit()

            print("æ•°æ®æ¸…é™¤æˆåŠŸ")
            return True

        except MySQLError as e:
            print(f"æ¸…é™¤æ•°æ®å¤±è´¥: {e}")
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def delete_subject_data(self, subject_name):
        """åˆ é™¤æŒ‡å®šå­¦ç§‘çš„æ•°æ®"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()

            cursor.execute("SELECT COUNT(*) as count FROM shanghai_subject_rankings WHERE subject_name = %s",
                           (subject_name,))
            subject_count = cursor.fetchone()[0]

            if subject_count == 0:
                print(f"å­¦ç§‘ '{subject_name}' æ²¡æœ‰æ•°æ®å¯åˆ é™¤")
                return True

            confirm = input(f"ç¡®è®¤åˆ é™¤å­¦ç§‘ '{subject_name}' çš„æ‰€æœ‰ {subject_count} æ¡æ•°æ®å—ï¼Ÿ(y/n): ").strip().lower()
            if confirm != 'y':
                print("å·²å–æ¶ˆåˆ é™¤æ“ä½œ")
                return False

            cursor.execute("DELETE FROM shanghai_subject_rankings WHERE subject_name = %s", (subject_name,))
            connection.commit()

            print(f"æˆåŠŸåˆ é™¤å­¦ç§‘ '{subject_name}' çš„ {subject_count} æ¡æ•°æ®")
            return True

        except MySQLError as e:
            print(f"åˆ é™¤å­¦ç§‘æ•°æ®å¤±è´¥: {e}")
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def close_driver(self):
        """å…³é—­WebDriver"""
        if self.driver:
            try:
                self.driver.quit()
                logging.info("WebDriverå·²å…³é—­")
            except:
                pass


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        connection = pymysql.connect(
            host='localhost',
            user='root',
            password='Wza!64416685',
            database='kaoyan_data',
            charset='utf8mb4',
            cursorclass=DictCursor
        )
        return connection
    except pymysql.Error as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None


def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    connection = get_db_connection()
    if not connection:
        return False

    try:
        with connection.cursor() as cursor:
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS users (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    username VARCHAR(50) UNIQUE NOT NULL,
                    email VARCHAR(100) UNIQUE NOT NULL,
                    password_hash VARCHAR(255) NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_login TIMESTAMP NULL,
                    is_active BOOLEAN DEFAULT TRUE
                )
            """)

            cursor.execute("""
                CREATE TABLE IF NOT EXISTS chat_history (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    user_id INT,
                    question TEXT NOT NULL,
                    answer TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id)
                )
            """)

        connection.commit()
        return True
    except pymysql.Error as e:
        st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    finally:
        connection.close()


def hash_password(password):
    """å¯†ç å“ˆå¸Œå¤„ç†"""
    return hashlib.sha256(password.encode()).hexdigest()


def validate_email(email):
    """éªŒè¯é‚®ç®±æ ¼å¼"""
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None


def validate_username(username):
    """éªŒè¯ç”¨æˆ·åæ ¼å¼"""
    return len(username) >= 3 and len(username) <= 50 and re.match(r'^[a-zA-Z0-9_]+$', username)


def register_user(username, email, password):
    """æ³¨å†Œæ–°ç”¨æˆ·"""
    connection = get_db_connection()
    if not connection:
        return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"

    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT id FROM users WHERE username = %s", (username,))
            if cursor.fetchone():
                return False, "ç”¨æˆ·åå·²å­˜åœ¨"

            cursor.execute("SELECT id FROM users WHERE email = %s", (email,))
            if cursor.fetchone():
                return False, "é‚®ç®±å·²è¢«æ³¨å†Œ"

            password_hash = hash_password(password)
            cursor.execute(
                "INSERT INTO users (username, email, password_hash) VALUES (%s, %s, %s)",
                (username, email, password_hash)
            )

        connection.commit()
        return True, "æ³¨å†ŒæˆåŠŸ"

    except pymysql.Error as e:
        return False, f"æ³¨å†Œå¤±è´¥: {str(e)}"
    finally:
        connection.close()


def verify_user(username, password):
    """éªŒè¯ç”¨æˆ·ç™»å½•"""
    connection = get_db_connection()
    if not connection:
        return False, None

    try:
        with connection.cursor() as cursor:
            password_hash = hash_password(password)

            cursor.execute(
                "SELECT id, username, email FROM users WHERE username = %s AND password_hash = %s AND is_active = TRUE",
                (username, password_hash)
            )

            user = cursor.fetchone()
            if user:
                cursor.execute(
                    "UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = %s",
                    (user['id'],)
                )
                connection.commit()
                return True, user
            else:
                return False, None

    except pymysql.Error as e:
        return False, None
    finally:
        connection.close()


def save_chat_history(user_id, question, answer):
    """ä¿å­˜èŠå¤©è®°å½•åˆ°æ•°æ®åº“"""
    connection = get_db_connection()
    if not connection:
        return False

    try:
        with connection.cursor() as cursor:
            cursor.execute(
                "INSERT INTO chat_history (user_id, question, answer) VALUES (%s, %s, %s)",
                (user_id, question, answer)
            )
        connection.commit()
        return True
    except pymysql.Error:
        return False
    finally:
        connection.close()


def get_chat_history(user_id, limit=10):
    """è·å–ç”¨æˆ·èŠå¤©è®°å½•"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            cursor.execute(
                "SELECT question, answer, timestamp FROM chat_history WHERE user_id = %s ORDER BY timestamp DESC LIMIT %s",
                (user_id, limit)
            )
            return cursor.fetchall()
    except pymysql.Error:
        return []
    finally:
        connection.close()


def query_database(question):
    """æ ¹æ®é—®é¢˜ç²¾ç¡®æŸ¥è¯¢è€ƒç ”æ•°æ®åº“"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            question_lower = question.lower()

            conditions = []
            params = []

            school_pattern = r'([\u4e00-\u9fa5]+å¤§å­¦)'
            school_matches = re.findall(school_pattern, question)

            if school_matches:
                for school in school_matches:
                    conditions.append("school_name LIKE %s")
                    params.append(f"%{school}%")

            major_patterns = [
                'ä¿¡æ¯å®‰å…¨', 'è®¡ç®—æœº', 'è½¯ä»¶', 'äººå·¥æ™ºèƒ½', 'ç”µå­ä¿¡æ¯',
                'ç”µå­ç§‘å­¦', 'ç½‘ç»œç©ºé—´å®‰å…¨', 'ç”µå­ä¿¡æ¯æŠ€æœ¯', 'æ–°ä¸€ä»£ç”µå­ä¿¡æ¯æŠ€æœ¯',
                'è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯', 'è½¯ä»¶å·¥ç¨‹', 'äººå·¥æ™ºèƒ½', 'ç½‘ç»œå®‰å…¨'
            ]

            for pattern in major_patterns:
                if pattern in question:
                    conditions.append("major_name LIKE %s")
                    params.append(f"%{pattern}%")

            direction_keywords = ['æ–¹å‘', 'ç ”ç©¶æ–¹å‘', 'æœ‰å“ªäº›æ–¹å‘', 'ä»€ä¹ˆæ–¹å‘']
            has_direction_query = any(keyword in question for keyword in direction_keywords)

            if conditions:
                query = """
                SELECT DISTINCT 
                    school_name, major_name, major_code, department, research_direction,
                    politics_subject, foreign_language_subject, business_subject1, business_subject2,
                    enrollment_plan, region, data_source
                FROM exam_subjects 
                WHERE """ + " OR ".join(conditions)

                if has_direction_query:
                    query += " AND research_direction IS NOT NULL AND research_direction != ''"

                query += " ORDER BY school_name, major_name, research_direction"
                cursor.execute(query, params)
            else:
                words = question.replace('?', '').replace('ï¼Ÿ', '').split()
                if len(words) > 0:
                    query = """
                    SELECT * FROM exam_subjects 
                    WHERE CONCAT(school_name, major_name, research_direction) LIKE %s
                    ORDER BY school_name, major_name
                    LIMIT 10
                    """
                    search_term = f"%{'%'.join(words)}%"
                    cursor.execute(query, (search_term,))
                else:
                    return []

            results = cursor.fetchall()

            grouped_results = []
            seen = {}

            for result in results:
                key = f"{result['school_name']}_{result['major_name']}"

                if key not in seen:
                    seen[key] = {
                        'school_name': result['school_name'],
                        'major_name': result['major_name'],
                        'major_code': result.get('major_code', ''),
                        'research_directions': [],
                        'departments': set(),
                        'enrollment_plan': result.get('enrollment_plan', ''),
                        'politics_subject': result.get('politics_subject', ''),
                        'foreign_language_subject': result.get('foreign_language_subject', ''),
                        'business_subject1': result.get('business_subject1', ''),
                        'business_subject2': result.get('business_subject2', ''),
                        'region': result.get('region', ''),
                        'data_source': result.get('data_source', '')
                    }

                if result.get('research_direction'):
                    direction = result['research_direction'].strip()
                    if direction and direction not in seen[key]['research_directions']:
                        seen[key]['research_directions'].append(direction)

                if result.get('department'):
                    seen[key]['departments'].add(result['department'])

            for key, value in seen.items():
                value['departments'] = list(value['departments'])
                grouped_results.append(value)

            return grouped_results

    except pymysql.Error as e:
        print(f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {e}")
        return []
    finally:
        connection.close()


def format_database_results(results):
    """æ ¼å¼åŒ–æ•°æ®åº“æŸ¥è¯¢ç»“æœï¼Œä¼˜åŒ–å›ç­”ç»“æ„"""
    if not results:
        return "æœªåœ¨æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

    formatted = "ä»¥ä¸‹æ˜¯æ•°æ®åº“ä¸­çš„ç›¸å…³è€ƒç ”ä¿¡æ¯ï¼š\n\n"

    for i, result in enumerate(results, 1):
        formatted += f"**{i}. {result['school_name']} - {result['major_name']}**"

        if result.get('major_code'):
            formatted += f"ï¼ˆ{result['major_code']}ï¼‰"
        formatted += "\n"

        if result.get('research_directions'):
            formatted += "   **ç ”ç©¶æ–¹å‘**ï¼š\n"
            for direction in result['research_directions']:
                formatted += f"   - {direction}\n"
        else:
            formatted += "   **ç ”ç©¶æ–¹å‘**ï¼šæ•°æ®åº“ä¸­æœªè®°å½•å…·ä½“æ–¹å‘ï¼Œæˆ–è¯¥ä¸“ä¸šåœ¨æ‹›ç”Ÿæ—¶ä¸åŒºåˆ†æ–¹å‘ã€‚\n"

        if result.get('departments'):
            formatted += f"   **å¼€è®¾é™¢ç³»**ï¼š{', '.join(result['departments'])}\n"

        if result.get('enrollment_plan'):
            formatted += f"   **æ‹Ÿæ‹›ç”Ÿäººæ•°**ï¼š{result['enrollment_plan']}\n"

        has_exam_subjects = (
                result.get('politics_subject') or
                result.get('foreign_language_subject') or
                result.get('business_subject1') or
                result.get('business_subject2')
        )

        if has_exam_subjects:
            formatted += "   **è€ƒè¯•ç§‘ç›®**ï¼š\n"
            if result.get('politics_subject'):
                formatted += f"   - æ”¿æ²»ï¼š{result['politics_subject']}\n"
            if result.get('foreign_language_subject'):
                formatted += f"   - å¤–è¯­ï¼š{result['foreign_language_subject']}\n"
            if result.get('business_subject1'):
                formatted += f"   - ä¸šåŠ¡è¯¾ä¸€ï¼š{result['business_subject1']}\n"
            if result.get('business_subject2'):
                formatted += f"   - ä¸šåŠ¡è¯¾äºŒï¼š{result['business_subject2']}\n"

        formatted += f"   **åœ°åŒº**ï¼š{result.get('region', 'æœªè®°å½•')}\n"
        formatted += "\n"

    formatted += """
---
**é‡è¦è¯´æ˜**ï¼š
1. ä»¥ä¸Šä¿¡æ¯åŸºäºæ•°æ®åº“ä¸­çš„å†å²æ‹›ç”Ÿæ•°æ®ï¼Œå®é™…æ‹›ç”Ÿä¿¡æ¯è¯·ä»¥å­¦æ ¡å®˜æ–¹æœ€æ–°å…¬å¸ƒä¸ºå‡†ã€‚
2. "ä¸åŒºåˆ†æ–¹å‘"åœ¨å®˜æ–¹æ–‡ä»¶ä¸­é€šå¸¸æŒ‡å¤è¯•åˆ†æ•°çº¿ç»Ÿä¸€ï¼Œä½†å…¥å­¦åå®é™…ç ”ç©¶ä¼šæœ‰å…·ä½“æ–¹å‘åˆ’åˆ†ã€‚
3. åŒä¸€ä¸“ä¸šåœ¨ä¸åŒé™¢ç³»å¯èƒ½å¼€è®¾ä¸åŒç ”ç©¶æ–¹å‘ã€‚
"""

    return formatted


def call_deepseek_api(question, context):
    """è°ƒç”¨DeepSeek APIï¼Œä¼˜åŒ–æç¤ºè¯å’Œå›ç­”ç”Ÿæˆ"""
    try:
        api_key = st.secrets.get("DEEPSEEK_API_KEY", "your_deepseek_api_key_here")
        url = "https://api.deepseek.com/v1/chat/completions"

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è€ƒç ”å’¨è¯¢åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æä¾›çš„æ•°æ®åº“ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

**å›ç­”å‡†åˆ™**ï¼š
1. **å¿ å®äºæ•°æ®åº“**ï¼šæ‰€æœ‰å›ç­”å¿…é¡»åŸºäºæä¾›çš„æ•°æ®åº“ä¿¡æ¯ï¼Œä¸æ·»åŠ æœªæåŠçš„ä¿¡æ¯ã€‚
2. **è§£é‡Šè¯´æ˜**ï¼šå¦‚æœæ•°æ®åº“ä¿¡æ¯ä¸å¸¸è§è®¤çŸ¥æœ‰å·®å¼‚ï¼ˆå¦‚"ä¸åŒºåˆ†æ–¹å‘"ï¼‰ï¼Œè¯·åŸºäºæ•°æ®åº“ä¿¡æ¯è§£é‡Šã€‚
3. **ç»“æ„æ¸…æ™°**ï¼šæŒ‰å­¦æ ¡ã€ä¸“ä¸šã€ç ”ç©¶æ–¹å‘ã€è€ƒè¯•ç§‘ç›®çš„é¡ºåºç»„ç»‡å›ç­”ã€‚
4. **å®Œæ•´æ€§**ï¼šåˆ—å‡ºæ•°æ®åº“ä¸­æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼Œä¸é—æ¼ã€‚
5. **å®¢è§‚æ€§**ï¼šä¸æ·»åŠ ä¸»è§‚è¯„ä»·ï¼Œåªé™ˆè¿°äº‹å®ã€‚

**ç‰¹åˆ«æ³¨æ„äº‹é¡¹**ï¼š
- å½“æ•°æ®åº“æ˜¾ç¤ºå¤šä¸ªç ”ç©¶æ–¹å‘æ—¶ï¼Œå…¨éƒ¨åˆ—å‡ºã€‚
- å½“æ•°æ®åº“æ˜¾ç¤º"ä¸åŒºåˆ†ç ”ç©¶æ–¹å‘"æ—¶ï¼Œå¦‚å®è¯´æ˜ï¼Œå¹¶è§£é‡Šè¿™é€šå¸¸æŒ‡å¤è¯•æ—¶ç»Ÿä¸€åˆ†æ•°çº¿ã€‚
- å¦‚æœæ•°æ®åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜ã€‚
"""

        user_message = f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š
{context}

è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®åº“ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚æ³¨æ„ï¼š
1. å¦‚æœæ•°æ®åº“ä¸­æœ‰å¤šæ¡è®°å½•ï¼Œè¯·æ±‡æ€»æ•´ç†åå›ç­”ã€‚
2. å¦‚æœç ”ç©¶æ–¹å‘ä¸ºç©ºæˆ–æ˜¾ç¤º"ä¸åŒºåˆ†ç ”ç©¶æ–¹å‘"ï¼Œè¯·è¯´æ˜å®é™…æƒ…å†µã€‚
3. å¦‚æœæ•°æ®åº“ä¿¡æ¯ä¸å…¨ï¼Œè¯·è¯´æ˜å“ªäº›ä¿¡æ¯ç¼ºå¤±ã€‚
4. å›ç­”è¦ç®€æ´ã€å‡†ç¡®ã€å®Œæ•´ã€‚
"""

        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": 0.3,
            "max_tokens": 2500
        }

        response = requests.post(url, headers=headers, json=data, timeout=30)

        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content']

            if "æœªåœ¨æ•°æ®åº“ä¸­" in context and "æœªæ‰¾åˆ°" not in answer.lower():
                answer += "\n\næ³¨ï¼šä»¥ä¸Šä¿¡æ¯åŸºäºæ•°æ®åº“æŸ¥è¯¢ç»“æœï¼Œå¦‚ä¸å®˜æ–¹ä¿¡æ¯æœ‰å‡ºå…¥ï¼Œè¯·ä»¥å­¦æ ¡å®˜æ–¹å‘å¸ƒä¸ºå‡†ã€‚"

            return answer
        else:
            return f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}\n\næ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š\n{context}"

    except Exception as e:
        return f"è°ƒç”¨AIæœåŠ¡æ—¶å‡ºé”™ï¼š{str(e)}\n\næ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š\n{context}"


def get_school_list():
    """è·å–å­¦æ ¡åˆ—è¡¨"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT DISTINCT school_name FROM exam_subjects ORDER BY school_name")
            schools = [row['school_name'] for row in cursor.fetchall()]
            return schools
    except pymysql.Error:
        return []
    finally:
        connection.close()


def query_shanghai_ranking(question):
    """æŸ¥è¯¢è½¯ç§‘æ’åæ•°æ®"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            question_lower = question.lower()

            ranking_keywords = ['æ’å', 'è½¯ç§‘', 'shanghai', 'å­¦ç§‘è¯„ä¼°', 'å­¦ç§‘æ’å']
            if not any(keyword in question_lower for keyword in ranking_keywords):
                return []

            subject_keywords = {
                'æ•°å­¦': ['æ•°å­¦', 'math', 'mathematics'],
                'è®¡ç®—æœº': ['è®¡ç®—æœº', 'è½¯ä»¶', 'äººå·¥æ™ºèƒ½', 'ai', 'computer', 'software'],
                'ç‰©ç†å­¦': ['ç‰©ç†', 'physics'],
                'åŒ–å­¦': ['åŒ–å­¦', 'chemistry'],
                'ç”Ÿç‰©å­¦': ['ç”Ÿç‰©', 'biology'],
                'ç»Ÿè®¡å­¦': ['ç»Ÿè®¡', 'statistics'],
                'æœºæ¢°å·¥ç¨‹': ['æœºæ¢°', 'æœºæ¢°å·¥ç¨‹', 'mechanical'],
                'ç”µå­ä¿¡æ¯': ['ç”µå­', 'é€šä¿¡', 'ä¿¡æ¯', 'ç”µå­ä¿¡æ¯', 'electronic'],
                'åœŸæœ¨å·¥ç¨‹': ['åœŸæœ¨', 'åœŸæœ¨å·¥ç¨‹', 'civil'],
                'ç¯å¢ƒç§‘å­¦': ['ç¯å¢ƒ', 'ç¯å¢ƒç§‘å­¦', 'environment']
            }

            conditions = []
            params = []

            for subject_name, keywords in subject_keywords.items():
                for keyword in keywords:
                    if keyword in question_lower:
                        conditions.append("subject_name LIKE %s")
                        params.append(f"%{subject_name}%")
                        break

            school_pattern = r'([\u4e00-\u9fa5]+å¤§å­¦)'
            school_matches = re.findall(school_pattern, question)
            if school_matches:
                for school in school_matches:
                    conditions.append("school_name LIKE %s")
                    params.append(f"%{school}%")

            if conditions:
                query = """
                SELECT 
                    subject_name, school_name, ranking_position_2025, ranking_position_2024,
                    score_2025, score_2024, subject_category
                FROM shanghai_subject_rankings 
                WHERE """ + " OR ".join(conditions)

                if 'å‰å' in question or 'å‰10' in question or 'top10' in question_lower:
                    query += " AND ranking_position_2025 <= 10 ORDER BY ranking_position_2025"
                elif 'å‰äºŒå' in question or 'å‰20' in question or 'top20' in question_lower:
                    query += " AND ranking_position_2025 <= 20 ORDER BY ranking_position_2025"
                elif 'å‰äº”å' in question or 'å‰50' in question or 'top50' in question_lower:
                    query += " AND ranking_position_2025 <= 50 ORDER BY ranking_position_2025"
                elif 'å‰ä¸€ç™¾' in question or 'å‰100' in question or 'top100' in question_lower:
                    query += " AND ranking_position_2025 <= 100 ORDER BY ranking_position_2025"
                else:
                    query += " ORDER BY subject_name, ranking_position_2025"

                cursor.execute(query, params)
            else:
                query = """
                SELECT 
                    subject_name, school_name, ranking_position_2025, ranking_position_2024,
                    score_2025, score_2024, subject_category
                FROM shanghai_subject_rankings 
                WHERE ranking_position_2025 <= 50
                ORDER BY subject_name, ranking_position_2025
                """
                cursor.execute(query)

            results = cursor.fetchall()
            return results

    except pymysql.Error as e:
        print(f"è½¯ç§‘æ’åæŸ¥è¯¢é”™è¯¯: {e}")
        return []
    finally:
        connection.close()


def format_shanghai_ranking_results(results):
    """æ ¼å¼åŒ–è½¯ç§‘æ’åæŸ¥è¯¢ç»“æœ"""
    if not results:
        return "æœªåœ¨è½¯ç§‘æ’åæ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

    grouped_results = {}
    for result in results:
        subject_name = result['subject_name']
        if subject_name not in grouped_results:
            grouped_results[subject_name] = []
        grouped_results[subject_name].append(result)

    formatted = "**è½¯ç§‘2025å­¦ç§‘æ’åä¿¡æ¯ï¼š**\n\n"

    for subject_name, rankings in grouped_results.items():
        formatted += f"**{subject_name}**\n"

        max_display = 20
        for i, ranking in enumerate(rankings[:max_display]):
            formatted += f"{i + 1:2d}. {ranking['school_name']:<20s} "
            formatted += f"æ’å2025: {ranking['ranking_position_2025']:3d} "

            if ranking['ranking_position_2024'] > 0:
                formatted += f"æ’å2024: {ranking['ranking_position_2024']:3d} "

            if ranking['score_2025'] > 0:
                formatted += f"åˆ†æ•°: {ranking['score_2025']:.1f}"

            formatted += "\n"

        if len(rankings) > max_display:
            formatted += f"  ... è¿˜æœ‰ {len(rankings) - max_display} æ‰€å­¦æ ¡\n"

        formatted += "\n"

    formatted += """
---
**è¯´æ˜**ï¼š
1. æ’ååŸºäºè½¯ç§‘2025å¹´ä¸­å›½å¤§å­¦å­¦ç§‘æ’å
2. æ’å2025ä¸ºæœ€æ–°æ’åï¼Œæ’å2024ä¸ºä¸Šä¸€å¹´æ’åï¼ˆå¦‚æœ‰ï¼‰
3. åˆ†æ•°ä¸ºå­¦ç§‘ç»¼åˆå¾—åˆ†ï¼ˆæ»¡åˆ†100ï¼‰
4. æ•°æ®æ¥æºï¼šhttps://www.shanghairanking.cn/
"""

    return formatted


def combine_query_results(question):
    """åˆå¹¶è€ƒè¯•ç§‘ç›®å’Œæ’åæŸ¥è¯¢ç»“æœ"""
    exam_results = query_database(question)
    exam_context = format_database_results(exam_results)

    ranking_results = query_shanghai_ranking(question)
    ranking_context = format_shanghai_ranking_results(ranking_results)

    combined_context = ""

    if "æœªåœ¨æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯" not in exam_context:
        combined_context += f"**è€ƒç ”ä¸“ä¸šä¿¡æ¯ï¼š**\n{exam_context}\n\n"

    if "æœªåœ¨è½¯ç§‘æ’åæ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯" not in ranking_context:
        combined_context += f"**è½¯ç§‘æ’åä¿¡æ¯ï¼š**\n{ranking_context}"

    if not combined_context:
        combined_context = "æŠ±æ­‰ï¼Œæœªåœ¨æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

    return combined_context


def login_page():
    """ç™»å½•é¡µé¢"""
    st.title("ğŸ“ è€ƒç ”AIé—®ç­”ç³»ç»Ÿ - ç™»å½•")

    with st.form("login_form"):
        email = st.text_input("é‚®ç®±", placeholder="è¯·è¾“å…¥æ³¨å†Œé‚®ç®±", key="login_email")
        password = st.text_input("å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ", key="login_password")
        submit = st.form_submit_button("ç™»å½•", type="primary")

        if submit:
            if not email or not password:
                st.error("è¯·è¾“å…¥é‚®ç®±å’Œå¯†ç ")
            else:
                if not validate_email(email):
                    st.error("é‚®ç®±æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„é‚®ç®±åœ°å€")
                else:
                    success, user = verify_user_by_email(email, password)
                    if success:
                        st.session_state.user = user
                        st.session_state.page = "main"
                        st.success(f"ç™»å½•æˆåŠŸï¼Œæ¬¢è¿ {user['username']}ï¼")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("é‚®ç®±æˆ–å¯†ç é”™è¯¯")

    st.markdown("---")
    st.write("è¿˜æ²¡æœ‰è´¦å·ï¼Ÿ")

    col1, col2 = st.columns([1, 2])
    with col1:
        if st.button("ç«‹å³æ³¨å†Œ", key="to_register"):
            st.session_state.page = "register"
            st.rerun()


def verify_user_by_email(email, password):
    """é€šè¿‡é‚®ç®±éªŒè¯ç”¨æˆ·ç™»å½•"""
    connection = get_db_connection()
    if not connection:
        return False, None

    try:
        with connection.cursor() as cursor:
            password_hash = hash_password(password)

            cursor.execute(
                "SELECT id, username, email FROM users WHERE email = %s AND password_hash = %s AND is_active = TRUE",
                (email, password_hash)
            )

            user = cursor.fetchone()
            if user:
                cursor.execute(
                    "UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = %s",
                    (user['id'],)
                )
                connection.commit()
                return True, user
            else:
                return False, None

    except pymysql.Error as e:
        return False, None
    finally:
        connection.close()


def register_page():
    """æ³¨å†Œé¡µé¢"""
    st.title("ğŸ“ è€ƒç ”AIé—®ç­”ç³»ç»Ÿ - æ³¨å†Œ")

    with st.form("register_form"):
        username = st.text_input("ç”¨æˆ·å", placeholder="3-50ä¸ªå­—ç¬¦ï¼Œåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
        email = st.text_input("é‚®ç®±", placeholder="è¯·è¾“å…¥æœ‰æ•ˆçš„é‚®ç®±åœ°å€")
        password = st.text_input("å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
        confirm_password = st.text_input("ç¡®è®¤å¯†ç ", type="password", placeholder="è¯·å†æ¬¡è¾“å…¥å¯†ç ")
        submit = st.form_submit_button("æ³¨å†Œ")

        if submit:
            if not username or not email or not password:
                st.error("è¯·å¡«å†™æ‰€æœ‰å­—æ®µ")
            elif not validate_username(username):
                st.error("ç”¨æˆ·åæ ¼å¼ä¸æ­£ç¡®ï¼ˆ3-50ä¸ªå­—ç¬¦ï¼Œåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿ï¼‰")
            elif not validate_email(email):
                st.error("é‚®ç®±æ ¼å¼ä¸æ­£ç¡®")
            elif password != confirm_password:
                st.error("ä¸¤æ¬¡è¾“å…¥çš„å¯†ç ä¸ä¸€è‡´")
            elif len(password) < 6:
                st.error("å¯†ç é•¿åº¦è‡³å°‘6ä½")
            else:
                success, message = register_user(username, email, password)
                if success:
                    st.success(message)
                    st.info("è¯·è¿”å›ç™»å½•é¡µé¢ç™»å½•")
                else:
                    st.error(message)

    st.markdown("---")
    st.write("å·²æœ‰è´¦å·ï¼Ÿ")
    if st.button("è¿”å›ç™»å½•"):
        st.session_state.page = "login"
        st.rerun()


def clear_chat_history(user_id):
    """æ¸…ç©ºç”¨æˆ·çš„èŠå¤©å†å²è®°å½•"""
    connection = get_db_connection()
    if not connection:
        return False

    try:
        with connection.cursor() as cursor:
            cursor.execute(
                "DELETE FROM chat_history WHERE user_id = %s",
                (user_id,)
            )
        connection.commit()
        return True
    except pymysql.Error:
        return False
    finally:
        connection.close()


def main_page():
    """ä¸»é¡µé¢ - AIé—®ç­”"""
    st.title("ğŸ¤– è€ƒç ”AIæ™ºèƒ½é—®ç­”")

    col1, col2, col3 = st.columns([3, 1, 1])
    with col1:
        st.write(f"æ¬¢è¿ï¼Œ**{st.session_state.user['username']}**ï¼")
    with col2:
        if st.button("ğŸ“Š æ•°æ®æŸ¥è¯¢"):
            st.session_state.page = "data_query"
            st.rerun()
    with col3:
        if st.button("ğŸšª é€€å‡ºç™»å½•"):
            st.session_state.clear()
            st.rerun()

    st.markdown("---")

    if 'show_clear_confirm' not in st.session_state:
        st.session_state.show_clear_confirm = False

    if 'messages' not in st.session_state:
        st.session_state.messages = []
        history = get_chat_history(st.session_state.user['id'])
        for item in history:
            st.session_state.messages.append({"role": "user", "content": item['question']})
            st.session_state.messages.append({"role": "assistant", "content": item['answer']})

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    st.subheader("ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼š")
    examples = [
        "ä¸­å›½åœ°è´¨å¤§å­¦ä¿¡æ¯å®‰å…¨ä¸“ä¸šæœ‰å“ªäº›ç ”ç©¶æ–¹å‘ï¼Ÿ",
        "æµ™æ±Ÿå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šçš„è€ƒè¯•ç§‘ç›®æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è½¯ç§‘æ•°å­¦ä¸“ä¸šæ’åå‰åçš„å­¦æ ¡æœ‰å“ªäº›ï¼Ÿ",
        "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯çš„è½¯ç§‘æ’åæƒ…å†µå¦‚ä½•ï¼Ÿ"
    ]

    cols = st.columns(4)
    for i, example in enumerate(examples):
        with cols[i]:
            if st.button(example[:15] + "..." if len(example) > 15 else example, key=f"example_{i}"):
                st.session_state.new_question = example

    question = st.text_area(
        "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š",
        value=st.session_state.get('new_question', ''),
        height=100,
        placeholder="ä¾‹å¦‚ï¼šä¸­å›½åœ°è´¨å¤§å­¦ä¿¡æ¯å®‰å…¨ä¸“ä¸šæœ‰å“ªäº›ç ”ç©¶æ–¹å‘ï¼Ÿæˆ–ï¼šè½¯ç§‘æ•°å­¦æ’åå‰åçš„å­¦æ ¡ï¼Ÿ"
    )

    col1, col2, col3 = st.columns([4, 1, 1])
    with col1:
        if st.button("ğŸ” è·å–ç­”æ¡ˆ", type="primary", use_container_width=True):
            if question:
                st.session_state.messages.append({"role": "user", "content": question})

                with st.chat_message("user"):
                    st.markdown(question)

                with st.chat_message("assistant"):
                    with st.spinner("æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“å¹¶ç”Ÿæˆå›ç­”..."):
                        context = combine_query_results(question)

                        with st.expander("æŸ¥çœ‹æ•°æ®åº“åŸå§‹æŸ¥è¯¢ç»“æœ", expanded=False):
                            exam_results = query_database(question)
                            if exam_results:
                                st.subheader("è€ƒè¯•ç§‘ç›®æ•°æ®")
                                df_exam = pd.DataFrame(exam_results)
                                display_cols = ['school_name', 'major_name', 'research_directions', 'departments']
                                if all(col in df_exam.columns for col in display_cols):
                                    st.dataframe(df_exam[display_cols])
                                else:
                                    st.dataframe(df_exam)
                            else:
                                st.info("è€ƒè¯•ç§‘ç›®æ•°æ®åº“æœªæŸ¥è¯¢åˆ°ç›¸å…³è®°å½•")

                            ranking_results = query_shanghai_ranking(question)
                            if ranking_results:
                                st.subheader("è½¯ç§‘æ’åæ•°æ®")
                                df_ranking = pd.DataFrame(ranking_results)
                                st.dataframe(df_ranking)
                            else:
                                st.info("è½¯ç§‘æ’åæ•°æ®åº“æœªæŸ¥è¯¢åˆ°ç›¸å…³è®°å½•")

                        response = call_deepseek_api(question, context)

                        st.markdown(response)

                        save_chat_history(st.session_state.user['id'], question, response)

                st.session_state.messages.append({"role": "assistant", "content": response})

                if 'new_question' in st.session_state:
                    del st.session_state.new_question
            else:
                st.warning("è¯·è¾“å…¥é—®é¢˜")
    with col2:
        if st.button("æ¸…ç©ºå½“å‰å¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            st.success("å½“å‰å¯¹è¯å·²æ¸…ç©º")
            st.rerun()
    with col3:
        if st.button("æ¸…ç©ºå†å²è®°å½•", use_container_width=True):
            st.session_state.show_clear_confirm = True

    if st.session_state.show_clear_confirm:
        st.warning("âš ï¸ ç¡®å®šè¦æ°¸ä¹…åˆ é™¤æ‰€æœ‰å†å²è®°å½•å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ï¼")
        col_yes, col_no = st.columns(2)
        with col_yes:
            if st.button("ç¡®å®šåˆ é™¤", type="primary"):
                if clear_chat_history(st.session_state.user['id']):
                    st.session_state.messages = []
                    st.session_state.show_clear_confirm = False
                    st.success("æ‰€æœ‰å†å²è®°å½•å·²æ°¸ä¹…åˆ é™¤")
                    st.rerun()
        with col_no:
            if st.button("å–æ¶ˆ"):
                st.session_state.show_clear_confirm = False
                st.rerun()


def data_query_page():
    """æ•°æ®æŸ¥è¯¢é¡µé¢"""
    st.title("ğŸ“š è€ƒç ”æ•°æ®æŸ¥è¯¢")

    col1, col2, col3 = st.columns([3, 1, 1])
    with col1:
        st.write(f"æ¬¢è¿ï¼Œ**{st.session_state.user['username']}**ï¼")
    with col2:
        if st.button("ğŸ¤– AIé—®ç­”"):
            st.session_state.page = "main"
            st.rerun()
    with col3:
        if st.button("ğŸšª é€€å‡ºç™»å½•"):
            st.session_state.clear()
            st.rerun()

    st.markdown("---")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” æ¡ä»¶æŸ¥è¯¢", "ğŸ« å­¦æ ¡æµè§ˆ", "ğŸ“Š æ•°æ®ç»Ÿè®¡", "ğŸ¥‡ è½¯ç§‘æ’å"])

    with tab1:
        st.subheader("æ¡ä»¶æŸ¥è¯¢")
        col1, col2 = st.columns(2)
        with col1:
            school_name = st.text_input("å­¦æ ¡åç§°", key="query_school")
        with col2:
            major_name = st.text_input("ä¸“ä¸šåç§°", key="query_major")

        if st.button("æŸ¥è¯¢", key="query_btn"):
            if school_name or major_name:
                connection = get_db_connection()
                if connection:
                    try:
                        with connection.cursor() as cursor:
                            query = "SELECT * FROM exam_subjects WHERE 1=1"
                            params = []

                            if school_name:
                                query += " AND school_name LIKE %s"
                                params.append(f"%{school_name}%")
                            if major_name:
                                query += " AND major_name LIKE %s"
                                params.append(f"%{major_name}%")

                            query += " ORDER BY school_name, major_name LIMIT 50"
                            cursor.execute(query, params)
                            results = cursor.fetchall()

                            if results:
                                st.subheader(f"æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
                                for result in results:
                                    with st.expander(f"{result['school_name']} - {result['major_name']}"):
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.write("**åŸºæœ¬ä¿¡æ¯**")
                                            st.write(f"ä¸“ä¸šä»£ç ï¼š{result.get('major_code', '')}")
                                            st.write(f"é™¢ç³»ï¼š{result.get('department', '')}")
                                            st.write(f"ç ”ç©¶æ–¹å‘ï¼š{result.get('research_direction', '')}")
                                            st.write(f"æ‹›ç”Ÿäººæ•°ï¼š{result.get('enrollment_plan', '')}")
                                            st.write(f"åœ°åŒºï¼š{result.get('region', '')}")

                                        with col2:
                                            st.write("**è€ƒè¯•ç§‘ç›®**")
                                            if result.get('politics_subject'):
                                                st.write(f"æ”¿æ²»ï¼š{result['politics_subject']}")
                                            if result.get('foreign_language_subject'):
                                                st.write(f"å¤–è¯­ï¼š{result['foreign_language_subject']}")
                                            if result.get('business_subject1'):
                                                st.write(f"ä¸šåŠ¡è¯¾ä¸€ï¼š{result['business_subject1']}")
                                            if result.get('business_subject2'):
                                                st.write(f"ä¸šåŠ¡è¯¾äºŒï¼š{result['business_subject2']}")

                                        if result.get('exam_scope'):
                                            st.write(f"**è€ƒè¯•èŒƒå›´ï¼š** {result['exam_scope']}")

                                        if result.get('reference_books'):
                                            st.write(f"**å‚è€ƒä¹¦ç±ï¼š** {result['reference_books']}")
                            else:
                                st.warning("æœªæ‰¾åˆ°ç›¸å…³æ•°æ®")

                    except pymysql.Error as e:
                        st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    finally:
                        connection.close()
            else:
                st.warning("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶")

    with tab2:
        st.subheader("å­¦æ ¡ä¸“ä¸šæµè§ˆ")
        schools = get_school_list()

        if schools:
            selected_school = st.selectbox("é€‰æ‹©å­¦æ ¡", schools, key="browse_school")

            if selected_school:
                connection = get_db_connection()
                if connection:
                    try:
                        with connection.cursor() as cursor:
                            cursor.execute(
                                "SELECT DISTINCT major_name FROM exam_subjects WHERE school_name = %s ORDER BY major_name",
                                (selected_school,)
                            )
                            majors = [row['major_name'] for row in cursor.fetchall()]

                            if majors:
                                selected_major = st.selectbox("é€‰æ‹©ä¸“ä¸š", majors, key="browse_major")

                                if selected_major:
                                    cursor.execute(
                                        "SELECT * FROM exam_subjects WHERE school_name = %s AND major_name = %s ORDER BY department",
                                        (selected_school, selected_major)
                                    )
                                    results = cursor.fetchall()

                                    if results:
                                        for result in results:
                                            with st.expander(
                                                    f"{result['department']} - {result.get('research_direction', 'ä¸åŒºåˆ†ç ”ç©¶æ–¹å‘')}"):
                                                col1, col2 = st.columns(2)
                                                with col1:
                                                    st.write("**åŸºæœ¬ä¿¡æ¯**")
                                                    st.write(f"ä¸“ä¸šä»£ç ï¼š{result.get('major_code', '')}")
                                                    st.write(f"æ‹›ç”Ÿäººæ•°ï¼š{result.get('enrollment_plan', '')}")

                                                with col2:
                                                    st.write("**è€ƒè¯•ç§‘ç›®**")
                                                    if result.get('politics_subject'):
                                                        st.write(f"æ”¿æ²»ï¼š{result['politics_subject']}")
                                                    if result.get('foreign_language_subject'):
                                                        st.write(f"å¤–è¯­ï¼š{result['foreign_language_subject']}")
                                                    if result.get('business_subject1'):
                                                        st.write(f"ä¸šåŠ¡è¯¾ä¸€ï¼š{result['business_subject1']}")
                                                    if result.get('business_subject2'):
                                                        st.write(f"ä¸šåŠ¡è¯¾äºŒï¼š{result['business_subject2']}")
                            else:
                                st.warning("è¯¥å­¦æ ¡æš‚æ— ä¸“ä¸šä¿¡æ¯")

                    except pymysql.Error as e:
                        st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    finally:
                        connection.close()
        else:
            st.warning("æš‚æ— å­¦æ ¡æ•°æ®")

    with tab3:
        st.subheader("æ•°æ®ç»Ÿè®¡")
        connection = get_db_connection()
        if connection:
            try:
                with connection.cursor() as cursor:
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        cursor.execute("SELECT COUNT(*) FROM exam_subjects")
                        total_records = cursor.fetchone()['COUNT(*)']
                        st.metric("æ€»è®°å½•æ•°", total_records)

                    with col2:
                        cursor.execute("SELECT COUNT(DISTINCT school_name) FROM exam_subjects")
                        total_schools = cursor.fetchone()['COUNT(DISTINCT school_name)']
                        st.metric("è¦†ç›–é«˜æ ¡æ•°", total_schools)

                    with col3:
                        cursor.execute("SELECT COUNT(DISTINCT major_name) FROM exam_subjects")
                        total_majors = cursor.fetchone()['COUNT(DISTINCT major_name)']
                        st.metric("ä¸“ä¸šæ•°é‡", total_majors)

                    st.subheader("çƒ­é—¨ä¸“ä¸šTOP 10")
                    cursor.execute("""
                        SELECT major_name, COUNT(*) as count 
                        FROM exam_subjects 
                        GROUP BY major_name 
                        ORDER BY count DESC 
                        LIMIT 10
                    """)
                    major_stats = cursor.fetchall()

                    if major_stats:
                        df_major = pd.DataFrame(major_stats)
                        st.dataframe(df_major, use_container_width=True)

                    st.subheader("åœ°åŒºåˆ†å¸ƒ")
                    cursor.execute(
                        "SELECT region, COUNT(*) as count FROM exam_subjects GROUP BY region ORDER BY count DESC")
                    region_stats = cursor.fetchall()

                    if region_stats:
                        df_region = pd.DataFrame(region_stats)
                        st.bar_chart(df_region.set_index('region'))

            except pymysql.Error as e:
                st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            finally:
                connection.close()

    with tab4:
        st.subheader("è½¯ç§‘æ’åæŸ¥è¯¢")

        col1, col2 = st.columns(2)
        with col1:
            ranking_subject = st.text_input("å­¦ç§‘åç§°ï¼ˆå¦‚ï¼šæ•°å­¦ã€è®¡ç®—æœºï¼‰", key="ranking_subject")
        with col2:
            ranking_school = st.text_input("å­¦æ ¡åç§°", key="ranking_school")

        col3, col4 = st.columns(2)
        with col3:
            top_n = st.selectbox("æ˜¾ç¤ºå‰Nå", [10, 20, 50, 100, 200], index=0)
        with col4:
            subject_category = st.selectbox("å­¦ç§‘ç±»åˆ«", ["å…¨éƒ¨", "ç†å­¦", "å·¥å­¦", "å…¶ä»–"], index=0)

        if st.button("æŸ¥è¯¢æ’å", key="query_ranking"):
            connection = get_db_connection()
            if connection:
                try:
                    with connection.cursor() as cursor:
                        query = """
                        SELECT 
                            subject_name, school_name, ranking_position_2025, ranking_position_2024,
                            score_2025, score_2024, subject_category
                        FROM shanghai_subject_rankings 
                        WHERE 1=1
                        """
                        params = []

                        if ranking_subject:
                            query += " AND subject_name LIKE %s"
                            params.append(f"%{ranking_subject}%")

                        if ranking_school:
                            query += " AND school_name LIKE %s"
                            params.append(f"%{ranking_school}%")

                        if subject_category != "å…¨éƒ¨":
                            query += " AND subject_category = %s"
                            params.append(subject_category)

                        query += f" AND ranking_position_2025 <= {top_n}"
                        query += " ORDER BY subject_name, ranking_position_2025"

                        cursor.execute(query, params)
                        results = cursor.fetchall()

                        if results:
                            grouped_results = {}
                            for result in results:
                                subject_name = result['subject_name']
                                if subject_name not in grouped_results:
                                    grouped_results[subject_name] = []
                                grouped_results[subject_name].append(result)

                            for subject_name, rankings in grouped_results.items():
                                st.subheader(f"{subject_name}")

                                df = pd.DataFrame(rankings)
                                df = df[['school_name', 'ranking_position_2025', 'ranking_position_2024', 'score_2025',
                                         'subject_category']]
                                df.columns = ['å­¦æ ¡åç§°', '2025æ’å', '2024æ’å', '2025åˆ†æ•°', 'å­¦ç§‘ç±»åˆ«']

                                st.dataframe(df, use_container_width=True)

                                chart_df = df.head(10).copy()
                                if not chart_df.empty:
                                    chart_df = chart_df.sort_values('2025æ’å')
                                    st.bar_chart(chart_df.set_index('å­¦æ ¡åç§°')['2025åˆ†æ•°'])
                        else:
                            st.warning("æœªæ‰¾åˆ°ç›¸å…³æ’åæ•°æ®")

                except pymysql.Error as e:
                    st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                finally:
                    connection.close()


def interactive_crawler_ui():
    """äº¤äº’å¼çˆ¬è™«ç•Œé¢"""
    print("=" * 60)
    print("æ¬¢è¿ä½¿ç”¨è€ƒç ”æ•°æ®çˆ¬è™«ç³»ç»Ÿ")
    print("=" * 60)

    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
        print("1. æŒ‰åœ°åŒºæœç´¢çˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯")
        print("2. æŒ‰å­¦æ ¡æœç´¢çˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯")
        print("3. è¿è¡Œè½¯ç§‘æ’åçˆ¬è™«")
        print("4. åˆ é™¤æ•°æ®")
        print("5. é€€å‡º")

        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()

        if choice == "1":
            crawl_by_region()
        elif choice == "2":
            crawl_by_school()
        elif choice == "3":
            crawl_shanghai_ranking()
        elif choice == "4":
            delete_data()
        elif choice == "5":
            print("æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        else:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")


def crawl_by_region():
    """æŒ‰åœ°åŒºçˆ¬å–"""
    print("\n=== æŒ‰åœ°åŒºçˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯ ===")
    spider = CompleteInfoSpider()

    regions, features = spider.select_region_and_features()

    if not regions:
        print("æœªé€‰æ‹©ä»»ä½•åœ°åŒºï¼Œè¿”å›ä¸»èœå•")
        return

    print(f"\nå·²é€‰æ‹©åœ°åŒº: {regions}")
    print(f"å·²é€‰æ‹©é™¢æ ¡ç‰¹æ€§: {features}")

    confirm = input("ç¡®è®¤å¼€å§‹çˆ¬å–å—ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆçˆ¬å–")
        return

    print("\nå¼€å§‹çˆ¬å–...")
    spider.crawl_by_regions_and_features(regions, features)
    print(f"\nçˆ¬å–å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“å’ŒExcelæ–‡ä»¶: {spider.excel_filename}")


def crawl_by_school():
    """æŒ‰å­¦æ ¡çˆ¬å–"""
    print("\n=== æŒ‰å­¦æ ¡çˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯ ===")
    spider = CompleteInfoSpider()

    school_names = spider.select_schools_by_name()

    if not school_names:
        print("æœªè¾“å…¥ä»»ä½•å­¦æ ¡åç§°ï¼Œè¿”å›ä¸»èœå•")
        return

    print(f"\nå·²é€‰æ‹©å­¦æ ¡: {school_names}")

    confirm = input("ç¡®è®¤å¼€å§‹çˆ¬å–å—ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆçˆ¬å–")
        return

    print("\nå¼€å§‹çˆ¬å–...")
    spider.crawl_by_school_names(school_names)
    print(f"\nçˆ¬å–å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“å’ŒExcelæ–‡ä»¶: {spider.excel_filename}")


def crawl_shanghai_ranking():
    """çˆ¬å–è½¯ç§‘æ’å"""
    print("\n=== çˆ¬å–è½¯ç§‘æ’å ===")

    spider = ShanghaiRankingSpider(headless=True)

    try:
        print("\næ­£åœ¨ä»è½¯ç§‘å®˜ç½‘è·å–å­¦ç§‘åˆ—è¡¨...")
        subjects_data = spider.fetch_all_subjects_from_web()

        if not subjects_data:
            print("è·å–å­¦ç§‘åˆ—è¡¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç½‘ç«™ç»“æ„æ˜¯å¦å˜åŒ–")
            return

        subject_mapping = spider.display_all_subjects()

        if not subject_mapping:
            print("æœªæ‰¾åˆ°å¯ç”¨å­¦ç§‘")
            return

        print("\nè¯·é€‰æ‹©çˆ¬å–æ¨¡å¼ï¼š")
        print("1. é€‰æ‹©ç‰¹å®šå­¦ç§‘çˆ¬å–")
        print("2. çˆ¬å–æ‰€æœ‰å­¦ç§‘ï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰")
        print("3. æŒ‰å­¦ç§‘ç±»åˆ«çˆ¬å–")
        print("4. è¿”å›ä¸»èœå•")

        mode = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-4): ").strip()

        if mode == "1":
            while True:
                selection = input("\nè¯·è¾“å…¥è¦çˆ¬å–çš„å­¦ç§‘ç¼–å·ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œ0è¿”å›ï¼‰: ").strip()

                if selection == "0":
                    print("è¿”å›ä¸»èœå•")
                    return

                try:
                    selected_indices = [int(idx.strip()) for idx in selection.split(',') if idx.strip().isdigit()]
                    valid_indices = [idx for idx in selected_indices if 1 <= idx <= len(subject_mapping)]

                    if not valid_indices:
                        print("æ— æ•ˆçš„ç¼–å·ï¼Œè¯·é‡æ–°è¾“å…¥")
                        continue

                    selected_subjects = []
                    for idx in valid_indices:
                        subject_code, subject_name, category_code, category_name = subject_mapping[idx]
                        selected_subjects.append((subject_code, subject_name))
                        print(f"  - {subject_code} {subject_name}")

                    confirm = input(f"\nç¡®è®¤çˆ¬å–ä»¥ä¸Š {len(selected_subjects)} ä¸ªå­¦ç§‘å—ï¼Ÿ(y/n): ").strip().lower()
                    if confirm != 'y':
                        print("å·²å–æ¶ˆçˆ¬å–")
                        continue

                    print("\nå¼€å§‹çˆ¬å–...")
                    all_data = []

                    for i, (subject_code, subject_name) in enumerate(selected_subjects):
                        print(f"\n[{i + 1}/{len(selected_subjects)}] çˆ¬å–å­¦ç§‘: {subject_name} ({subject_code})")
                        data = spider.fetch_subject_data(subject_code, subject_name, max_pages=3)
                        if data:
                            spider.save_subject_rankings_to_db(data)
                            all_data.extend(data)
                            print(f"  å·²çˆ¬å– {len(data)} æ¡æ•°æ®")
                        else:
                            print(f"  æœªè·å–åˆ°æ•°æ®")

                        if i < len(selected_subjects) - 1:
                            delay = random.uniform(3, 8)
                            print(f"  ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                            time.sleep(delay)

                    print(f"\nçˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡æ•°æ®")
                    break

                except ValueError:
                    print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")

        elif mode == "2":
            total_subjects = len(subject_mapping)
            print(f"\nè­¦å‘Šï¼šå°†çˆ¬å–å…¨éƒ¨ {total_subjects} ä¸ªå­¦ç§‘ï¼Œè¿™å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼")

            confirm = input("ç¡®è®¤çˆ¬å–æ‰€æœ‰å­¦ç§‘å—ï¼Ÿ(y/n): ").strip().lower()
            if confirm != 'y':
                print("å·²å–æ¶ˆçˆ¬å–")
                return

            print("\nå¼€å§‹çˆ¬å–æ‰€æœ‰å­¦ç§‘...")
            all_data = []
            current = 1

            for idx in range(1, total_subjects + 1):
                subject_code, subject_name, category_code, category_name = subject_mapping[idx]
                print(f"\n[{current}/{total_subjects}] çˆ¬å–å­¦ç§‘: {subject_name} ({subject_code})")

                data = spider.fetch_subject_data(subject_code, subject_name, max_pages=2)
                if data:
                    spider.save_subject_rankings_to_db(data)
                    all_data.extend(data)
                    print(f"  å·²çˆ¬å– {len(data)} æ¡æ•°æ®")
                else:
                    print(f"  æœªè·å–åˆ°æ•°æ®")

                current += 1

                if current <= total_subjects:
                    delay = random.uniform(5, 10)
                    print(f"  ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                    time.sleep(delay)

            print(f"\næ‰€æœ‰å­¦ç§‘çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡æ•°æ®")

        elif mode == "3":
            print("\nè¯·é€‰æ‹©å­¦ç§‘ç±»åˆ«ï¼š")

            categories = {}
            for category_code, category_info in subjects_data.items():
                categories[category_code] = category_info['category_name']

            sorted_cat_codes = sorted(categories.keys())
            for i, cat_code in enumerate(sorted_cat_codes, 1):
                print(f"{i:2d}. [{cat_code}] {categories[cat_code]}")

            print("0. è¿”å›")

            while True:
                cat_selection = input("\nè¯·è¾“å…¥ç±»åˆ«ç¼–å·ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰: ").strip()

                if cat_selection == "0":
                    print("è¿”å›")
                    break

                try:
                    selected_cat_indices = [int(idx.strip()) for idx in cat_selection.split(',') if
                                            idx.strip().isdigit()]
                    valid_cat_indices = [idx for idx in selected_cat_indices if 1 <= idx <= len(categories)]

                    if not valid_cat_indices:
                        print("æ— æ•ˆçš„ç¼–å·ï¼Œè¯·é‡æ–°è¾“å…¥")
                        continue

                    selected_categories = []
                    cat_keys = list(categories.keys())
                    for idx in valid_cat_indices:
                        cat_code = cat_keys[idx - 1]
                        cat_name = categories[cat_code]
                        selected_categories.append((cat_code, cat_name))

                    total_subjects_in_cats = 0
                    for cat_code, cat_name in selected_categories:
                        subjects_in_cat = subjects_data[cat_code]['subjects']
                        total_subjects_in_cats += len(subjects_in_cat)
                        print(f"\nç±»åˆ« [{cat_code}] {cat_name}: {len(subjects_in_cat)} ä¸ªå­¦ç§‘")
                        for subj_code, subj_name in subjects_in_cat:
                            print(f"  - {subj_code} {subj_name}")

                    confirm = input(
                        f"\nç¡®è®¤çˆ¬å–ä»¥ä¸Š {len(selected_categories)} ä¸ªç±»åˆ«å…± {total_subjects_in_cats} ä¸ªå­¦ç§‘å—ï¼Ÿ(y/n): ").strip().lower()
                    if confirm != 'y':
                        print("å·²å–æ¶ˆçˆ¬å–")
                        continue

                    print("\nå¼€å§‹çˆ¬å–...")
                    all_data = []
                    total_processed = 0

                    for cat_code, cat_name in selected_categories:
                        print(f"\n=== çˆ¬å–ç±»åˆ«: {cat_name} ===")
                        subjects_in_cat = subjects_data[cat_code]['subjects']

                        for i, (subject_code, subject_name) in enumerate(subjects_in_cat):
                            total_processed += 1
                            print(f"\n[{total_processed}/{total_subjects_in_cats}] {subject_name} ({subject_code})")

                            data = spider.fetch_subject_data(subject_code, subject_name, max_pages=2)
                            if data:
                                spider.save_subject_rankings_to_db(data)
                                all_data.extend(data)
                                print(f"  å·²çˆ¬å– {len(data)} æ¡æ•°æ®")
                            else:
                                print(f"  æœªè·å–åˆ°æ•°æ®")

                            if total_processed < total_subjects_in_cats:
                                delay = random.uniform(4, 8)
                                print(f"  ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                                time.sleep(delay)

                    print(f"\nçˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡æ•°æ®")
                    break

                except ValueError:
                    print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")

        elif mode == "4":
            print("è¿”å›ä¸»èœå•")

        else:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¿”å›ä¸»èœå•")

    except Exception as e:
        print(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    finally:
        spider.close_driver()


def delete_data():
    """åˆ é™¤æ•°æ®"""
    print("\n=== åˆ é™¤æ•°æ® ===")

    print("\nè¯·é€‰æ‹©åˆ é™¤ç±»å‹ï¼š")
    print("1. æŒ‰åœ°åŒºåˆ é™¤è€ƒç ”ä¸“ä¸šä¿¡æ¯")
    print("2. æŒ‰å­¦æ ¡åˆ é™¤è€ƒç ”ä¸“ä¸šä¿¡æ¯")
    print("3. æŒ‰å­¦ç§‘åˆ é™¤è½¯ç§‘æ’å")
    print("4. æ¸…ç©ºæ‰€æœ‰è½¯ç§‘æ’åæ•°æ®")
    print("5. è¿”å›ä¸»èœå•")

    choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()

    if choice == "1":
        region = input("è¯·è¾“å…¥è¦åˆ é™¤çš„åœ°åŒºåç§°: ").strip()
        if region:
            spider = CompleteInfoSpider()
            if spider.delete_region_data(region):
                print(f"æˆåŠŸåˆ é™¤åœ°åŒº '{region}' çš„æ‰€æœ‰æ•°æ®")
            else:
                print(f"åˆ é™¤åœ°åŒº '{region}' æ•°æ®å¤±è´¥")

    elif choice == "2":
        school_name = input("è¯·è¾“å…¥è¦åˆ é™¤çš„å­¦æ ¡åç§°: ").strip()
        if school_name:
            spider = CompleteInfoSpider()
            if spider.delete_school_data(school_name, 'school'):
                print(f"æˆåŠŸåˆ é™¤å­¦æ ¡ '{school_name}' çš„æ‰€æœ‰æ•°æ®")
            else:
                print(f"åˆ é™¤å­¦æ ¡ '{school_name}' æ•°æ®å¤±è´¥")

    elif choice == "3":
        subject_name = input("è¯·è¾“å…¥è¦åˆ é™¤çš„å­¦ç§‘åç§°: ").strip()
        if subject_name:
            spider = ShanghaiRankingSpider()
            spider.delete_subject_data(subject_name)

    elif choice == "4":
        spider = ShanghaiRankingSpider()
        spider.clear_database()

    elif choice == "5":
        print("è¿”å›ä¸»èœå•")

    else:
        print("æ— æ•ˆé€‰é¡¹ï¼Œè¿”å›ä¸»èœå•")


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–æ•°æ®åº“
    if 'db_initialized' not in st.session_state:
        if init_database():
            st.session_state.db_initialized = True
        else:
            st.error("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥")
            return

    # é¡µé¢è·¯ç”±
    if 'page' not in st.session_state:
        st.session_state.page = "login"

    # æ ¹æ®å½“å‰é¡µé¢æ˜¾ç¤ºç›¸åº”å†…å®¹
    if st.session_state.page == "login":
        login_page()
    elif st.session_state.page == "register":
        register_page()
    elif st.session_state.page == "main":
        if 'user' in st.session_state:
            main_page()
        else:
            st.session_state.page = "login"
            st.rerun()
    elif st.session_state.page == "data_query":
        if 'user' in st.session_state:
            data_query_page()
        else:
            st.session_state.page = "login"
            st.rerun()


def is_running_in_streamlit():
    """æ£€æŸ¥æ˜¯å¦åœ¨Streamlitç¯å¢ƒä¸­è¿è¡Œ"""
    try:
        from streamlit.runtime.scriptrunner import get_script_run_ctx
        return get_script_run_ctx() is not None
    except:
        return False


def streamlit_main():
    """Streamlitåº”ç”¨çš„å…¥å£å‡½æ•°"""
    if 'db_initialized' not in st.session_state:
        if init_database():
            st.session_state.db_initialized = True
        else:
            st.error("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥")
            return

    if 'page' not in st.session_state:
        st.session_state.page = "login"

    if st.session_state.page == "login":
        login_page()
    elif st.session_state.page == "register":
        register_page()
    elif st.session_state.page == "main":
        if 'user' in st.session_state:
            main_page()
        else:
            st.session_state.page = "login"
            st.rerun()
    elif st.session_state.page == "data_query":
        if 'user' in st.session_state:
            data_query_page()
        else:
            st.session_state.page = "login"
            st.rerun()


def command_line_main():
    """å‘½ä»¤è¡Œçˆ¬è™«å·¥å…·çš„å…¥å£å‡½æ•°"""
    interactive_crawler_ui()


if __name__ == "__main__":
    # è‡ªåŠ¨æ£€æµ‹è¿è¡Œç¯å¢ƒ
    if is_running_in_streamlit():
        streamlit_main()
    else:
        command_line_main()
