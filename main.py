# main.py
import mysql.connector
from mysql.connector import Error as MySQLError
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options
from selenium.common.exceptions import InvalidSessionIdException, WebDriverException
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import logging
from datetime import datetime
import sys
import os
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
import streamlit as st
import hashlib
import pymysql
from pymysql.cursors import DictCursor

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="è€ƒç ”AIé—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'crawler_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

# å…¨å±€æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': 'your_password',
    'database': 'kaoyan_data'
}


class ThreadSafeSpider:
    """çº¿ç¨‹å®‰å…¨çš„çˆ¬è™«ç±»"""

    def __init__(self, thread_id=0):
        self.thread_id = thread_id
        self.retry_count = 0
        self.max_retries = 3
        self.setup_driver()

    def setup_driver(self):
        """é…ç½®Edgeæµè§ˆå™¨é©±åŠ¨"""
        edge_options = Options()

        # åŸºæœ¬è®¾ç½®
        edge_options.add_argument('--no-sandbox')
        edge_options.add_argument('--disable-dev-shm-usage')
        edge_options.add_argument('--window-size=1920,1080')
        edge_options.add_argument('--disable-gpu')

        # åæ£€æµ‹è®¾ç½®
        edge_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        edge_options.add_experimental_option('useAutomationExtension', False)
        edge_options.add_argument('--disable-blink-features=AutomationControlled')

        # ç¦ç”¨å›¾ç‰‡
        prefs = {'profile.default_content_setting_values': {'images': 2}}
        edge_options.add_experimental_option('prefs', prefs)

        edge_options.add_argument(
            '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
        )

        try:
            driver_path = 'msedgedriver.exe'
            service = Service(driver_path)
            self.driver = webdriver.Edge(service=service, options=edge_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

            # è¶…æ—¶æ—¶é—´
            self.driver.set_page_load_timeout(35)
            self.driver.implicitly_wait(7)
            self.wait = WebDriverWait(self.driver, 10)
            logging.info(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def restart_driver(self):
        """é‡å¯æµè§ˆå™¨é©±åŠ¨"""
        try:
            if hasattr(self, 'driver'):
                self.driver.quit()
        except:
            pass

        time.sleep(5)
        self.setup_driver()
        self.retry_count += 1
        logging.info(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨é©±åŠ¨å·²é‡å¯ï¼Œé‡è¯•æ¬¡æ•°: {self.retry_count}")

    def safe_execute(self, func, *args, **kwargs):
        """å®‰å…¨æ‰§è¡Œå‡½æ•°"""
        try:
            return func(*args, **kwargs)
        except (InvalidSessionIdException, WebDriverException, TimeoutException) as e:
            if self.retry_count < self.max_retries:
                logging.warning(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨ä¼šè¯å¤±æ•ˆï¼Œé‡å¯: {e}")
                self.restart_driver()
                time.sleep(3)
                return self.safe_execute(func, *args, **kwargs)
            else:
                logging.error(f"çº¿ç¨‹ {self.thread_id} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                raise
        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æ‰§è¡Œå‡½æ•°æ—¶å‡ºé”™: {e}")
            raise

    def wait_for_element(self, by, value, timeout=10):
        """ç­‰å¾…å…ƒç´ å‡ºç°"""
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.presence_of_element_located((by, value))
            )
            return element
        except TimeoutException:
            return None

    def wait_for_element_clickable(self, by, value, timeout=10):
        """ç­‰å¾…å…ƒç´ å¯ç‚¹å‡»"""
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.element_to_be_clickable((by, value))
            )
            return element
        except TimeoutException:
            return None

    def crawl_school_majors(self, school_name, major_link=None, region=None, school_features=None,
                            search_type='region'):
        """çˆ¬å–å­¦æ ¡ä¸“ä¸šä¿¡æ¯"""
        return self.safe_execute(self._crawl_school_majors_impl, school_name, major_link, region, school_features,
                                 search_type)

    def _crawl_school_majors_impl(self, school_name, major_link=None, region=None, school_features=None,
                                  search_type='region'):
        """çˆ¬å–å­¦æ ¡ä¸“ä¸šä¿¡æ¯çš„å®ç°"""
        all_majors_data = []

        # æœç´¢å…³é”®è¯
        search_keywords = [
            "è®¡ç®—æœº", "è½¯ä»¶å·¥ç¨‹", "äººå·¥æ™ºèƒ½", "ç½‘ç»œç©ºé—´å®‰å…¨", "æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯",
            "ä¿¡æ¯å®‰å…¨", "æ•°å­¦", "ç»Ÿè®¡å­¦", "åŒ»å­¦", "è¯å­¦", "æŠ¤ç†å­¦"
        ]

        try:
            logging.info(f"çº¿ç¨‹ {self.thread_id} å¼€å§‹çˆ¬å– {school_name}")

            if major_link:
                self.driver.get(major_link)
                time.sleep(3)
            else:
                self.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
                time.sleep(3)

                school_search_input = self.wait_for_element(
                    By.CSS_SELECTOR, "input[placeholder='è¯·è¾“å…¥æ‹›ç”Ÿå•ä½åç§°']"
                )
                if not school_search_input:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°å­¦æ ¡æœç´¢æ¡†")
                    return []

                school_search_input.clear()
                school_search_input.send_keys(school_name)
                time.sleep(3)

                search_button = self.wait_for_element_clickable(
                    By.CSS_SELECTOR, "button.ivu-btn-primary"
                )
                if search_button:
                    search_button.click()
                    time.sleep(3)
                else:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®")
                    return []

                if self.check_no_results():
                    logging.warning(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°å­¦æ ¡: {school_name}")
                    return []

                # æå–åœ°åŒºä¿¡æ¯å’Œé™¢æ ¡ç‰¹æ€§
                if search_type == 'school':
                    region = self.extract_region_from_school_page()
                    if not school_features:
                        school_features = self.extract_school_features_from_page()

                major_button = self.find_major_button()
                if major_button:
                    try:
                        button_href = major_button.get_attribute("href")
                        if button_href and "http" in button_href:
                            self.driver.get(button_href)
                            time.sleep(3)
                    except Exception as e:
                        logging.error(f"çº¿ç¨‹ {self.thread_id} è¿›å…¥ä¸“ä¸šé¡µé¢å¤±è´¥: {e}")
                        return []
                else:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœªæ‰¾åˆ°å¼€è®¾ä¸“ä¸šæŒ‰é’®")
                    return []

            current_url = self.driver.current_url
            if "/zsml/dwzy.do" not in current_url:
                logging.error(f"çº¿ç¨‹ {self.thread_id} ä¸åœ¨ä¸“ä¸šé¡µé¢")
                return []

            original_url = self.driver.current_url

            for keyword in search_keywords:
                try:
                    keyword_data = self.search_and_parse_majors(keyword, school_name, original_url, region,
                                                                school_features, search_type)
                    if keyword_data:
                        all_majors_data.extend(keyword_data)
                    time.sleep(2)
                except Exception as e:
                    logging.error(f"çº¿ç¨‹ {self.thread_id} æœç´¢å…³é”®è¯ {keyword} æ—¶å‡ºé”™: {e}")
                    continue

            # å»é‡å¤„ç†
            unique_majors = {}
            for data in all_majors_data:
                key = f"{data['school_name']}_{data['major_name']}_{data.get('major_code', '')}_{data.get('department', '')}"
                if key not in unique_majors:
                    unique_majors[key] = data

            all_majors_data = list(unique_majors.values())
            logging.info(f"çº¿ç¨‹ {self.thread_id} å»é‡åå…±è·å– {len(all_majors_data)} ä¸ªå”¯ä¸€ä¸“ä¸š")

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} çˆ¬å–å­¦æ ¡ {school_name} å¤±è´¥: {e}")

        return all_majors_data

    def search_and_parse_majors(self, keyword, school_name, original_url, region, school_features, search_type):
        """æœç´¢å¹¶è§£æä¸“ä¸šä¿¡æ¯"""
        return self.safe_execute(self._search_and_parse_majors_impl, keyword, school_name, original_url, region,
                                 school_features, search_type)

    def _search_and_parse_majors_impl(self, keyword, school_name, original_url, region, school_features, search_type):
        """æœç´¢å¹¶è§£æä¸“ä¸šä¿¡æ¯çš„å®ç°"""
        majors_data = []

        try:
            search_input = self.wait_for_element(
                By.CSS_SELECTOR, "input.ivu-input.ivu-input-default[placeholder='è¯·è¾“å…¥ä¸“ä¸šåç§°']"
            )
            if not search_input:
                return []

            search_input.clear()
            search_input.send_keys(keyword)
            time.sleep(3)

            try:
                dropdown = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".ivu-select-dropdown"))
                )
                options = dropdown.find_elements(By.CSS_SELECTOR, ".ivu-select-item")

                for i in range(len(options)):
                    try:
                        search_input = self.wait_for_element(
                            By.CSS_SELECTOR, "input.ivu-input.ivu-input-default[placeholder='è¯·è¾“å…¥ä¸“ä¸šåç§°']"
                        )
                        if not search_input:
                            continue

                        search_input.clear()
                        search_input.send_keys(keyword)
                        time.sleep(3)

                        dropdown = WebDriverWait(self.driver, 10).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, ".ivu-select-dropdown"))
                        )
                        current_options = dropdown.find_elements(By.CSS_SELECTOR, ".ivu-select-item")
                        if i < len(current_options):
                            current_option = current_options[i]
                            option_text = current_option.text.strip()

                            self.driver.execute_script("arguments[0].click();", current_option)
                            time.sleep(3)

                            page_data = self.parse_current_page_majors(school_name, keyword, option_text, region,
                                                                       school_features, search_type)
                            if page_data:
                                majors_data.extend(page_data)

                            self.driver.get(original_url)
                            time.sleep(3)

                    except StaleElementReferenceException:
                        continue
                    except Exception as e:
                        try:
                            self.driver.get(original_url)
                            time.sleep(3)
                        except:
                            pass
                        continue

            except TimeoutException:
                # å¦‚æœæ²¡æœ‰ä¸‹æ‹‰é€‰é¡¹ï¼Œç›´æ¥æœç´¢
                search_button = self.wait_for_element_clickable(
                    By.CSS_SELECTOR, "button.ivu-btn-primary"
                )
                if search_button:
                    search_button.click()
                    time.sleep(3)

                    page_data = self.parse_current_page_majors(school_name, keyword, keyword, region, school_features,
                                                               search_type)
                    if page_data:
                        majors_data.extend(page_data)

                    self.driver.get(original_url)
                    time.sleep(3)

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} æœç´¢ä¸“ä¸š {keyword} å¤±è´¥: {e}")

        return majors_data

    def parse_current_page_majors(self, school_name, keyword, option_text, region, school_features, search_type):
        """è§£æå½“å‰é¡µé¢çš„ä¸“ä¸šä¿¡æ¯"""
        return self.safe_execute(self._parse_current_page_majors_impl, school_name, keyword, option_text, region,
                                 school_features, search_type)

    def _parse_current_page_majors_impl(self, school_name, keyword, option_text, region, school_features, search_type):
        """è§£æå½“å‰é¡µé¢ä¸“ä¸šä¿¡æ¯çš„å®ç°"""
        majors_data = []

        try:
            self.expand_all_major_details()
            time.sleep(2)

            major_items = self.driver.find_elements(By.CSS_SELECTOR, ".zy-item")

            for item in major_items:
                try:
                    major_data = self.extract_major_basic_info(item)
                    if major_data and self.is_target_major(major_data['major_name']):
                        detailed_data_list = self.get_all_research_directions(item, school_name)

                        if detailed_data_list:
                            for detailed_data in detailed_data_list:
                                combined_data = major_data.copy()
                                combined_data.update(detailed_data)
                                combined_data.update({
                                    'school_name': school_name,
                                    'search_keyword': keyword,
                                    'selected_option': option_text,
                                    'region': region,
                                    'school_features': ', '.join(school_features) if school_features else '',
                                    'search_type': search_type,
                                    'data_source': f"ç ”æ‹›ç½‘æœç´¢ - {school_name} - {keyword}"
                                })
                                majors_data.append(combined_data)
                        else:
                            detailed_data = self.get_major_details_from_detail_page(item, school_name)
                            major_data.update(detailed_data)
                            major_data.update({
                                'school_name': school_name,
                                'search_keyword': keyword,
                                'selected_option': option_text,
                                'region': region,
                                'school_features': ', '.join(school_features) if school_features else '',
                                'search_type': search_type,
                                'data_source': f"ç ”æ‹›ç½‘æœç´¢ - {school_name} - {keyword}"
                            })
                            majors_data.append(major_data)

                except Exception:
                    continue

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {self.thread_id} è§£æé¡µé¢ä¸“ä¸šå¤±è´¥: {e}")

        return majors_data

    def is_target_major(self, text):
        """æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡ä¸“ä¸š"""
        if not text:
            return False

        target_keywords = [
            "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯", "è½¯ä»¶å·¥ç¨‹", "äººå·¥æ™ºèƒ½", "ç½‘ç»œç©ºé—´å®‰å…¨", "æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯",
            "è®¡ç®—æœºåº”ç”¨æŠ€æœ¯", "ä¿¡æ¯å®‰å…¨", "æ•°å­¦ä¸åº”ç”¨æ•°å­¦", "ä¿¡æ¯ä¸è®¡ç®—ç§‘å­¦", "åº”ç”¨æ•°å­¦",
            "ç»Ÿè®¡å­¦", "ä¸´åºŠåŒ»å­¦", "åŸºç¡€åŒ»å­¦", "è¯å­¦", "æŠ¤ç†å­¦"
        ]

        text_lower = text.lower()
        return any(keyword in text_lower for keyword in target_keywords)

    def get_all_research_directions(self, item, school_name):
        """è·å–ä¸“ä¸šçš„æ‰€æœ‰ç ”ç©¶æ–¹å‘"""
        detailed_data_list = []

        try:
            table_rows = item.find_elements(By.CSS_SELECTOR, ".ivu-table-row")
            for row in table_rows:
                try:
                    department = self.extract_text_from_row(row, ["td:nth-child(1)"])
                    research_direction = self.extract_text_from_row(row, ["td:nth-child(4)"])
                    exam_data = self.extract_exam_subjects_from_row(row)
                    enrollment_plan = self.extract_enrollment_plan_from_row(row)

                    detailed_data = {
                        'department': department,
                        'research_direction': research_direction,
                        'enrollment_plan': enrollment_plan,
                        **exam_data
                    }
                    detailed_data_list.append(detailed_data)
                except Exception:
                    continue

        except Exception:
            pass

        return detailed_data_list

    def extract_text_from_row(self, row, selectors):
        """ä»è¡¨æ ¼è¡Œä¸­æå–æ–‡æœ¬"""
        for selector in selectors:
            try:
                element = row.find_element(By.CSS_SELECTOR, selector)
                text = element.text.strip()
                if text:
                    return text
            except:
                continue
        return ""

    def extract_exam_subjects_from_row(self, row):
        """ä»è¡¨æ ¼è¡Œä¸­æå–è€ƒè¯•ç§‘ç›®ä¿¡æ¯"""
        exam_data = {
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            exam_buttons = row.find_elements(By.CSS_SELECTOR, "a[href*='javascript:;']")
            for button in exam_buttons:
                if "æŸ¥çœ‹" in button.text:
                    try:
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(2)

                        popup = self.wait_for_element(By.CSS_SELECTOR, ".ivu-poptip-popper")
                        if popup:
                            self.parse_exam_popup_content(popup, exam_data)
                            self.close_popup()
                            break
                    except Exception:
                        continue

        except Exception:
            pass

        return exam_data

    def parse_exam_popup_content(self, popup, exam_data):
        """è§£æè€ƒè¯•ç§‘ç›®å¼¹å‡ºçª—å£å†…å®¹"""
        try:
            popup_text = popup.text
            lines = [line.strip() for line in popup_text.split('\n') if line.strip()]

            for i, line in enumerate(lines):
                if i == 0 or 'æ€æƒ³æ”¿æ²»' in line or '(101)' in line:
                    exam_data['politics_subject'] = line
                elif i == 1 or any(keyword in line for keyword in ['è‹±è¯­', 'æ—¥è¯­', 'ä¿„è¯­', '(201)', '(202)', '(203)']):
                    exam_data['foreign_language_subject'] = line
                elif i == 2 or 'ä¸šåŠ¡è¯¾ä¸€' in line:
                    exam_data['business_subject1'] = line
                elif i == 3 or 'ä¸šåŠ¡è¯¾äºŒ' in line:
                    exam_data['business_subject2'] = line

        except Exception:
            pass

    def extract_enrollment_plan_from_row(self, row):
        """ä»è¡¨æ ¼è¡Œä¸­æå–æ‹Ÿæ‹›ç”Ÿäººæ•°"""
        enrollment_plan = ""

        try:
            plan_buttons = row.find_elements(By.CSS_SELECTOR, "a[href*='javascript:;']")
            for button in plan_buttons:
                if "æŸ¥çœ‹" in button.text:
                    try:
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(4)

                        popup = self.wait_for_element(By.CSS_SELECTOR, ".ivu-tooltip-popper")
                        if popup:
                            plan_text = popup.text.strip()
                            match = re.search(r'ä¸“ä¸šï¼š\s*(\d+)', plan_text)
                            if match:
                                enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"
                            else:
                                match = re.search(r'(\d+)', plan_text)
                                if match:
                                    enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"
                            self.close_popup()
                            break
                    except Exception:
                        continue

        except Exception:
            pass

        return enrollment_plan

    def close_popup(self):
        """å…³é—­å¼¹å‡ºçª—å£"""
        try:
            body = self.driver.find_element(By.TAG_NAME, "body")
            body.click()
            time.sleep(2)
        except:
            pass

    def extract_major_basic_info(self, item):
        """æå–ä¸“ä¸šåŸºæœ¬ä¿¡æ¯"""
        try:
            name_elem = item.find_element(By.CSS_SELECTOR, ".zy-name")
            name_text = name_elem.text.strip()

            if not name_text:
                return None

            code_match = re.search(r'\((\d+)\)', name_text)
            major_code = code_match.group(1) if code_match else ""
            major_name = re.sub(r'\(\d+\)', '', name_text).strip()

            if not major_name:
                return None

            degree_type = ""
            try:
                degree_elem = item.find_element(By.CSS_SELECTOR, ".zy-tag.xs, .zy-tag.zs")
                degree_type = degree_elem.text.strip()
            except:
                if "ä¸“ä¸šå­¦ä½" in name_text:
                    degree_type = "ä¸“ä¸šå­¦ä½"
                elif "å­¦æœ¯å­¦ä½" in name_text:
                    degree_type = "å­¦æœ¯å­¦ä½"
                elif major_code and major_code.startswith('085'):
                    degree_type = "ä¸“ä¸šå­¦ä½"
                else:
                    degree_type = "å­¦æœ¯å­¦ä½"

            return {
                'major_name': major_name,
                'major_code': major_code,
                'degree_type': degree_type
            }
        except Exception:
            return None

    def get_major_details_from_detail_page(self, item, school_name):
        """ä»è¯¦æƒ…é¡µé¢è·å–ä¸“ä¸šè¯¦ç»†ä¿¡æ¯"""
        details = {
            'enrollment_plan': '',
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            detail_links = item.find_elements(By.CSS_SELECTOR, "a[href*='/zsml/queryYjfx']")
            if detail_links:
                for detail_link in detail_links:
                    try:
                        detail_url = detail_link.get_attribute("href")
                        if detail_url:
                            if not detail_url.startswith('http'):
                                detail_url = 'https://yz.chsi.com.cn' + detail_url

                            original_window = self.driver.current_window_handle
                            self.driver.execute_script("window.open(arguments[0]);", detail_url)
                            time.sleep(4)

                            new_window = [w for w in self.driver.window_handles if w != original_window][0]
                            self.driver.switch_to.window(new_window)
                            time.sleep(4)

                            if "ç™»å½•" not in self.driver.title and "é”™è¯¯" not in self.driver.title:
                                page_details = self.parse_detail_page()
                                details.update(page_details)

                            self.driver.close()
                            self.driver.switch_to.window(original_window)
                            time.sleep(3)
                            break
                    except Exception:
                        try:
                            self.driver.switch_to.window(original_window)
                        except:
                            pass
                        continue

        except Exception:
            pass

        return details

    def parse_detail_page(self):
        """è§£æè¯¦æƒ…é¡µé¢"""
        details = {
            'enrollment_plan': '',
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            enrollment_plan = self.extract_enrollment_plan_from_detail_page()
            if enrollment_plan:
                details['enrollment_plan'] = enrollment_plan

            exam_data = self.extract_exam_subjects_from_detail_page()
            details.update(exam_data)

        except Exception:
            pass

        return details

    def extract_enrollment_plan_from_detail_page(self):
        """ä»è¯¦æƒ…é¡µé¢æå–æ‹Ÿæ‹›ç”Ÿäººæ•°"""
        enrollment_plan = ""

        try:
            page_text = self.driver.page_source
            match = re.search(r'ä¸“ä¸šï¼š\s*(\d+)', page_text)
            if match:
                enrollment_plan = f"{match.group(1)}(ä¸å«æ¨å…)"

        except Exception:
            pass

        return enrollment_plan

    def extract_exam_subjects_from_detail_page(self):
        """ä»è¯¦æƒ…é¡µé¢æå–è€ƒè¯•ç§‘ç›®ä¿¡æ¯"""
        exam_data = {
            'politics_subject': '',
            'foreign_language_subject': '',
            'business_subject1': '',
            'business_subject2': ''
        }

        try:
            kskm_items = self.driver.find_elements(By.CSS_SELECTOR, ".kskm-item")
            if kskm_items:
                first_kskm = kskm_items[0]
                kskm_details = first_kskm.find_elements(By.CSS_SELECTOR, ".kskm-detail .item")

                for i, item in enumerate(kskm_details):
                    text = item.text.strip()
                    if not text:
                        continue

                    clean_text = re.sub(r'è§æ‹›ç”Ÿç®€ç« |æŸ¥çœ‹è¯¦æƒ…', '', text).strip()

                    if i == 0:
                        exam_data['politics_subject'] = clean_text
                    elif i == 1:
                        exam_data['foreign_language_subject'] = clean_text
                    elif i == 2:
                        exam_data['business_subject1'] = clean_text
                    elif i == 3:
                        exam_data['business_subject2'] = clean_text

        except Exception:
            pass

        return exam_data

    def extract_region_from_school_page(self):
        """ä»å­¦æ ¡é¡µé¢æå–åœ°åŒºä¿¡æ¯"""
        try:
            page_text = self.driver.page_source
            region_patterns = [
                r'<div class="yx-area"[^>]*>.*?([\u4e00-\u9fa5]{2,10})</div>',
                r'æ‰€åœ¨åœ°.*?([\u4e00-\u9fa5]{2,10})',
            ]

            for pattern in region_patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    region = match.group(1)
                    return region

            return "æœªçŸ¥"
        except Exception:
            return "æœªçŸ¥"

    def extract_school_features_from_page(self):
        """ä»å­¦æ ¡é¡µé¢æå–é™¢æ ¡ç‰¹æ€§"""
        try:
            features = []
            feature_selectors = [".yx-tag", ".yx-tags .yx-tag"]

            for selector in feature_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        if text and text not in features:
                            features.append(text)
                except:
                    continue

            return list(set(features))
        except Exception:
            return []

    def expand_all_major_details(self):
        """å±•å¼€æ‰€æœ‰ä¸“ä¸šè¯¦ç»†ä¿¡æ¯"""
        try:
            expand_buttons = self.driver.find_elements(By.CSS_SELECTOR, ".show-more, [class*='expand']")
            for button in expand_buttons:
                try:
                    if button.is_displayed() and ("å±•å¼€" in button.text or "è¯¦æƒ…" in button.text):
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(1)
                except:
                    continue

            return True
        except Exception:
            return False

    def find_major_button(self):
        """æŸ¥æ‰¾å¼€è®¾ä¸“ä¸šæŒ‰é’®"""
        button_selectors = [
            "a.zy-btn.ivu-btn.ivu-btn-primary",
            "a[href*='/zsml/dwzy.do']",
            "//a[contains(text(), 'å¼€è®¾ä¸“ä¸š')]"
        ]

        for selector in button_selectors:
            try:
                if selector.startswith("//"):
                    button = self.driver.find_element(By.XPATH, selector)
                else:
                    button = self.driver.find_element(By.CSS_SELECTOR, selector)

                if button.is_displayed():
                    return button
            except:
                continue

        return None

    def check_no_results(self):
        """æ£€æŸ¥æ˜¯å¦æ²¡æœ‰ç»“æœ"""
        try:
            no_data_indicators = ["//*[contains(text(), 'æš‚æ— æ•°æ®')]", "//*[contains(text(), 'æ²¡æœ‰æ‰¾åˆ°')]"]
            for indicator in no_data_indicators:
                try:
                    no_data = self.driver.find_element(By.XPATH, indicator)
                    if no_data and no_data.is_displayed():
                        return True
                except:
                    continue
            return False
        except:
            return False

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if hasattr(self, 'driver'):
            try:
                self.driver.quit()
                logging.info(f"çº¿ç¨‹ {self.thread_id} æµè§ˆå™¨å·²å…³é—­")
            except:
                pass


class CompleteInfoSpider:
    def __init__(self, max_workers=2):
        self.max_workers = max_workers
        self.lock = threading.Lock()
        self.excel_filename = f'å®Œæ•´ä¿¡æ¯_è€ƒç ”ä¸“ä¸šä¿¡æ¯-{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'

        self.check_and_create_tables()
        self.init_excel_file()

    def init_excel_file(self):
        """åˆå§‹åŒ–Excelæ–‡ä»¶"""
        try:
            df = pd.DataFrame(columns=[
                'å­¦æ ¡', 'ä¸“ä¸šåç§°', 'ä¸“ä¸šä»£ç ', 'é™¢ç³»', 'ç ”ç©¶æ–¹å‘',
                'æ”¿æ²»ç§‘ç›®', 'å¤–è¯­ç§‘ç›®', 'ä¸šåŠ¡è¯¾ä¸€', 'ä¸šåŠ¡è¯¾äºŒ',
                'æ‹Ÿæ‹›ç”Ÿäººæ•°', 'åœ°åŒº', 'é™¢æ ¡ç‰¹æ€§', 'å­¦ä½ç±»å‹',
                'æœç´¢å…³é”®è¯', 'æ•°æ®æ¥æº'
            ])
            df.to_excel(self.excel_filename, index=False, engine='openpyxl')
            logging.info(f"Excelæ–‡ä»¶å·²åˆå§‹åŒ–: {self.excel_filename}")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–Excelæ–‡ä»¶å¤±è´¥: {e}")

    def append_to_excel(self, data_list):
        """è¿½åŠ æ•°æ®åˆ°Excelæ–‡ä»¶"""
        if not data_list:
            return

        with self.lock:
            try:
                try:
                    existing_df = pd.read_excel(self.excel_filename, engine='openpyxl')
                except:
                    existing_df = pd.DataFrame()

                new_data = []
                for data in data_list:
                    new_data.append({
                        'å­¦æ ¡': data['school_name'],
                        'ä¸“ä¸šåç§°': data['major_name'],
                        'ä¸“ä¸šä»£ç ': data.get('major_code', ''),
                        'é™¢ç³»': data.get('department', ''),
                        'ç ”ç©¶æ–¹å‘': data.get('research_direction', ''),
                        'æ”¿æ²»ç§‘ç›®': data.get('politics_subject', ''),
                        'å¤–è¯­ç§‘ç›®': data.get('foreign_language_subject', ''),
                        'ä¸šåŠ¡è¯¾ä¸€': data.get('business_subject1', ''),
                        'ä¸šåŠ¡è¯¾äºŒ': data.get('business_subject2', ''),
                        'æ‹Ÿæ‹›ç”Ÿäººæ•°': data.get('enrollment_plan', ''),
                        'åœ°åŒº': data.get('region', ''),
                        'é™¢æ ¡ç‰¹æ€§': data.get('school_features', ''),
                        'å­¦ä½ç±»å‹': data.get('degree_type', ''),
                        'æœç´¢å…³é”®è¯': data.get('search_keyword', ''),
                        'æ•°æ®æ¥æº': data['data_source']
                    })

                new_df = pd.DataFrame(new_data)

                if not existing_df.empty:
                    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                else:
                    combined_df = new_df

                combined_df.to_excel(self.excel_filename, index=False, engine='openpyxl')
                logging.info(f"å·²è¿½åŠ  {len(data_list)} æ¡æ•°æ®åˆ°Excelæ–‡ä»¶")

            except Exception as e:
                logging.error(f"è¿½åŠ æ•°æ®åˆ°Excelå¤±è´¥: {e}")

    def check_and_create_tables(self):
        """æ£€æŸ¥å¹¶åˆ›å»ºè¡¨"""
        connection = self.get_db_connection()
        if not connection:
            return

        try:
            cursor = connection.cursor()

            cursor.execute("SHOW TABLES LIKE 'exam_subjects'")
            if not cursor.fetchone():
                cursor.execute("""
                    CREATE TABLE exam_subjects (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        school_name VARCHAR(255) NOT NULL,
                        major_name VARCHAR(255) NOT NULL,
                        major_code VARCHAR(100),
                        department VARCHAR(255),
                        research_direction VARCHAR(255),
                        politics_subject VARCHAR(100),
                        foreign_language_subject VARCHAR(100),
                        business_subject1 VARCHAR(255),
                        business_subject2 VARCHAR(255),
                        enrollment_plan VARCHAR(100),
                        region VARCHAR(100),
                        data_source VARCHAR(500) NOT NULL,
                        school_features TEXT,
                        degree_type VARCHAR(50),
                        search_type ENUM('region', 'school') DEFAULT 'region',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                logging.info("åˆ›å»ºè¡¨ exam_subjects")

            connection.commit()
            logging.info("æ•°æ®è¡¨æ£€æŸ¥å®Œæˆ")

        except MySQLError as e:
            logging.error(f"æ£€æŸ¥è¡¨å¤±è´¥: {e}")
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            connection = mysql.connector.connect(**DB_CONFIG)
            return connection
        except MySQLError as e:
            logging.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return None

    def check_school_exists_in_database(self, school_name, search_type='region'):
        """æ£€æŸ¥å­¦æ ¡æ˜¯å¦å·²åœ¨æ•°æ®åº“ä¸­å­˜åœ¨"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            query = "SELECT COUNT(*) FROM exam_subjects WHERE school_name = %s AND search_type = %s"
            cursor.execute(query, (school_name, search_type))
            count = cursor.fetchone()[0]
            return count > 0
        except MySQLError:
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def delete_school_data(self, school_name, search_type='region'):
        """åˆ é™¤æŒ‡å®šå­¦æ ¡çš„æ•°æ®"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            query = "DELETE FROM exam_subjects WHERE school_name = %s AND search_type = %s"
            cursor.execute(query, (school_name, search_type))
            connection.commit()
            logging.info(f"å·²åˆ é™¤å­¦æ ¡ {school_name} çš„ç°æœ‰æ•°æ®")
            return True
        except MySQLError:
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def ask_user_for_existing_schools(self, school_list, search_type='region'):
        """è¯¢é—®ç”¨æˆ·å¯¹å·²å­˜åœ¨å­¦æ ¡çš„å¤„ç†æ–¹å¼"""
        schools_to_crawl = []

        for school_info in school_list:
            school_name = school_info['name']
            exists = self.check_school_exists_in_database(school_name, search_type)

            if exists:
                while True:
                    choice = input(f"å­¦æ ¡ '{school_name}' å·²å­˜åœ¨ï¼Œæ˜¯å¦é‡æ–°çˆ¬å–ï¼Ÿ(y/n): ").strip().lower()
                    if choice in ['y', 'yes', 'æ˜¯']:
                        if self.delete_school_data(school_name, search_type):
                            schools_to_crawl.append(school_info)
                        break
                    elif choice in ['n', 'no', 'å¦']:
                        break
            else:
                schools_to_crawl.append(school_info)

        return schools_to_crawl

    def save_to_database(self, data):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        if not data:
            return False

        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            saved_count = 0

            for item in data:
                try:
                    query = """
                    INSERT INTO exam_subjects 
                    (school_name, major_name, major_code, department, research_direction,
                     politics_subject, foreign_language_subject, business_subject1, business_subject2,
                     enrollment_plan, region, data_source, school_features, degree_type, search_type)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """
                    cursor.execute(query, (
                        item.get('school_name', ''),
                        item.get('major_name', ''),
                        item.get('major_code', ''),
                        item.get('department', ''),
                        item.get('research_direction', ''),
                        item.get('politics_subject', ''),
                        item.get('foreign_language_subject', ''),
                        item.get('business_subject1', ''),
                        item.get('business_subject2', ''),
                        item.get('enrollment_plan', ''),
                        item.get('region', ''),
                        item.get('data_source', ''),
                        item.get('school_features', ''),
                        item.get('degree_type', ''),
                        item.get('search_type', 'region')
                    ))
                    saved_count += 1
                except MySQLError:
                    continue

            connection.commit()
            logging.info(f"æˆåŠŸä¿å­˜ {saved_count} æ¡æ•°æ®åˆ°æ•°æ®åº“")
            return True

        except MySQLError:
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def crawl_school_task(self, school_info, region=None, search_type='region', thread_id=0):
        """å•ä¸ªå­¦æ ¡çš„çˆ¬å–ä»»åŠ¡"""
        thread_spider = ThreadSafeSpider(thread_id)
        try:
            school_name = school_info['name']
            school_data = thread_spider.crawl_school_majors(
                school_info['name'],
                school_info.get('major_link'),
                region,
                school_info.get('features', []),
                search_type
            )

            if school_data:
                self.save_to_database(school_data)
                self.append_to_excel(school_data)
                logging.info(f"çº¿ç¨‹ {thread_id} å®Œæˆå­¦æ ¡ {school_name}ï¼Œè·å– {len(school_data)} æ¡æ•°æ®")
                return school_data
            else:
                logging.info(f"çº¿ç¨‹ {thread_id} å­¦æ ¡ {school_name} æ²¡æœ‰æ‰¾åˆ°ç›®æ ‡ä¸“ä¸š")
                return []

        except Exception as e:
            logging.error(f"çº¿ç¨‹ {thread_id} å¤„ç†å­¦æ ¡ {school_info['name']} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []
        finally:
            thread_spider.close()

    def crawl_all_schools_multithread(self, school_list, region=None, search_type='region'):
        """å¤šçº¿ç¨‹æ‰¹é‡çˆ¬å–æ‰€æœ‰å­¦æ ¡"""
        all_data = []

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_school = {
                executor.submit(self.crawl_school_task, school, region, search_type, i): (school, i)
                for i, school in enumerate(school_list)
            }

            for future in as_completed(future_to_school):
                school, thread_id = future_to_school[future]
                try:
                    school_data = future.result()
                    if school_data:
                        all_data.extend(school_data)
                except Exception as e:
                    logging.error(f"å­¦æ ¡ {school['name']} çˆ¬å–å¤±è´¥: {e}")

        return all_data

    def get_available_regions(self):
        """è·å–æ‰€æœ‰å¯ç”¨åœ°åŒº"""
        temp_spider = ThreadSafeSpider(0)
        try:
            temp_spider.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
            time.sleep(5)

            area_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".area-item")
            all_regions = []

            for area_item in area_items:
                regions = area_item.find_elements(By.CSS_SELECTOR, ".option-item")
                for region in regions:
                    region_name = region.text.strip()
                    all_regions.append(region_name)

            return all_regions

        except Exception as e:
            logging.error(f"è·å–å¯ç”¨åœ°åŒºå¤±è´¥: {e}")
            return []
        finally:
            temp_spider.close()

    def select_region_and_features(self):
        """äº¤äº’å¼é€‰æ‹©åœ°åŒºå’Œé™¢æ ¡ç‰¹æ€§"""
        try:
            all_regions = self.get_available_regions()
            if not all_regions:
                return [], []

            print("\nä¸€åŒº:", end=" ")
            for i, region in enumerate(all_regions[:21]):
                print(f"{i + 1}.{region}", end=" ")

            print("\n\näºŒåŒº:", end=" ")
            for i, region in enumerate(all_regions[21:], 22):
                print(f"{i}.{region}", end=" ")
            print()

            region_input = input("è¯·è¾“å…¥ç¼–å·ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼Œ0é€‰æ‹©æ‰€æœ‰ï¼‰: ").strip()
            selected_regions = []

            if region_input == "0":
                selected_regions = all_regions
            else:
                input_nums = [num.strip() for num in region_input.split(',') if num.strip()]
                for num in input_nums:
                    if num.isdigit() and 1 <= int(num) <= len(all_regions):
                        selected_regions.append(all_regions[int(num) - 1])

            if not selected_regions:
                print("æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆåœ°åŒº")
                return [], []

            feature_input = input("è¾“å…¥é™¢æ ¡ç‰¹æ€§ç¼–å·ï¼ˆ1.åšå£«ç‚¹ 2.åŒä¸€æµ 3.è‡ªåˆ’çº¿ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå›è½¦è·³è¿‡ï¼‰: ").strip()
            selected_features = []

            if feature_input:
                input_nums = [num.strip() for num in feature_input.split(',') if num.strip()]
                for num in input_nums:
                    if num == "1":
                        selected_features.append("bs")
                    elif num == "2":
                        selected_features.append("syl")
                    elif num == "3":
                        selected_features.append("zhx")

            return selected_regions, selected_features

        except Exception as e:
            logging.error(f"é€‰æ‹©åœ°åŒºå’Œç‰¹æ€§å¤±è´¥: {e}")
            return [], []

    def select_schools_by_name(self):
        """æŒ‰å­¦æ ¡åç§°é€‰æ‹©å­¦æ ¡"""
        school_input = input("è¯·è¾“å…¥å­¦æ ¡åç§°ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰: ").strip()
        if not school_input:
            return []

        return [name.strip() for name in school_input.split(',') if name.strip()]

    def search_schools_by_region_and_features(self, region, features):
        """æ ¹æ®åœ°åŒºå’Œç‰¹æ€§æœç´¢å­¦æ ¡"""
        temp_spider = ThreadSafeSpider(0)
        try:
            temp_spider.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
            time.sleep(3)

            area_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".area-item")
            region_found = False
            for area_item in area_items:
                regions = area_item.find_elements(By.CSS_SELECTOR, ".option-item")
                for region_elem in regions:
                    if region_elem.text.strip() == region:
                        region_elem.click()
                        region_found = True
                        break
                if region_found:
                    break

            if not region_found:
                return []

            if features:
                for feature in features:
                    try:
                        checkbox = temp_spider.driver.find_element(By.CSS_SELECTOR,
                                                                   f"input[type='checkbox'][value='{feature}']")
                        if not checkbox.is_selected():
                            checkbox.click()
                    except:
                        pass

            search_button = temp_spider.wait_for_element_clickable(By.CSS_SELECTOR, "button.ivu-btn-primary")
            if search_button:
                search_button.click()
                time.sleep(3)

            schools = []
            school_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".zy-item")
            for item in school_items:
                try:
                    name_elem = item.find_element(By.CSS_SELECTOR, ".yx-name")
                    school_name = name_elem.text.strip()
                    clean_name = re.sub(r'\(\d+\)', '', school_name).strip()

                    school_features = []
                    try:
                        feature_tags = item.find_elements(By.CSS_SELECTOR, ".yx-tag")
                        for tag in feature_tags:
                            feature_text = tag.text.strip()
                            if feature_text:
                                school_features.append(feature_text)
                    except:
                        pass

                    major_link_elem = item.find_element(By.CSS_SELECTOR, ".zy-btn")
                    major_link = major_link_elem.get_attribute("href")

                    schools.append({
                        'name': clean_name,
                        'major_link': major_link,
                        'features': school_features
                    })
                except:
                    continue

            logging.info(f"åœ°åŒº {region} æ‰¾åˆ° {len(schools)} æ‰€å­¦æ ¡")
            return schools

        except Exception as e:
            logging.error(f"æœç´¢å­¦æ ¡å¤±è´¥ - åœ°åŒº: {region}: {e}")
            return []
        finally:
            temp_spider.close()

    def search_school_by_name(self, school_name):
        """æ ¹æ®å­¦æ ¡åç§°æœç´¢å­¦æ ¡"""
        temp_spider = ThreadSafeSpider(0)
        try:
            temp_spider.driver.get("https://yz.chsi.com.cn/zsml/dw.do")
            time.sleep(3)

            school_search_input = temp_spider.wait_for_element(
                By.CSS_SELECTOR, "input[placeholder='è¯·è¾“å…¥æ‹›ç”Ÿå•ä½åç§°']"
            )
            if not school_search_input:
                return None

            school_search_input.clear()
            school_search_input.send_keys(school_name)
            time.sleep(3)

            search_button = temp_spider.wait_for_element_clickable(
                By.CSS_SELECTOR, "button.ivu-btn-primary"
            )
            if search_button:
                search_button.click()
                time.sleep(3)
            else:
                return None

            if temp_spider.check_no_results():
                return None

            school_items = temp_spider.driver.find_elements(By.CSS_SELECTOR, ".zy-item")
            if school_items:
                item = school_items[0]
                name_elem = item.find_element(By.CSS_SELECTOR, ".yx-name")
                school_name = name_elem.text.strip()
                clean_name = re.sub(r'\(\d+\)', '', school_name).strip()

                school_features = []
                try:
                    feature_tags = item.find_elements(By.CSS_SELECTOR, ".yx-tag")
                    for tag in feature_tags:
                        feature_text = tag.text.strip()
                        if feature_text:
                            school_features.append(feature_text)
                except:
                    pass

                major_link_elem = item.find_element(By.CSS_SELECTOR, ".zy-btn")
                major_link = major_link_elem.get_attribute("href")

                return {
                    'name': clean_name,
                    'major_link': major_link,
                    'features': school_features
                }
            else:
                return None

        except Exception as e:
            logging.error(f"æœç´¢å­¦æ ¡ {school_name} å¤±è´¥: {e}")
            return None
        finally:
            temp_spider.close()

    def crawl_by_regions_and_features(self, regions, features):
        """æŒ‰åœ°åŒºå’Œç‰¹æ€§çˆ¬å–æ‰€æœ‰å­¦æ ¡"""
        all_data = []

        for region in regions:
            schools = self.search_schools_by_region_and_features(region, features)
            if not schools:
                continue

            filtered_schools = self.ask_user_for_existing_schools(schools, 'region')
            if not filtered_schools:
                continue

            region_data = self.crawl_all_schools_multithread(filtered_schools, region, 'region')
            all_data.extend(region_data)
            logging.info(f"åœ°åŒº {region} çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(region_data)} æ¡ä¸“ä¸šä¿¡æ¯")

        logging.info(f"æ‰€æœ‰åœ°åŒºçˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡ä¸“ä¸šä¿¡æ¯")
        return all_data

    def crawl_by_school_names(self, school_names):
        """æŒ‰å­¦æ ¡åç§°çˆ¬å–å­¦æ ¡ä¸“ä¸šä¿¡æ¯"""
        schools_to_crawl = []
        for school_name in school_names:
            school_info = self.search_school_by_name(school_name)
            if school_info:
                schools_to_crawl.append(school_info)

        if not schools_to_crawl:
            return []

        filtered_schools = self.ask_user_for_existing_schools(schools_to_crawl, 'school')
        if not filtered_schools:
            return []

        all_data = self.crawl_all_schools_multithread(filtered_schools, None, 'school')
        logging.info(f"æ‰€æœ‰å­¦æ ¡çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡ä¸“ä¸šä¿¡æ¯")
        return all_data

    def delete_region_data(self, region):
        """åˆ é™¤æŒ‡å®šåœ°åŒºçš„æ•°æ®"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            query = "DELETE FROM exam_subjects WHERE region = %s AND search_type = 'region'"
            cursor.execute(query, (region,))
            connection.commit()
            logging.info(f"å·²åˆ é™¤åœ°åŒº {region} çš„æ‰€æœ‰æ•°æ®")
            return True
        except MySQLError:
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()


class ShanghaiRankingSpider:
    """è½¯ç§‘æ’åçˆ¬è™«ç±»"""

    def __init__(self, headless=False):
        self.headless = headless
        self.driver = None
        self.wait = None
        self.edge_driver_path = "msedgedriver.exe"
        self.all_subjects = {}

        self.setup_driver()
        self.create_tables()

    def setup_driver(self):
        """é…ç½®Edgeæµè§ˆå™¨é©±åŠ¨"""
        try:
            edge_options = Options()

            if self.headless:
                edge_options.add_argument('--headless')
                edge_options.add_argument('--disable-gpu')

            edge_options.add_argument('--no-sandbox')
            edge_options.add_argument('--disable-dev-shm-usage')
            edge_options.add_argument('--window-size=1920,1080')
            edge_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            edge_options.add_experimental_option('useAutomationExtension', False)
            edge_options.add_argument('--disable-blink-features=AutomationControlled')

            edge_options.add_argument(
                'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
            )

            if not os.path.exists(self.edge_driver_path):
                raise FileNotFoundError(f"Edgeé©±åŠ¨æ–‡ä»¶ä¸å­˜åœ¨: {self.edge_driver_path}")

            service = Service(executable_path=self.edge_driver_path)
            self.driver = webdriver.Edge(service=service, options=edge_options)

            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.wait = WebDriverWait(self.driver, 10)
            self.driver.implicitly_wait(5)

            logging.info("æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logging.error(f"æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def wait_for_element(self, by, value, timeout=10):
        """ç­‰å¾…å…ƒç´ å‡ºç°"""
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.presence_of_element_located((by, value))
            )
            return element
        except TimeoutException:
            return None

    def get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            connection = mysql.connector.connect(**DB_CONFIG)
            return connection
        except MySQLError as e:
            logging.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return None

    def create_tables(self):
        """åˆ›å»ºè½¯ç§‘æ’åæ•°æ®è¡¨"""
        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            cursor.execute("SHOW TABLES LIKE 'shanghai_subject_rankings'")
            if not cursor.fetchone():
                cursor.execute("""
                    CREATE TABLE shanghai_subject_rankings (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        year INT NOT NULL,
                        subject_code VARCHAR(20) NOT NULL,
                        subject_name VARCHAR(100) NOT NULL,
                        ranking_position_2025 INT,
                        ranking_position_2024 INT,
                        school_name VARCHAR(255) NOT NULL,
                        score_2025 FLOAT,
                        score_2024 FLOAT,
                        subject_category VARCHAR(50),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                connection.commit()
                logging.info("è½¯ç§‘æ’åæ•°æ®è¡¨åˆ›å»ºæˆåŠŸ")
                return True
        except MySQLError as e:
            logging.error(f"åˆ›å»ºè½¯ç§‘æ’åè¡¨å¤±è´¥: {e}")
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def fetch_all_subjects_from_web(self):
        """ä»è½¯ç§‘æ’åé¡µé¢åŠ¨æ€çˆ¬å–æ‰€æœ‰å­¦ç§‘ä¿¡æ¯"""
        try:
            self.driver.get("https://www.shanghairanking.cn/rankings/bcsr/2025")
            time.sleep(5)

            # ç­‰å¾…é¡µé¢åŠ è½½
            self.wait_for_element(By.CLASS_NAME, "subject-item", timeout=15)

            subject_items = self.driver.find_elements(By.CLASS_NAME, "subject-item")
            all_subjects = {}

            for item in subject_items:
                try:
                    # è·å–ç±»åˆ«IDå’Œåç§°
                    category_code = item.get_attribute("id")
                    if not category_code:
                        continue

                    # è·å–ç±»åˆ«æ ‡é¢˜
                    category_title_elem = item.find_element(By.CSS_SELECTOR, ".subject-category .subject-title")
                    category_name = category_title_elem.text.strip() if category_title_elem else f"ç±»åˆ«{category_code}"

                    # è·å–å­¦ç§‘åˆ—è¡¨
                    subject_list = item.find_element(By.CLASS_NAME, "subject-list")
                    subject_links = subject_list.find_elements(By.CLASS_NAME, "subj-link")

                    subjects_in_category = []
                    for link in subject_links:
                        try:
                            spans = link.find_elements(By.TAG_NAME, "span")
                            if len(spans) >= 2:
                                subject_code = spans[0].text.strip()
                                subject_name = spans[1].text.strip()
                                if subject_code and subject_name:
                                    subjects_in_category.append((subject_code, subject_name))
                        except Exception:
                            continue

                    if subjects_in_category:
                        all_subjects[category_code] = {
                            'category_name': category_name,
                            'subjects': subjects_in_category
                        }

                except Exception as e:
                    logging.error(f"è§£æç±»åˆ«å¤±è´¥: {e}")
                    continue

            self.all_subjects = all_subjects
            return all_subjects

        except Exception as e:
            logging.error(f"çˆ¬å–å­¦ç§‘ä¿¡æ¯å¤±è´¥: {e}")
            return {}

    def display_all_subjects(self):
        """æ˜¾ç¤ºæ‰€æœ‰çˆ¬å–åˆ°çš„å­¦ç§‘ä¿¡æ¯"""
        if not self.all_subjects:
            self.fetch_all_subjects_from_web()

        if not self.all_subjects:
            print("æœªèƒ½è·å–åˆ°å­¦ç§‘ä¿¡æ¯")
            return {}

        subject_mapping = {}
        subject_index = 1

        # å…ˆæ‰“å°æ‰€æœ‰å­¦ç§‘
        print("\n=== å¯ç”¨å­¦ç§‘åˆ—è¡¨ ===")

        sorted_categories = sorted(self.all_subjects.items(), key=lambda x: x[0])
        for category_code, category_info in sorted_categories:
            print(f"\n{category_info['category_name']} ({category_code}):")

            for subject_code, subject_name in category_info['subjects']:
                print(f"  {subject_index:3d}. {subject_code} {subject_name}")
                subject_mapping[subject_index] = (
                    subject_code, subject_name, category_code, category_info['category_name']
                )
                subject_index += 1

        print(f"\nå…±è®¡ {subject_index - 1} ä¸ªå­¦ç§‘")
        return subject_mapping

    def clean_school_name(self, school_name):
        """æ¸…ç†å­¦æ ¡åç§°"""
        if not school_name:
            return ""

        school_name = school_name.strip()
        school_name = re.sub(r'\([^)]*\)', '', school_name)
        school_name = re.sub(r'ï¼ˆ[^ï¼‰]*ï¼‰', '', school_name)
        school_name = re.sub(r'\s+', ' ', school_name).strip()

        replacements = {
            'åŒ—äº¬åå’ŒåŒ»å­¦é™¢(æ¸…åå¤§å­¦åŒ»å­¦éƒ¨)': 'åŒ—äº¬åå’ŒåŒ»å­¦é™¢',
            'å›½é˜²ç§‘æŠ€å¤§å­¦ï¼ˆåŸå›½é˜²ç§‘å­¦æŠ€æœ¯å¤§å­¦ï¼‰': 'å›½é˜²ç§‘æŠ€å¤§å­¦',
            'åŒ—äº¬å¤§å­¦åŒ»å­¦éƒ¨': 'åŒ—äº¬å¤§å­¦',
            'å¤æ—¦å¤§å­¦ä¸Šæµ·åŒ»å­¦é™¢': 'å¤æ—¦å¤§å­¦',
            'ä¸Šæµ·äº¤é€šå¤§å­¦åŒ»å­¦é™¢': 'ä¸Šæµ·äº¤é€šå¤§å­¦',
        }

        for old, new in replacements.items():
            if old in school_name:
                school_name = school_name.replace(old, new)

        return school_name

    def extract_rank_number(self, rank_text):
        """ä»æ’åæ–‡æœ¬ä¸­æå–æ’åæ•°å­—"""
        if not rank_text:
            return 0

        rank_text = str(rank_text).strip()
        if rank_text.isdigit():
            return int(rank_text)
        elif '-' in rank_text:
            parts = rank_text.split('-')
            if parts[0].strip().isdigit():
                return int(parts[0].strip())
        else:
            match = re.search(r'(\d+)', rank_text)
            if match:
                return int(match.group(1))

        return 0

    def extract_score(self, score_text):
        """ä»åˆ†æ•°æ–‡æœ¬ä¸­æå–åˆ†æ•°"""
        if not score_text:
            return 0.0

        try:
            cleaned_text = re.sub(r'[^\d.]', '', str(score_text))
            if cleaned_text:
                return float(cleaned_text)
            return 0.0
        except:
            return 0.0

    def navigate_to_subject_page(self, subject_code):
        """å¯¼èˆªåˆ°å­¦ç§‘é¡µé¢"""
        url = f"https://www.shanghairanking.cn/rankings/bcsr/2025/{subject_code}"

        try:
            self.driver.get(url)
            time.sleep(3)
            table = self.wait_for_element(By.CLASS_NAME, "rk-table", timeout=20)
            return table is not None
        except Exception:
            return False

    def get_total_pages(self):
        """è·å–æ€»é¡µæ•°"""
        try:
            pagination = self.wait_for_element(By.CLASS_NAME, "ant-pagination", timeout=15)
            if not pagination:
                return 1

            try:
                total_text_element = pagination.find_element(By.CLASS_NAME, "ant-pagination-total-text")
                text = total_text_element.text
                match = re.search(r'å…±\s*(\d+)\s*æ¡', text)
                if match:
                    total_items = int(match.group(1))
                    total_pages = (total_items + 29) // 30
                    return total_pages
            except:
                pass

            return 1
        except Exception:
            return 1

    def parse_current_page(self, subject_code, subject_name, page_num=1):
        """è§£æå½“å‰é¡µé¢çš„æ•°æ®"""
        try:
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            table = soup.find('table', class_='rk-table')
            if not table:
                return []

            tbody = table.find('tbody')
            if not tbody:
                return []

            rows = tbody.find_all('tr')
            data_rows = []

            for row in rows:
                cells = row.find_all('td')
                if len(cells) < 5:
                    continue

                try:
                    rank_2025 = 0
                    if len(cells) > 0:
                        rank_cell = cells[0]
                        rank_div = rank_cell.find('div', class_='ranking')
                        if rank_div:
                            rank_text = rank_div.get_text(strip=True)
                        else:
                            rank_text = rank_cell.get_text(strip=True)
                        rank_2025 = self.extract_rank_number(rank_text)

                    rank_2024 = 0
                    if len(cells) > 1:
                        rank_cell = cells[1]
                        rank_span = rank_cell.find('span')
                        if rank_span:
                            rank_text = rank_span.get_text(strip=True)
                        else:
                            rank_text = rank_cell.get_text(strip=True)
                        rank_2024 = self.extract_rank_number(rank_text)

                    school_name = ""
                    if len(cells) > 3:
                        school_cell = cells[3]
                        name_span = school_cell.find('span', class_='name-cn')
                        if name_span:
                            school_name = self.clean_school_name(name_span.get_text(strip=True))
                        else:
                            school_name = self.clean_school_name(school_cell.get_text(strip=True))

                    if not school_name or len(school_name) < 2:
                        continue

                    score_2025 = 0.0
                    if len(cells) > 4:
                        score_text = cells[4].get_text(strip=True)
                        score_2025 = self.extract_score(score_text)

                    score_2024 = 0.0

                    subject_category = ""
                    if subject_code.startswith('01'):
                        subject_category = "å“²å­¦"
                    elif subject_code.startswith('02'):
                        subject_category = "ç»æµå­¦"
                    elif subject_code.startswith('03'):
                        subject_category = "æ³•å­¦"
                    elif subject_code.startswith('04'):
                        subject_category = "æ•™è‚²å­¦"
                    elif subject_code.startswith('05'):
                        subject_category = "æ–‡å­¦"
                    elif subject_code.startswith('06'):
                        subject_category = "å†å²å­¦"
                    elif subject_code.startswith('07'):
                        subject_category = "ç†å­¦"
                    elif subject_code.startswith('08'):
                        subject_category = "å·¥å­¦"
                    elif subject_code.startswith('09'):
                        subject_category = "å†œå­¦"
                    elif subject_code.startswith('10'):
                        subject_category = "åŒ»å­¦"
                    elif subject_code.startswith('12'):
                        subject_category = "ç®¡ç†å­¦"
                    elif subject_code.startswith('13'):
                        subject_category = "è‰ºæœ¯å­¦"
                    elif subject_code.startswith('14'):
                        subject_category = "äº¤å‰å­¦ç§‘"
                    else:
                        subject_category = "å…¶ä»–"

                    data_rows.append({
                        'year': 2025,
                        'subject_code': subject_code,
                        'subject_name': subject_name,
                        'ranking_position_2025': rank_2025,
                        'ranking_position_2024': rank_2024,
                        'school_name': school_name,
                        'score_2025': score_2025,
                        'score_2024': score_2024,
                        'subject_category': subject_category,
                        'page_number': page_num
                    })

                except Exception:
                    continue

            return data_rows

        except Exception:
            return []

    def fetch_subject_data(self, subject_code, subject_name, max_pages=None):
        """è·å–å­¦ç§‘æ‰€æœ‰é¡µé¢æ•°æ®"""
        all_data = []

        try:
            if not self.navigate_to_subject_page(subject_code):
                return []

            total_pages = self.get_total_pages()
            if max_pages and max_pages < total_pages:
                total_pages = max_pages

            for page_num in range(1, total_pages + 1):
                try:
                    if page_num > 1:
                        self.driver.get(
                            f"https://www.shanghairanking.cn/rankings/bcsr/2025/{subject_code}?page={page_num}")
                        time.sleep(3)

                    page_data = self.parse_current_page(subject_code, subject_name, page_num)
                    if page_data:
                        all_data.extend(page_data)

                    if page_num < total_pages:
                        time.sleep(random.uniform(3, 6))

                except Exception:
                    continue

            unique_data = {}
            for data in all_data:
                key = f"{data['ranking_position_2025']}_{data['school_name']}"
                if key not in unique_data:
                    unique_data[key] = data

            all_data = list(unique_data.values())
            all_data.sort(key=lambda x: x['ranking_position_2025'])
            return all_data

        except Exception:
            return []

    def save_subject_rankings_to_db(self, rankings):
        """ä¿å­˜å­¦ç§‘æ’åæ•°æ®åˆ°æ•°æ®åº“"""
        if not rankings:
            return False

        connection = self.get_db_connection()
        if not connection:
            return False

        try:
            cursor = connection.cursor()
            saved_count = 0

            for ranking in rankings:
                try:
                    if not ranking.get('school_name') or len(ranking['school_name']) < 2:
                        continue

                    query = """
                    INSERT INTO shanghai_subject_rankings 
                    (year, subject_code, subject_name, ranking_position_2025, ranking_position_2024, 
                     school_name, score_2025, score_2024, subject_category)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                    ranking_position_2025 = VALUES(ranking_position_2025),
                    ranking_position_2024 = VALUES(ranking_position_2024),
                    score_2025 = VALUES(score_2025),
                    score_2024 = VALUES(score_2024),
                    subject_category = VALUES(subject_category)
                    """

                    cursor.execute(query, (
                        ranking['year'],
                        ranking['subject_code'],
                        ranking['subject_name'],
                        ranking['ranking_position_2025'],
                        ranking['ranking_position_2024'],
                        ranking['school_name'],
                        ranking['score_2025'],
                        ranking['score_2024'],
                        ranking['subject_category']
                    ))
                    saved_count += 1

                except MySQLError:
                    continue

            connection.commit()
            logging.info(f"æˆåŠŸä¿å­˜ {saved_count} æ¡æ•°æ®åˆ°æ•°æ®åº“")
            return True

        except MySQLError:
            connection.rollback()
            return False
        finally:
            if connection.is_connected():
                cursor.close()
                connection.close()

    def close_driver(self):
        """å…³é—­WebDriver"""
        if self.driver:
            try:
                self.driver.quit()
                logging.info("WebDriverå·²å…³é—­")
            except:
                pass


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        connection = pymysql.connect(
            host='localhost',
            user='root',
            password='your_password',
            database='kaoyan_data',
            charset='utf8mb4',
            cursorclass=DictCursor
        )
        return connection
    except pymysql.Error as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None


def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    connection = get_db_connection()
    if not connection:
        return False

    try:
        with connection.cursor() as cursor:
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS users (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    username VARCHAR(50) UNIQUE NOT NULL,
                    email VARCHAR(100) UNIQUE NOT NULL,
                    password_hash VARCHAR(255) NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_login TIMESTAMP NULL,
                    is_active BOOLEAN DEFAULT TRUE
                )
            """)

            cursor.execute("""
                CREATE TABLE IF NOT EXISTS chat_history (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    user_id INT,
                    question TEXT NOT NULL,
                    answer TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id)
                )
            """)

        connection.commit()
        return True
    except pymysql.Error as e:
        st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    finally:
        connection.close()


def hash_password(password):
    """å¯†ç å“ˆå¸Œå¤„ç†"""
    return hashlib.sha256(password.encode()).hexdigest()


def validate_email(email):
    """éªŒè¯é‚®ç®±æ ¼å¼"""
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None


def validate_username(username):
    """éªŒè¯ç”¨æˆ·åæ ¼å¼"""
    return len(username) >= 3 and len(username) <= 50 and re.match(r'^[a-zA-Z0-9_]+$', username)


def register_user(username, email, password):
    """æ³¨å†Œæ–°ç”¨æˆ·"""
    connection = get_db_connection()
    if not connection:
        return False, "æ•°æ®åº“è¿æ¥å¤±è´¥"

    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT id FROM users WHERE username = %s", (username,))
            if cursor.fetchone():
                return False, "ç”¨æˆ·åå·²å­˜åœ¨"

            cursor.execute("SELECT id FROM users WHERE email = %s", (email,))
            if cursor.fetchone():
                return False, "é‚®ç®±å·²è¢«æ³¨å†Œ"

            password_hash = hash_password(password)
            cursor.execute(
                "INSERT INTO users (username, email, password_hash) VALUES (%s, %s, %s)",
                (username, email, password_hash)
            )

        connection.commit()
        return True, "æ³¨å†ŒæˆåŠŸ"

    except pymysql.Error as e:
        return False, f"æ³¨å†Œå¤±è´¥: {str(e)}"
    finally:
        connection.close()


def verify_user(username, password):
    """éªŒè¯ç”¨æˆ·ç™»å½•"""
    connection = get_db_connection()
    if not connection:
        return False, None

    try:
        with connection.cursor() as cursor:
            password_hash = hash_password(password)

            cursor.execute(
                "SELECT id, username, email FROM users WHERE username = %s AND password_hash = %s AND is_active = TRUE",
                (username, password_hash)
            )

            user = cursor.fetchone()
            if user:
                cursor.execute(
                    "UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = %s",
                    (user['id'],)
                )
                connection.commit()
                return True, user
            else:
                return False, None

    except pymysql.Error:
        return False, None
    finally:
        connection.close()


def verify_user_by_email(email, password):
    """é€šè¿‡é‚®ç®±éªŒè¯ç”¨æˆ·ç™»å½•"""
    connection = get_db_connection()
    if not connection:
        return False, None

    try:
        with connection.cursor() as cursor:
            password_hash = hash_password(password)

            cursor.execute(
                "SELECT id, username, email FROM users WHERE email = %s AND password_hash = %s AND is_active = TRUE",
                (email, password_hash)
            )

            user = cursor.fetchone()
            if user:
                cursor.execute(
                    "UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = %s",
                    (user['id'],)
                )
                connection.commit()
                return True, user
            else:
                return False, None

    except pymysql.Error:
        return False, None
    finally:
        connection.close()


def save_chat_history(user_id, question, answer):
    """ä¿å­˜èŠå¤©è®°å½•åˆ°æ•°æ®åº“"""
    connection = get_db_connection()
    if not connection:
        return False

    try:
        with connection.cursor() as cursor:
            cursor.execute(
                "INSERT INTO chat_history (user_id, question, answer) VALUES (%s, %s, %s)",
                (user_id, question, answer)
            )
        connection.commit()
        return True
    except pymysql.Error:
        return False
    finally:
        connection.close()


def get_chat_history(user_id, limit=10):
    """è·å–ç”¨æˆ·èŠå¤©è®°å½•"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            cursor.execute(
                "SELECT question, answer, timestamp FROM chat_history WHERE user_id = %s ORDER BY timestamp DESC LIMIT %s",
                (user_id, limit)
            )
            return cursor.fetchall()
    except pymysql.Error:
        return []
    finally:
        connection.close()


def clear_chat_history(user_id):
    """æ¸…ç©ºç”¨æˆ·çš„èŠå¤©å†å²è®°å½•"""
    connection = get_db_connection()
    if not connection:
        return False

    try:
        with connection.cursor() as cursor:
            cursor.execute(
                "DELETE FROM chat_history WHERE user_id = %s",
                (user_id,)
            )
        connection.commit()
        return True
    except pymysql.Error:
        return False
    finally:
        connection.close()


def query_database(question):
    """æ ¹æ®é—®é¢˜æŸ¥è¯¢è€ƒç ”æ•°æ®åº“"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            question_lower = question.lower()
            conditions = []
            params = []

            school_pattern = r'([\u4e00-\u9fa5]+å¤§å­¦)'
            school_matches = re.findall(school_pattern, question)
            if school_matches:
                for school in school_matches:
                    conditions.append("school_name LIKE %s")
                    params.append(f"%{school}%")

            major_patterns = [
                'ä¿¡æ¯å®‰å…¨', 'è®¡ç®—æœº', 'è½¯ä»¶', 'äººå·¥æ™ºèƒ½', 'ç”µå­ä¿¡æ¯',
                'è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯', 'è½¯ä»¶å·¥ç¨‹', 'äººå·¥æ™ºèƒ½', 'ç½‘ç»œå®‰å…¨'
            ]

            for pattern in major_patterns:
                if pattern in question:
                    conditions.append("major_name LIKE %s")
                    params.append(f"%{pattern}%")

            if conditions:
                query = """
                SELECT DISTINCT 
                    school_name, major_name, major_code, department, research_direction,
                    politics_subject, foreign_language_subject, business_subject1, business_subject2,
                    enrollment_plan, region, data_source
                FROM exam_subjects 
                WHERE """ + " OR ".join(conditions) + """
                ORDER BY school_name, major_name, research_direction
                """
                cursor.execute(query, params)
            else:
                words = question.replace('?', '').replace('ï¼Ÿ', '').split()
                if len(words) > 0:
                    query = """
                    SELECT * FROM exam_subjects 
                    WHERE CONCAT(school_name, major_name, research_direction) LIKE %s
                    ORDER BY school_name, major_name
                    LIMIT 10
                    """
                    search_term = f"%{'%'.join(words)}%"
                    cursor.execute(query, (search_term,))
                else:
                    return []

            results = cursor.fetchall()
            return results

    except pymysql.Error as e:
        print(f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {e}")
        return []
    finally:
        connection.close()


def format_database_results(results):
    """æ ¼å¼åŒ–æ•°æ®åº“æŸ¥è¯¢ç»“æœ"""
    if not results:
        return "æœªåœ¨æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

    formatted = "ä»¥ä¸‹æ˜¯æ•°æ®åº“ä¸­çš„ç›¸å…³è€ƒç ”ä¿¡æ¯ï¼š\n\n"

    for i, result in enumerate(results, 1):
        formatted += f"**{i}. {result['school_name']} - {result['major_name']}**"

        if result.get('major_code'):
            formatted += f"ï¼ˆ{result['major_code']}ï¼‰"
        formatted += "\n"

        if result.get('research_direction'):
            formatted += f"   **ç ”ç©¶æ–¹å‘**ï¼š{result['research_direction']}\n"

        if result.get('department'):
            formatted += f"   **å¼€è®¾é™¢ç³»**ï¼š{result['department']}\n"

        if result.get('enrollment_plan'):
            formatted += f"   **æ‹Ÿæ‹›ç”Ÿäººæ•°**ï¼š{result['enrollment_plan']}\n"

        has_exam_subjects = (
                result.get('politics_subject') or
                result.get('foreign_language_subject') or
                result.get('business_subject1') or
                result.get('business_subject2')
        )

        if has_exam_subjects:
            formatted += "   **è€ƒè¯•ç§‘ç›®**ï¼š\n"
            if result.get('politics_subject'):
                formatted += f"   - æ”¿æ²»ï¼š{result['politics_subject']}\n"
            if result.get('foreign_language_subject'):
                formatted += f"   - å¤–è¯­ï¼š{result['foreign_language_subject']}\n"
            if result.get('business_subject1'):
                formatted += f"   - ä¸šåŠ¡è¯¾ä¸€ï¼š{result['business_subject1']}\n"
            if result.get('business_subject2'):
                formatted += f"   - ä¸šåŠ¡è¯¾äºŒï¼š{result['business_subject2']}\n"

        formatted += f"   **åœ°åŒº**ï¼š{result.get('region', 'æœªè®°å½•')}\n"
        formatted += "\n"

    formatted += """
---
**é‡è¦è¯´æ˜**ï¼šä»¥ä¸Šä¿¡æ¯åŸºäºæ•°æ®åº“ä¸­çš„å†å²æ‹›ç”Ÿæ•°æ®ï¼Œå®é™…æ‹›ç”Ÿä¿¡æ¯è¯·ä»¥å­¦æ ¡å®˜æ–¹æœ€æ–°å…¬å¸ƒä¸ºå‡†ã€‚
"""
    return formatted


def query_shanghai_ranking(question):
    """æŸ¥è¯¢è½¯ç§‘æ’åæ•°æ®"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            question_lower = question.lower()

            ranking_keywords = ['æ’å', 'è½¯ç§‘', 'å­¦ç§‘è¯„ä¼°', 'å­¦ç§‘æ’å']
            if not any(keyword in question_lower for keyword in ranking_keywords):
                return []

            subject_keywords = {
                'æ•°å­¦': ['æ•°å­¦', 'math'],
                'è®¡ç®—æœº': ['è®¡ç®—æœº', 'è½¯ä»¶', 'äººå·¥æ™ºèƒ½', 'ai', 'computer'],
                'ç‰©ç†å­¦': ['ç‰©ç†'],
                'åŒ–å­¦': ['åŒ–å­¦'],
                'ç”Ÿç‰©å­¦': ['ç”Ÿç‰©'],
                'ç»Ÿè®¡å­¦': ['ç»Ÿè®¡'],
                'æœºæ¢°å·¥ç¨‹': ['æœºæ¢°'],
                'ç”µå­ä¿¡æ¯': ['ç”µå­', 'é€šä¿¡', 'ä¿¡æ¯']
            }

            conditions = []
            params = []

            for subject_name, keywords in subject_keywords.items():
                for keyword in keywords:
                    if keyword in question_lower:
                        conditions.append("subject_name LIKE %s")
                        params.append(f"%{subject_name}%")
                        break

            school_pattern = r'([\u4e00-\u9fa5]+å¤§å­¦)'
            school_matches = re.findall(school_pattern, question)
            if school_matches:
                for school in school_matches:
                    conditions.append("school_name LIKE %s")
                    params.append(f"%{school}%")

            if conditions:
                query = """
                SELECT 
                    subject_name, school_name, ranking_position_2025, ranking_position_2024,
                    score_2025, score_2024, subject_category
                FROM shanghai_subject_rankings 
                WHERE """ + " OR ".join(conditions)

                if 'å‰å' in question or 'å‰10' in question:
                    query += " AND ranking_position_2025 <= 10 ORDER BY ranking_position_2025"
                elif 'å‰äºŒå' in question or 'å‰20' in question:
                    query += " AND ranking_position_2025 <= 20 ORDER BY ranking_position_2025"
                elif 'å‰äº”å' in question or 'å‰50' in question:
                    query += " AND ranking_position_2025 <= 50 ORDER BY ranking_position_2025"
                else:
                    query += " ORDER BY subject_name, ranking_position_2025"

                cursor.execute(query, params)
            else:
                query = """
                SELECT 
                    subject_name, school_name, ranking_position_2025, ranking_position_2024,
                    score_2025, score_2024, subject_category
                FROM shanghai_subject_rankings 
                WHERE ranking_position_2025 <= 50
                ORDER BY subject_name, ranking_position_2025
                """
                cursor.execute(query)

            results = cursor.fetchall()
            return results

    except pymysql.Error as e:
        print(f"è½¯ç§‘æ’åæŸ¥è¯¢é”™è¯¯: {e}")
        return []
    finally:
        connection.close()


def format_shanghai_ranking_results(results):
    """æ ¼å¼åŒ–è½¯ç§‘æ’åæŸ¥è¯¢ç»“æœ"""
    if not results:
        return "æœªåœ¨è½¯ç§‘æ’åæ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

    grouped_results = {}
    for result in results:
        subject_name = result['subject_name']
        if subject_name not in grouped_results:
            grouped_results[subject_name] = []
        grouped_results[subject_name].append(result)

    formatted = "**è½¯ç§‘2025å­¦ç§‘æ’åä¿¡æ¯ï¼š**\n\n"

    for subject_name, rankings in grouped_results.items():
        formatted += f"**{subject_name}**\n"

        max_display = 20
        for i, ranking in enumerate(rankings[:max_display]):
            formatted += f"{i + 1:2d}. {ranking['school_name']:<20s} "
            formatted += f"æ’å2025: {ranking['ranking_position_2025']:3d} "

            if ranking['ranking_position_2024'] > 0:
                formatted += f"æ’å2024: {ranking['ranking_position_2024']:3d} "

            if ranking['score_2025'] > 0:
                formatted += f"åˆ†æ•°: {ranking['score_2025']:.1f}"

            formatted += "\n"

        if len(rankings) > max_display:
            formatted += f"  ... è¿˜æœ‰ {len(rankings) - max_display} æ‰€å­¦æ ¡\n"

        formatted += "\n"

    formatted += """
---
**è¯´æ˜**ï¼šæ’ååŸºäºè½¯ç§‘2025å¹´ä¸­å›½å¤§å­¦å­¦ç§‘æ’åï¼Œæ•°æ®æ¥æºï¼šhttps://www.shanghairanking.cn/
"""
    return formatted


def combine_query_results(question):
    """åˆå¹¶è€ƒè¯•ç§‘ç›®å’Œæ’åæŸ¥è¯¢ç»“æœ"""
    exam_results = query_database(question)
    exam_context = format_database_results(exam_results)

    ranking_results = query_shanghai_ranking(question)
    ranking_context = format_shanghai_ranking_results(ranking_results)

    combined_context = ""

    if "æœªåœ¨æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯" not in exam_context:
        combined_context += f"**è€ƒç ”ä¸“ä¸šä¿¡æ¯ï¼š**\n{exam_context}\n\n"

    if "æœªåœ¨è½¯ç§‘æ’åæ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯" not in ranking_context:
        combined_context += f"**è½¯ç§‘æ’åä¿¡æ¯ï¼š**\n{ranking_context}"

    if not combined_context:
        combined_context = "æŠ±æ­‰ï¼Œæœªåœ¨æ•°æ®åº“ä¸­æŸ¥è¯¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

    return combined_context


def call_deepseek_api(question, context):
    """è°ƒç”¨DeepSeek API"""
    try:
        api_key = st.secrets.get("DEEPSEEK_API_KEY", "your_deepseek_api_key_here")
        url = "https://api.deepseek.com/v1/chat/completions"

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è€ƒç ”å’¨è¯¢åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æä¾›çš„æ•°æ®åº“ä¿¡æ¯å›ç­”é—®é¢˜ã€‚"""

        user_message = f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š
{context}

è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®åº“ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"""

        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": 0.3,
            "max_tokens": 2000
        }

        response = requests.post(url, headers=headers, json=data, timeout=30)

        if response.status_code == 200:
            result = response.json()
            answer = result['choices'][0]['message']['content']
            return answer
        else:
            return f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n\næ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š\n{context}"

    except Exception as e:
        return f"è°ƒç”¨AIæœåŠ¡æ—¶å‡ºé”™\n\næ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š\n{context}"


def get_school_list():
    """è·å–å­¦æ ¡åˆ—è¡¨"""
    connection = get_db_connection()
    if not connection:
        return []

    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT DISTINCT school_name FROM exam_subjects ORDER BY school_name")
            schools = [row['school_name'] for row in cursor.fetchall()]
            return schools
    except pymysql.Error:
        return []
    finally:
        connection.close()


def login_page():
    """ç™»å½•é¡µé¢"""
    st.title("ğŸ“ è€ƒç ”AIé—®ç­”ç³»ç»Ÿ - ç™»å½•")

    with st.form("login_form"):
        email = st.text_input("é‚®ç®±", placeholder="è¯·è¾“å…¥æ³¨å†Œé‚®ç®±")
        password = st.text_input("å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
        submit = st.form_submit_button("ç™»å½•", type="primary")

        if submit:
            if not email or not password:
                st.error("è¯·è¾“å…¥é‚®ç®±å’Œå¯†ç ")
            elif not validate_email(email):
                st.error("é‚®ç®±æ ¼å¼ä¸æ­£ç¡®")
            else:
                success, user = verify_user_by_email(email, password)
                if success:
                    st.session_state.user = user
                    st.session_state.page = "main"
                    st.success(f"ç™»å½•æˆåŠŸï¼Œæ¬¢è¿ {user['username']}ï¼")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("é‚®ç®±æˆ–å¯†ç é”™è¯¯")

    st.markdown("---")
    if st.button("ç«‹å³æ³¨å†Œ"):
        st.session_state.page = "register"
        st.rerun()


def register_page():
    """æ³¨å†Œé¡µé¢"""
    st.title("ğŸ“ è€ƒç ”AIé—®ç­”ç³»ç»Ÿ - æ³¨å†Œ")

    with st.form("register_form"):
        username = st.text_input("ç”¨æˆ·å", placeholder="3-50ä¸ªå­—ç¬¦ï¼Œåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
        email = st.text_input("é‚®ç®±", placeholder="è¯·è¾“å…¥æœ‰æ•ˆçš„é‚®ç®±åœ°å€")
        password = st.text_input("å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
        confirm_password = st.text_input("ç¡®è®¤å¯†ç ", type="password", placeholder="è¯·å†æ¬¡è¾“å…¥å¯†ç ")
        submit = st.form_submit_button("æ³¨å†Œ")

        if submit:
            if not username or not email or not password:
                st.error("è¯·å¡«å†™æ‰€æœ‰å­—æ®µ")
            elif not validate_username(username):
                st.error("ç”¨æˆ·åæ ¼å¼ä¸æ­£ç¡®")
            elif not validate_email(email):
                st.error("é‚®ç®±æ ¼å¼ä¸æ­£ç¡®")
            elif password != confirm_password:
                st.error("ä¸¤æ¬¡è¾“å…¥çš„å¯†ç ä¸ä¸€è‡´")
            elif len(password) < 6:
                st.error("å¯†ç é•¿åº¦è‡³å°‘6ä½")
            else:
                success, message = register_user(username, email, password)
                if success:
                    st.success(message)
                else:
                    st.error(message)

    st.markdown("---")
    if st.button("è¿”å›ç™»å½•"):
        st.session_state.page = "login"
        st.rerun()


def main_page():
    """ä¸»é¡µé¢ - AIé—®ç­”"""
    st.title("ğŸ¤– è€ƒç ”AIæ™ºèƒ½é—®ç­”")

    col1, col2, col3 = st.columns([3, 1, 1])
    with col1:
        st.write(f"æ¬¢è¿ï¼Œ**{st.session_state.user['username']}**ï¼")
    with col2:
        if st.button("ğŸ“Š æ•°æ®æŸ¥è¯¢"):
            st.session_state.page = "data_query"
            st.rerun()
    with col3:
        if st.button("ğŸšª é€€å‡ºç™»å½•"):
            st.session_state.clear()
            st.rerun()

    st.markdown("---")

    if 'show_clear_confirm' not in st.session_state:
        st.session_state.show_clear_confirm = False

    if 'messages' not in st.session_state:
        st.session_state.messages = []
        history = get_chat_history(st.session_state.user['id'])
        for item in history:
            st.session_state.messages.append({"role": "user", "content": item['question']})
            st.session_state.messages.append({"role": "assistant", "content": item['answer']})

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    st.subheader("ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼š")
    examples = [
        "ä¸­å›½åœ°è´¨å¤§å­¦ä¿¡æ¯å®‰å…¨ä¸“ä¸šæœ‰å“ªäº›ç ”ç©¶æ–¹å‘ï¼Ÿ",
        "æµ™æ±Ÿå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šçš„è€ƒè¯•ç§‘ç›®æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è½¯ç§‘æ•°å­¦ä¸“ä¸šæ’åå‰åçš„å­¦æ ¡æœ‰å“ªäº›ï¼Ÿ",
        "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯çš„è½¯ç§‘æ’åæƒ…å†µå¦‚ä½•ï¼Ÿ"
    ]

    cols = st.columns(4)
    for i, example in enumerate(examples):
        with cols[i]:
            if st.button(example[:15] + "..." if len(example) > 15 else example, key=f"example_{i}"):
                st.session_state.new_question = example

    question = st.text_area(
        "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š",
        value=st.session_state.get('new_question', ''),
        height=100,
        placeholder="ä¾‹å¦‚ï¼šä¸­å›½åœ°è´¨å¤§å­¦ä¿¡æ¯å®‰å…¨ä¸“ä¸šæœ‰å“ªäº›ç ”ç©¶æ–¹å‘ï¼Ÿæˆ–ï¼šè½¯ç§‘æ•°å­¦æ’åå‰åçš„å­¦æ ¡ï¼Ÿ"
    )

    col1, col2, col3 = st.columns([4, 1, 1])
    with col1:
        if st.button("ğŸ” è·å–ç­”æ¡ˆ", type="primary", use_container_width=True):
            if question:
                st.session_state.messages.append({"role": "user", "content": question})

                with st.chat_message("user"):
                    st.markdown(question)

                with st.chat_message("assistant"):
                    with st.spinner("æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“å¹¶ç”Ÿæˆå›ç­”..."):
                        context = combine_query_results(question)
                        response = call_deepseek_api(question, context)
                        st.markdown(response)
                        save_chat_history(st.session_state.user['id'], question, response)

                st.session_state.messages.append({"role": "assistant", "content": response})

                if 'new_question' in st.session_state:
                    del st.session_state.new_question
            else:
                st.warning("è¯·è¾“å…¥é—®é¢˜")
    with col2:
        if st.button("æ¸…ç©ºå½“å‰å¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            st.success("å½“å‰å¯¹è¯å·²æ¸…ç©º")
            st.rerun()
    with col3:
        if st.button("æ¸…ç©ºå†å²è®°å½•", use_container_width=True):
            st.session_state.show_clear_confirm = True

    if st.session_state.show_clear_confirm:
        st.warning("âš ï¸ ç¡®å®šè¦æ°¸ä¹…åˆ é™¤æ‰€æœ‰å†å²è®°å½•å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ï¼")
        col_yes, col_no = st.columns(2)
        with col_yes:
            if st.button("ç¡®å®šåˆ é™¤", type="primary"):
                if clear_chat_history(st.session_state.user['id']):
                    st.session_state.messages = []
                    st.session_state.show_clear_confirm = False
                    st.success("æ‰€æœ‰å†å²è®°å½•å·²æ°¸ä¹…åˆ é™¤")
                    st.rerun()
        with col_no:
            if st.button("å–æ¶ˆ"):
                st.session_state.show_clear_confirm = False
                st.rerun()


def data_query_page():
    """æ•°æ®æŸ¥è¯¢é¡µé¢ - å››ä¸ªé€‰é¡¹å¡ç•Œé¢"""
    st.title("ğŸ“š è€ƒç ”æ•°æ®æŸ¥è¯¢")

    col1, col2, col3 = st.columns([3, 1, 1])
    with col1:
        st.write(f"æ¬¢è¿ï¼Œ**{st.session_state.user['username']}**ï¼")
    with col2:
        if st.button("ğŸ¤– AIé—®ç­”"):
            st.session_state.page = "main"
            st.rerun()
    with col3:
        if st.button("ğŸšª é€€å‡ºç™»å½•"):
            st.session_state.clear()
            st.rerun()

    st.markdown("---")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” æ¡ä»¶æŸ¥è¯¢", "ğŸ« å­¦æ ¡æµè§ˆ", "ğŸ“Š æ•°æ®ç»Ÿè®¡", "ğŸ¥‡ è½¯ç§‘æ’å"])

    with tab1:
        st.subheader("æ¡ä»¶æŸ¥è¯¢")
        col1, col2 = st.columns(2)
        with col1:
            school_name = st.text_input("å­¦æ ¡åç§°", key="query_school")
        with col2:
            major_name = st.text_input("ä¸“ä¸šåç§°", key="query_major")

        if st.button("æŸ¥è¯¢", key="query_btn"):
            if school_name or major_name:
                connection = get_db_connection()
                if connection:
                    try:
                        with connection.cursor() as cursor:
                            query = "SELECT * FROM exam_subjects WHERE 1=1"
                            params = []

                            if school_name:
                                query += " AND school_name LIKE %s"
                                params.append(f"%{school_name}%")
                            if major_name:
                                query += " AND major_name LIKE %s"
                                params.append(f"%{major_name}%")

                            query += " ORDER BY school_name, major_name LIMIT 50"
                            cursor.execute(query, params)
                            results = cursor.fetchall()

                            if results:
                                st.subheader(f"æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
                                for result in results:
                                    with st.expander(f"{result['school_name']} - {result['major_name']}"):
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.write("**åŸºæœ¬ä¿¡æ¯**")
                                            st.write(f"ä¸“ä¸šä»£ç ï¼š{result.get('major_code', '')}")
                                            st.write(f"é™¢ç³»ï¼š{result.get('department', '')}")
                                            st.write(f"ç ”ç©¶æ–¹å‘ï¼š{result.get('research_direction', '')}")
                                            st.write(f"æ‹›ç”Ÿäººæ•°ï¼š{result.get('enrollment_plan', '')}")
                                            st.write(f"åœ°åŒºï¼š{result.get('region', '')}")

                                        with col2:
                                            st.write("**è€ƒè¯•ç§‘ç›®**")
                                            if result.get('politics_subject'):
                                                st.write(f"æ”¿æ²»ï¼š{result['politics_subject']}")
                                            if result.get('foreign_language_subject'):
                                                st.write(f"å¤–è¯­ï¼š{result['foreign_language_subject']}")
                                            if result.get('business_subject1'):
                                                st.write(f"ä¸šåŠ¡è¯¾ä¸€ï¼š{result['business_subject1']}")
                                            if result.get('business_subject2'):
                                                st.write(f"ä¸šåŠ¡è¯¾äºŒï¼š{result['business_subject2']}")
                            else:
                                st.warning("æœªæ‰¾åˆ°ç›¸å…³æ•°æ®")

                    except pymysql.Error as e:
                        st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    finally:
                        connection.close()
            else:
                st.warning("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶")

    with tab2:
        st.subheader("å­¦æ ¡ä¸“ä¸šæµè§ˆ")
        schools = get_school_list()

        if schools:
            selected_school = st.selectbox("é€‰æ‹©å­¦æ ¡", schools, key="browse_school")

            if selected_school:
                connection = get_db_connection()
                if connection:
                    try:
                        with connection.cursor() as cursor:
                            cursor.execute(
                                "SELECT DISTINCT major_name FROM exam_subjects WHERE school_name = %s ORDER BY major_name",
                                (selected_school,)
                            )
                            majors = [row['major_name'] for row in cursor.fetchall()]

                            if majors:
                                selected_major = st.selectbox("é€‰æ‹©ä¸“ä¸š", majors, key="browse_major")

                                if selected_major:
                                    cursor.execute(
                                        "SELECT * FROM exam_subjects WHERE school_name = %s AND major_name = %s ORDER BY department",
                                        (selected_school, selected_major)
                                    )
                                    results = cursor.fetchall()

                                    if results:
                                        for result in results:
                                            with st.expander(
                                                    f"{result['department']} - {result.get('research_direction', 'ä¸åŒºåˆ†ç ”ç©¶æ–¹å‘')}"):
                                                col1, col2 = st.columns(2)
                                                with col1:
                                                    st.write("**åŸºæœ¬ä¿¡æ¯**")
                                                    st.write(f"ä¸“ä¸šä»£ç ï¼š{result.get('major_code', '')}")
                                                    st.write(f"æ‹›ç”Ÿäººæ•°ï¼š{result.get('enrollment_plan', '')}")

                                                with col2:
                                                    st.write("**è€ƒè¯•ç§‘ç›®**")
                                                    if result.get('politics_subject'):
                                                        st.write(f"æ”¿æ²»ï¼š{result['politics_subject']}")
                                                    if result.get('foreign_language_subject'):
                                                        st.write(f"å¤–è¯­ï¼š{result['foreign_language_subject']}")
                                                    if result.get('business_subject1'):
                                                        st.write(f"ä¸šåŠ¡è¯¾ä¸€ï¼š{result['business_subject1']}")
                                                    if result.get('business_subject2'):
                                                        st.write(f"ä¸šåŠ¡è¯¾äºŒï¼š{result['business_subject2']}")
                            else:
                                st.warning("è¯¥å­¦æ ¡æš‚æ— ä¸“ä¸šä¿¡æ¯")

                    except pymysql.Error as e:
                        st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                    finally:
                        connection.close()
        else:
            st.warning("æš‚æ— å­¦æ ¡æ•°æ®")

    with tab3:
        st.subheader("æ•°æ®ç»Ÿè®¡")
        connection = get_db_connection()
        if connection:
            try:
                with connection.cursor() as cursor:
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        cursor.execute("SELECT COUNT(*) FROM exam_subjects")
                        total_records = cursor.fetchone()['COUNT(*)']
                        st.metric("æ€»è®°å½•æ•°", total_records)

                    with col2:
                        cursor.execute("SELECT COUNT(DISTINCT school_name) FROM exam_subjects")
                        total_schools = cursor.fetchone()['COUNT(DISTINCT school_name)']
                        st.metric("è¦†ç›–é«˜æ ¡æ•°", total_schools)

                    with col3:
                        cursor.execute("SELECT COUNT(DISTINCT major_name) FROM exam_subjects")
                        total_majors = cursor.fetchone()['COUNT(DISTINCT major_name)']
                        st.metric("ä¸“ä¸šæ•°é‡", total_majors)

                    st.subheader("çƒ­é—¨ä¸“ä¸šTOP 10")
                    cursor.execute("""
                        SELECT major_name, COUNT(*) as count 
                        FROM exam_subjects 
                        GROUP BY major_name 
                        ORDER BY count DESC 
                        LIMIT 10
                    """)
                    major_stats = cursor.fetchall()

                    if major_stats:
                        df_major = pd.DataFrame(major_stats)
                        st.dataframe(df_major, use_container_width=True)

                    st.subheader("åœ°åŒºåˆ†å¸ƒ")
                    cursor.execute(
                        "SELECT region, COUNT(*) as count FROM exam_subjects GROUP BY region ORDER BY count DESC")
                    region_stats = cursor.fetchall()

                    if region_stats:
                        df_region = pd.DataFrame(region_stats)
                        st.bar_chart(df_region.set_index('region'))

            except pymysql.Error as e:
                st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            finally:
                connection.close()

    with tab4:
        st.subheader("è½¯ç§‘æ’åæŸ¥è¯¢")

        col1, col2 = st.columns(2)
        with col1:
            ranking_subject = st.text_input("å­¦ç§‘åç§°ï¼ˆå¦‚ï¼šæ•°å­¦ã€è®¡ç®—æœºï¼‰", key="ranking_subject")
        with col2:
            ranking_school = st.text_input("å­¦æ ¡åç§°", key="ranking_school")

        col3, col4 = st.columns(2)
        with col3:
            top_n = st.selectbox("æ˜¾ç¤ºå‰Nå", [10, 20, 50, 100, 200], index=0)
        with col4:
            subject_category = st.selectbox("å­¦ç§‘ç±»åˆ«", ["å…¨éƒ¨", "ç†å­¦", "å·¥å­¦", "å…¶ä»–"], index=0)

        if st.button("æŸ¥è¯¢æ’å", key="query_ranking"):
            connection = get_db_connection()
            if connection:
                try:
                    with connection.cursor() as cursor:
                        query = """
                        SELECT 
                            subject_name, school_name, ranking_position_2025, ranking_position_2024,
                            score_2025, score_2024, subject_category
                        FROM shanghai_subject_rankings 
                        WHERE 1=1
                        """
                        params = []

                        if ranking_subject:
                            query += " AND subject_name LIKE %s"
                            params.append(f"%{ranking_subject}%")

                        if ranking_school:
                            query += " AND school_name LIKE %s"
                            params.append(f"%{ranking_school}%")

                        if subject_category != "å…¨éƒ¨":
                            query += " AND subject_category = %s"
                            params.append(subject_category)

                        query += f" AND ranking_position_2025 <= {top_n}"
                        query += " ORDER BY subject_name, ranking_position_2025"

                        cursor.execute(query, params)
                        results = cursor.fetchall()

                        if results:
                            grouped_results = {}
                            for result in results:
                                subject_name = result['subject_name']
                                if subject_name not in grouped_results:
                                    grouped_results[subject_name] = []
                                grouped_results[subject_name].append(result)

                            for subject_name, rankings in grouped_results.items():
                                st.subheader(f"{subject_name}")

                                df = pd.DataFrame(rankings)
                                df = df[['school_name', 'ranking_position_2025', 'ranking_position_2024', 'score_2025',
                                         'subject_category']]
                                df.columns = ['å­¦æ ¡åç§°', '2025æ’å', '2024æ’å', '2025åˆ†æ•°', 'å­¦ç§‘ç±»åˆ«']

                                st.dataframe(df, use_container_width=True)

                                chart_df = df.head(10).copy()
                                if not chart_df.empty:
                                    chart_df = chart_df.sort_values('2025æ’å')
                                    st.bar_chart(chart_df.set_index('å­¦æ ¡åç§°')['2025åˆ†æ•°'])
                        else:
                            st.warning("æœªæ‰¾åˆ°ç›¸å…³æ’åæ•°æ®")

                except pymysql.Error as e:
                    st.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
                finally:
                    connection.close()


def interactive_crawler_ui():
    """äº¤äº’å¼çˆ¬è™«ç•Œé¢"""
    print("=" * 60)
    print("æ¬¢è¿ä½¿ç”¨è€ƒç ”æ•°æ®çˆ¬è™«ç³»ç»Ÿ")
    print("=" * 60)

    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
        print("1. æŒ‰åœ°åŒºæœç´¢çˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯")
        print("2. æŒ‰å­¦æ ¡æœç´¢çˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯")
        print("3. è¿è¡Œè½¯ç§‘æ’åçˆ¬è™«")
        print("4. åˆ é™¤æ•°æ®")
        print("5. é€€å‡º")

        choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()

        if choice == "1":
            crawl_by_region()
        elif choice == "2":
            crawl_by_school()
        elif choice == "3":
            crawl_shanghai_ranking()
        elif choice == "4":
            delete_data()
        elif choice == "5":
            print("æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
        else:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")


def crawl_by_region():
    """æŒ‰åœ°åŒºçˆ¬å–"""
    print("\n=== æŒ‰åœ°åŒºçˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯ ===")
    spider = CompleteInfoSpider()

    regions, features = spider.select_region_and_features()

    if not regions:
        print("æœªé€‰æ‹©ä»»ä½•åœ°åŒºï¼Œè¿”å›ä¸»èœå•")
        return

    print(f"\nå·²é€‰æ‹©åœ°åŒº: {regions}")
    print(f"å·²é€‰æ‹©é™¢æ ¡ç‰¹æ€§: {features}")

    confirm = input("ç¡®è®¤å¼€å§‹çˆ¬å–å—ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆçˆ¬å–")
        return

    print("\nå¼€å§‹çˆ¬å–...")
    spider.crawl_by_regions_and_features(regions, features)
    print(f"\nçˆ¬å–å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“å’ŒExcelæ–‡ä»¶: {spider.excel_filename}")


def crawl_by_school():
    """æŒ‰å­¦æ ¡çˆ¬å–"""
    print("\n=== æŒ‰å­¦æ ¡çˆ¬å–è€ƒç ”ä¸“ä¸šä¿¡æ¯ ===")
    spider = CompleteInfoSpider()

    school_names = spider.select_schools_by_name()

    if not school_names:
        print("æœªè¾“å…¥ä»»ä½•å­¦æ ¡åç§°ï¼Œè¿”å›ä¸»èœå•")
        return

    print(f"\nå·²é€‰æ‹©å­¦æ ¡: {school_names}")

    confirm = input("ç¡®è®¤å¼€å§‹çˆ¬å–å—ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆçˆ¬å–")
        return

    print("\nå¼€å§‹çˆ¬å–...")
    spider.crawl_by_school_names(school_names)
    print(f"\nçˆ¬å–å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“å’ŒExcelæ–‡ä»¶: {spider.excel_filename}")


def crawl_shanghai_ranking():
    """çˆ¬å–è½¯ç§‘æ’å"""
    print("\n=== çˆ¬å–è½¯ç§‘æ’å ===")

    spider = ShanghaiRankingSpider(headless=True)

    try:
        print("\næ­£åœ¨ä»è½¯ç§‘å®˜ç½‘è·å–å­¦ç§‘åˆ—è¡¨...")
        subjects_data = spider.fetch_all_subjects_from_web()

        if not subjects_data:
            print("è·å–å­¦ç§‘åˆ—è¡¨å¤±è´¥")
            return

        subject_mapping = spider.display_all_subjects()

        if not subject_mapping:
            print("æœªæ‰¾åˆ°å¯ç”¨å­¦ç§‘")
            return

        # æ˜¾ç¤ºå­¦ç§‘åˆ—è¡¨ç»™ç”¨æˆ·
        print("\nå¯ç”¨çš„å­¦ç§‘åˆ—è¡¨ï¼š")
        print("-" * 60)

        sorted_categories = {}
        for idx in subject_mapping:
            subject_code, subject_name, category_code, category_name = subject_mapping[idx]
            if category_name not in sorted_categories:
                sorted_categories[category_name] = []
            sorted_categories[category_name].append((idx, subject_code, subject_name))

        # æŒ‰ç±»åˆ«æ˜¾ç¤ºå­¦ç§‘
        for category_name in sorted(sorted_categories.keys()):
            print(f"\n{category_name}:")
            for idx, subject_code, subject_name in sorted_categories[category_name]:
                print(f"  {idx:3d}. {subject_code} {subject_name}")

        print("-" * 60)

        print("\nè¯·é€‰æ‹©çˆ¬å–æ¨¡å¼ï¼š")
        print("1. é€‰æ‹©ç‰¹å®šå­¦ç§‘çˆ¬å–")
        print("2. çˆ¬å–æ‰€æœ‰å­¦ç§‘ï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰")
        print("3. è¿”å›ä¸»èœå•")

        mode = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-3): ").strip()

        if mode == "1":
            while True:
                selection = input("\nè¯·è¾“å…¥è¦çˆ¬å–çš„å­¦ç§‘ç¼–å·ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰: ").strip()

                if not selection:
                    print("è¾“å…¥ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue

                try:
                    selected_indices = [int(idx.strip()) for idx in selection.split(',') if idx.strip().isdigit()]

                    if not selected_indices:
                        print("æœªè¾“å…¥æœ‰æ•ˆç¼–å·ï¼Œè¯·é‡æ–°è¾“å…¥")
                        continue

                    valid_indices = [idx for idx in selected_indices if idx in subject_mapping]

                    if not valid_indices:
                        print("æ— æ•ˆçš„ç¼–å·ï¼Œè¯·é‡æ–°è¾“å…¥")
                        continue

                    selected_subjects = []
                    for idx in valid_indices:
                        subject_code, subject_name, _, _ = subject_mapping[idx]
                        selected_subjects.append((subject_code, subject_name))
                        print(f"  - {subject_code} {subject_name}")

                    confirm = input(f"\nç¡®è®¤çˆ¬å–ä»¥ä¸Š {len(selected_subjects)} ä¸ªå­¦ç§‘å—ï¼Ÿ(y/n): ").strip().lower()
                    if confirm != 'y':
                        print("å·²å–æ¶ˆçˆ¬å–")
                        continue

                    print("\nå¼€å§‹çˆ¬å–...")
                    all_data = []

                    for i, (subject_code, subject_name) in enumerate(selected_subjects):
                        print(f"\n[{i + 1}/{len(selected_subjects)}] çˆ¬å–å­¦ç§‘: {subject_name} ({subject_code})")
                        data = spider.fetch_subject_data(subject_code, subject_name, max_pages=3)
                        if data:
                            spider.save_subject_rankings_to_db(data)
                            all_data.extend(data)
                            print(f"  å·²çˆ¬å– {len(data)} æ¡æ•°æ®")
                        else:
                            print(f"  æœªè·å–åˆ°æ•°æ®")

                        if i < len(selected_subjects) - 1:
                            delay = random.uniform(3, 8)
                            print(f"  ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                            time.sleep(delay)

                    print(f"\nçˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡æ•°æ®")
                    break

                except ValueError:
                    print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")

        elif mode == "2":
            total_subjects = len(subject_mapping)
            print(f"\nè­¦å‘Šï¼šå°†çˆ¬å–å…¨éƒ¨ {total_subjects} ä¸ªå­¦ç§‘ï¼Œè¿™å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼")

            confirm = input("ç¡®è®¤çˆ¬å–æ‰€æœ‰å­¦ç§‘å—ï¼Ÿ(y/n): ").strip().lower()
            if confirm != 'y':
                print("å·²å–æ¶ˆçˆ¬å–")
                return

            print("\nå¼€å§‹çˆ¬å–æ‰€æœ‰å­¦ç§‘...")
            all_data = []
            current = 1

            for idx in range(1, total_subjects + 1):
                subject_code, subject_name, _, _ = subject_mapping[idx]
                print(f"\n[{current}/{total_subjects}] çˆ¬å–å­¦ç§‘: {subject_name} ({subject_code})")

                data = spider.fetch_subject_data(subject_code, subject_name, max_pages=2)
                if data:
                    spider.save_subject_rankings_to_db(data)
                    all_data.extend(data)
                    print(f"  å·²çˆ¬å– {len(data)} æ¡æ•°æ®")
                else:
                    print(f"  æœªè·å–åˆ°æ•°æ®")

                current += 1

                if current <= total_subjects:
                    delay = random.uniform(5, 10)
                    print(f"  ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                    time.sleep(delay)

            print(f"\næ‰€æœ‰å­¦ç§‘çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_data)} æ¡æ•°æ®")

        elif mode == "3":
            print("è¿”å›ä¸»èœå•")

        else:
            print("æ— æ•ˆé€‰é¡¹ï¼Œè¿”å›ä¸»èœå•")

    except Exception as e:
        print(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        spider.close_driver()


def delete_data():
    """åˆ é™¤æ•°æ®"""
    print("\n=== åˆ é™¤æ•°æ® ===")

    print("\nè¯·é€‰æ‹©åˆ é™¤ç±»å‹ï¼š")
    print("1. æŒ‰åœ°åŒºåˆ é™¤è€ƒç ”ä¸“ä¸šä¿¡æ¯")
    print("2. æŒ‰å­¦æ ¡åˆ é™¤è€ƒç ”ä¸“ä¸šä¿¡æ¯")
    print("3. æŒ‰å­¦ç§‘åˆ é™¤è½¯ç§‘æ’å")
    print("4. æ¸…ç©ºæ‰€æœ‰è½¯ç§‘æ’åæ•°æ®")
    print("5. è¿”å›ä¸»èœå•")

    choice = input("è¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()

    if choice == "1":
        region = input("è¯·è¾“å…¥è¦åˆ é™¤çš„åœ°åŒºåç§°: ").strip()
        if region:
            spider = CompleteInfoSpider()
            if spider.delete_region_data(region):
                print(f"æˆåŠŸåˆ é™¤åœ°åŒº '{region}' çš„æ‰€æœ‰æ•°æ®")
            else:
                print(f"åˆ é™¤åœ°åŒº '{region}' æ•°æ®å¤±è´¥")

    elif choice == "2":
        school_name = input("è¯·è¾“å…¥è¦åˆ é™¤çš„å­¦æ ¡åç§°: ").strip()
        if school_name:
            spider = CompleteInfoSpider()
            if spider.delete_school_data(school_name, 'school'):
                print(f"æˆåŠŸåˆ é™¤å­¦æ ¡ '{school_name}' çš„æ‰€æœ‰æ•°æ®")
            else:
                print(f"åˆ é™¤å­¦æ ¡ '{school_name}' æ•°æ®å¤±è´¥")

    elif choice == "3":
        subject_name = input("è¯·è¾“å…¥è¦åˆ é™¤çš„å­¦ç§‘åç§°: ").strip()
        if subject_name:
            spider = ShanghaiRankingSpider()
            print(f"åˆ é™¤å­¦ç§‘ '{subject_name}' æ•°æ®åŠŸèƒ½éœ€åœ¨ä»£ç ä¸­å®ç°")

    elif choice == "4":
        spider = ShanghaiRankingSpider()
        print("æ¸…ç©ºæ‰€æœ‰è½¯ç§‘æ’åæ•°æ®åŠŸèƒ½éœ€åœ¨ä»£ç ä¸­å®ç°")

    elif choice == "5":
        print("è¿”å›ä¸»èœå•")

    else:
        print("æ— æ•ˆé€‰é¡¹ï¼Œè¿”å›ä¸»èœå•")


def is_running_in_streamlit():
    """æ£€æŸ¥æ˜¯å¦åœ¨Streamlitç¯å¢ƒä¸­è¿è¡Œ"""
    try:
        from streamlit.runtime.scriptrunner import get_script_run_ctx
        return get_script_run_ctx() is not None
    except:
        return False


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–æ•°æ®åº“
    if 'db_initialized' not in st.session_state:
        if init_database():
            st.session_state.db_initialized = True
        else:
            st.error("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥")
            return

    # é¡µé¢è·¯ç”±
    if 'page' not in st.session_state:
        st.session_state.page = "login"

    # æ ¹æ®å½“å‰é¡µé¢æ˜¾ç¤ºç›¸åº”å†…å®¹
    if st.session_state.page == "login":
        login_page()
    elif st.session_state.page == "register":
        register_page()
    elif st.session_state.page == "main":
        if 'user' in st.session_state:
            main_page()
        else:
            st.session_state.page = "login"
            st.rerun()
    elif st.session_state.page == "data_query":
        if 'user' in st.session_state:
            data_query_page()
        else:
            st.session_state.page = "login"
            st.rerun()


if __name__ == "__main__":
    # è‡ªåŠ¨æ£€æµ‹è¿è¡Œç¯å¢ƒ
    if is_running_in_streamlit():
        main()
    else:
        interactive_crawler_ui()
